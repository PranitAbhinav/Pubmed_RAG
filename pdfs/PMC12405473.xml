


<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
    <responseDate>2025-09-09T13:47:28Z</responseDate>
    <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:12405473" metadataPrefix="pmc">https://pmc.ncbi.nlm.nih.gov/api/oai/v1/mh/</request>
    
    <GetRecord>
        <record>
    <header>
    <identifier>oai:pubmedcentral.nih.gov:12405473</identifier>
    <datestamp>2025-09-04</datestamp>
    
        
        <setSpec>scirep</setSpec>
        
    
        
        <setSpec>pmc-open</setSpec>
        
    
</header>
    <metadata>
        
        <article xmlns="https://jats.nlm.nih.gov/ns/archiving/1.4/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.4/ https://jats.nlm.nih.gov/archiving/1.4/xsd/JATS-archivearticle1-4.xsd" article-type="research-article" xml:lang="en" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-id journal-id-type="pmc-domain-id">1579</journal-id><journal-id journal-id-type="pmc-domain">scirep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12405473</article-id><article-id pub-id-type="pmcid-ver">PMC12405473.1</article-id><article-id pub-id-type="pmcaid">12405473</article-id><article-id pub-id-type="pmcaiid">12405473</article-id><article-id pub-id-type="pmid">40897770</article-id><article-id pub-id-type="doi">10.1038/s41598-025-15741-y</article-id><article-id pub-id-type="publisher-id">15741</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Automated analysis of emotional expressions in dogs based on geometric morphometrics</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Martvel</surname><given-names initials="G">George</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><name name-style="western"><surname>Riemer</surname><given-names initials="S">Stefanie</given-names></name><address><email>stefanie.riemer@vetmeduni.ac.at</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02f009v59</institution-id><institution-id institution-id-type="GRID">grid.18098.38</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 0562</institution-id><institution>Tech4Animals Lab, </institution><institution>University of Haifa, </institution></institution-wrap>Abba Khoushy Ave 199, 3498838 Haifa, Israel </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01w6qp003</institution-id><institution-id institution-id-type="GRID">grid.6583.8</institution-id><institution-id institution-id-type="ISNI">0000 0000 9686 6466</institution-id><institution>Present Address: Messerli Research Institute, </institution><institution>University of Veterinary Medicine, </institution></institution-wrap>Veterin&#228;rplatz 1, 1210 Vienna, Austria </aff></contrib-group><pub-date pub-type="epub"><day>2</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>15</volume><issue-id pub-id-type="pmc-issue-id">478255</issue-id><elocation-id>32331</elocation-id><history><date date-type="received"><day>17</day><month>4</month><year>2025</year></date><date date-type="accepted"><day>11</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>02</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>04</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-04 00:25:59.930"><day>04</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#8217;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#8217;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><self-uri content-type="pmc-pdf" xlink:href="41598_2025_Article_15741.pdf"/><abstract id="Abs1"><p id="Par1">Automated analysis of facial expressions is a vibrant field in human affective computing, while research in nonhuman animals is still in its early stages. Compared to labour-intensive manual coding, automation can provide a more reliable and objective alternative, eliminating subjectivity and bias. However, using automated approaches of facial analysis in nonhuman animals &#8220;in the wild&#8221;, i.e. outside of controlled laboratory conditions, is a challenge given the nature of noisy datasets. Here we present the first study using a fully automated analysis of facial landmarks associated with different emotional states in a morphologically diverse sample of pet dogs. We applied a novel AI-pipeline to study fear expressions of dogs in their home environment, analysing owner-provided video recordings during a real-life firework situation on New Year&#8217;s Eve in comparison to a control evening without fireworks. Using a static geometric morphometrics-inspired analysis, the pipeline allows for quantifying dog facial expressions in an extremely noisy and diverse &#8220;in the wild&#8221; dataset, encompassing various breeds, angles and environments. We used an automated facial landmark system of 36 dog facial landmarks based on the Dog Facial Action Coding System. Due to the great variety in morphology of the included dogs, landmarks denoting the ear pinnae were excluded. Nonetheless, landmarks relating to the base of the ears differentiated most strongly between the conditions, suggesting backwards-drawn ears as the best indicator of the firework condition, which is in agreement with manually coded data. Additionally, the firework condition was associated with more mouth-opening, possibly reflecting panting in a subset of dogs. We conclude that automated analysis of dog facial expressions, based on the previously validated landmark system, is feasible in a diverse sample of pet dogs, paving the way towards automated emotion detection.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Animal behaviour</kwd><kwd>Computer science</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100023394</institution-id><institution>Data Science Research Center, University of Haifa</institution></institution-wrap></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#169; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Emotions are considered to be central to the concept of animal welfare&#160;<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. They are affective responses elicited by specific stimuli of relevance to the individual. Such eliciting stimuli may be internal (e.g. the individual&#8217;s own behaviour or memory of past events) or external (e.g. the behaviour of other group members)&#160;<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. Emotions are commonly considered to encompass several components, including specific neural activation, physiological reactions, bodily expressions, a cognitive component (appraisal) and feelings&#160;<sup><xref ref-type="bibr" rid="CR3">3</xref>&#8211;<xref ref-type="bibr" rid="CR8">8</xref></sup>. While subjective states (&#8220;feelings&#8221;)&#160;<sup><xref ref-type="bibr" rid="CR9">9</xref>,<xref ref-type="bibr" rid="CR10">10</xref></sup> could be considered at the core of animal welfare&#160;<sup><xref ref-type="bibr" rid="CR11">11</xref>&#8211;<xref ref-type="bibr" rid="CR13">13</xref></sup>, they cannot be measured directly. Instead, proxy indicators, such as physiological changes (e.g. body temperature, heart rate, and hormone levels), behavioural reactions, vocalisations and bodily and facial expressions can be measured objectively, allowing inferences about the possible emotional experience of the animal&#160;<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>.</p><p id="Par3">To validate emotional indicators, it is essential to utilise target situations that very likely induce the emotion of interest&#160;<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. For instance, G&#228;hwiler et al.&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> used a citizen science approach, collecting home videos of dogs during New Year&#8217;s Eve fireworks as compared to an evening without fireworks to study fear expressions in dogs, with noise fears constituting one of the most common behaviour problems in dogs, affecting up to half the pet dog population&#160;<sup><xref ref-type="bibr" rid="CR17">17</xref>&#8211;<xref ref-type="bibr" rid="CR21">21</xref></sup>. Other studies presented selected stimuli in a controlled experimental environment to dogs to measure behavioural and expressive reactions related to fear&#160;<sup><xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR23">23</xref></sup>. Using predefined ethograms, these studies identified fear-associated behaviours and expressions such as avoidance, a lowered body posture and tail, retreating, vocalisations, hiding, panting, and more subtle indicators such as backwards-directed ears and blinking&#160;<sup><xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR23">23</xref></sup>.</p><p id="Par4">Evidence is increasing that facial expressions of emotions are not limited to humans, but that affective states, motivations, intentions and communicative intent can be inferred from facial expressions also in nonhuman mammals&#160;<sup><xref ref-type="bibr" rid="CR24">24</xref>&#8211;<xref ref-type="bibr" rid="CR27">27</xref></sup>. Unlike in humans, in non-human species, the positioning of the ears also plays a prominent role&#160;<sup><xref ref-type="bibr" rid="CR28">28</xref>&#8211;<xref ref-type="bibr" rid="CR32">32</xref></sup>. Some studies have identified the neurobiological pathways associated with emotional expressions in animals, such as contraction of facial muscles and flattening of the ears when particular relevant stimuli are presented&#160;<sup><xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR33">33</xref></sup>, further supporting the use of facial expressions as emotion indicators in animals.</p><p id="Par5">While the universality of facial expressions of emotions is controversially debated in humans&#160;<sup><xref ref-type="bibr" rid="CR34">34</xref>&#8211;<xref ref-type="bibr" rid="CR36">36</xref></sup>, some issues from human facial expression of emotion, e.g. the influence of social norms&#160;<sup><xref ref-type="bibr" rid="CR37">37</xref></sup> or emotional deception&#160;<sup><xref ref-type="bibr" rid="CR5">5</xref></sup> likely don&#8217;t apply to nonhuman animals. Moreover, research on primates shows that they have less control over their facial expressions compared to their motor behaviors&#160;<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>. This suggests that facial expressions in nonhuman animals have the potential to serve as reliable indicators of their emotional states&#160;<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>.</p><p id="Par6">A relatively objective analysis of facial expressions was made possible by the development of facial action coding systems (FACS)&#160;<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>, which are still considered standard in facial expression analysis. Originally developed for humans, FACS is anatomically based and systematic, describing movements of specific facial muscles&#160;<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>. To date, FACS for several non-human species have been developed, including several primate species, horses, cats, and dogs&#160;<sup><xref ref-type="bibr" rid="CR42">42</xref>&#8211;<xref ref-type="bibr" rid="CR47">47</xref></sup>.</p><p id="Par7">Although the extensive anatomical and appearance diversity of domestic dogs&#160;<sup><xref ref-type="bibr" rid="CR48">48</xref>&#8211;<xref ref-type="bibr" rid="CR51">51</xref></sup> makes studying facial expression in this species particularly challenging, Dog Facial Action Coding System (DogFACS) is increasingly being used to identify emotional states in pet dogs&#160;<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR52">52</xref>&#8211;<xref ref-type="bibr" rid="CR54">54</xref></sup>, particularly in studies conducted in controlled environments where facial behavior can be more effectively captured and analyzed. These studies have demonstrated consistent associations of facial action units with emotional states such as positive anticipation, frustration and fear&#160;<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR52">52</xref>&#8211;<xref ref-type="bibr" rid="CR54">54</xref></sup>.</p><p id="Par8">However, the reliance on manual labelling of expressions and behaviours represents a significant limitation. The coding process is labour-intensive, may require extensive human training and certification, and remains susceptible to a certain degree of human error or bias&#160;<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>. Automation can provide a more reliable and objective alternative, eliminating subjectivity and bias, as well as allowing for work on a much larger scale. It is therefore not surprising that automated facial expression analysis is a vibrant field in human emotion research and affective computing, with numerous commercial software tools available, such as Noldus FaceReader&#160;<sup><xref ref-type="bibr" rid="CR56">56</xref></sup> and Affectiva&#160;<sup><xref ref-type="bibr" rid="CR57">57</xref></sup>. In nonhuman animals, however, the automation of facial expression analysis is still understudied.</p><p id="Par9">In the context of dogs, Boneh-Shitrit et al.&#160;<sup><xref ref-type="bibr" rid="CR58">58</xref></sup> have made first steps towards automation of the detection of DogFACS action units in dogs of one breed (<italic toggle="yes">Labrador Retriever</italic>), utilizing ResNet50&#160;<sup><xref ref-type="bibr" rid="CR59">59</xref></sup> and Vision Transformer (ViT)&#160;<sup><xref ref-type="bibr" rid="CR60">60</xref></sup> backbones over the facial images cropped from video frames, and concluding that more extensive and diverse datasets are crucial for adequately addressing this challenge. The issue with this approach is that it depends on visual characteristics and is thus hardly scalable. For example, a computer vision model that is trained on a particular appearance (range of skin or fur colours) may underperform when encountering different appearances, as has been shown in studies involving humans&#160;<sup><xref ref-type="bibr" rid="CR61">61</xref>,<xref ref-type="bibr" rid="CR62">62</xref></sup>.</p><p id="Par10">Algorithms that utilise facial landmarks present a promising alternative method for automated facial analysis. These algorithms are currently being developed for various species, including cats, dogs, horses, cattle, and sheep&#160;<sup><xref ref-type="bibr" rid="CR63">63</xref>&#8211;<xref ref-type="bibr" rid="CR72">72</xref></sup>; however, many of these efforts have limitations. Typically, there is a limited amount of training data, a small number of landmarks, and a lack of justification for their placement concerning facial muscles, which is crucial for capturing the subtle facial changes necessary for affect recognition.</p><p id="Par11">Although traditionally studied as separate fields, facial landmark detection shares a strong connection with geometric morphometric approaches (GMM)&#160;<sup><xref ref-type="bibr" rid="CR73">73</xref></sup>. This approach relies on the multivariate examination of landmark coordinates, thereby preserving their relative spatial configuration to depict shape accurately. Within GMM, shape differences are assessed primarily using Procrustes distance, calculated following the alignment of shapes through a Generalised Procrustes Analysis (GPA)&#160;<sup><xref ref-type="bibr" rid="CR74">74</xref></sup>. GMM is particularly adept at analysing shape variation across a range of biological structures, allowing for the detection of subtle morphological differences that are significant in developmental and evolutionary research&#160;<sup><xref ref-type="bibr" rid="CR75">75</xref></sup>.</p><p id="Par12">Geometric morphometric-inspired approaches are gaining interest as tools for analysing facial changes as indicators of animal affective states, particularly in studies on pain in cats&#160;<sup><xref ref-type="bibr" rid="CR76">76</xref>,<xref ref-type="bibr" rid="CR77">77</xref></sup> and macaques&#160;<sup><xref ref-type="bibr" rid="CR78">78</xref></sup>. Since these methods rely on single-frame analysis, they are especially valuable when data collection occurs &#8220;in the wild&#8221;, making it challenging to capture a clear view of an animal&#8217;s face for an extended period. One obstacle in using GMM analysis for facial expression analysis, however, is the time-consuming manual annotation of facial landmarks&#160;<sup><xref ref-type="bibr" rid="CR65">65</xref></sup>. The second is the necessity to manually select &#8220;good&#8221; frames, where all facial features are clearly visible. If a computer vision model can be trained to detect a sufficient number of facial landmarks automatically, this will solve both of these challenges: it does not require manual efforts, and the detection is robust to noise and obstruction, as frames of low quality can be automatically detected and discarded.</p><p id="Par13">Recently, Martvel et al. addressed this gap in cat facial analysis by introducing a dataset containing 2,091 cat images and a model that detects 48 anatomy-based cat facial landmarks&#160;<sup><xref ref-type="bibr" rid="CR79">79</xref></sup>. This detector has shown strong performance in tasks that require nuanced facial analysis, such as recognising breed, cephalic type, and pain&#160;<sup><xref ref-type="bibr" rid="CR80">80</xref>,<xref ref-type="bibr" rid="CR81">81</xref></sup>. Furthermore, Martvel et al. extended this approach to dogs by developing a comprehensive landmark scheme that includes 46 facial landmarks based on DogFACS, and a dataset of 3,274 images of dogs of 120 breeds&#160;<sup><xref ref-type="bibr" rid="CR82">82</xref></sup>. Based on this dataset, automated landmark detection models can be trained to analyse new data.</p><p id="Par14">In the current study, we performed automated analysis of dogs&#8217; facial expressions, based on the landmark system by Martvel et al.&#160;<sup><xref ref-type="bibr" rid="CR82">82</xref></sup>, to study dogs&#8217; facial expressions in a fear situation during a real-life firework event as compared to a control situation without fireworks. We used recordings of 11 dogs from the dataset collected by G&#228;hwiler et al.&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> from dog owners using a citizen science approach. An ethogram-based analysis in the original paper revealed that a backwards-directed ear position, measured at the base of the ear rather than the ear pinna, was most closely associated with the fireworks condition. Additionally, the durations of locomotion and panting were significantly greater during the fireworks than in the control setting. While there were increases in vocalisations, blinking, and hiding during the fireworks displays, these changes were no longer statistically significant after correcting for multiple testing. The extremely noisy and diverse data (ranging over dog breeds, environments, and angles) presents an interesting challenge for studying automated analysis, as dynamic landmark-based approaches extracting a continuous signal (like those used in Martvel et al.&#160;<sup><xref ref-type="bibr" rid="CR80">80</xref></sup>) are not feasible. Instead, we developed an automated end-to-end AI pipeline for (1) extracting informative frames from the noisy data and (2) detecting facial landmarks on the dog faces in the extracted frames, using this information to compare dog faces in fireworks and control conditions.</p></sec><sec id="Sec2"><title>Methods</title><sec id="Sec3"><title>Dataset</title><p id="Par15">The dataset for this study was collected previously by G&#228;hwiler et al.&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> to investigate the behaviour of pet dogs during a real-life firework situation (approved by the Veterinary Office of the Canton of Bern, Switzerland, Licence number BE28/17). In a citizen science study, volunteer dog owners were asked to film their dog for five minutes (1) during fireworks on New Year&#8217;s Eve (firework video) and (2) again several days later at a similar time in the evening (control video) of what they considered their dog&#8217;s normal behaviour. All videos were taken indoors in the dogs&#8217; homes. Although the authors did not specifically ask about the identity of the people present during the videos, no more than two people (including the operator) could be discerned in any of the submitted videos. The videos of 42 dogs (one video from each condition, fireworks and control) were initially included in the study, with an average length of <inline-formula id="IEq1"><alternatives><tex-math id="d33e456">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$4.41 \pm 1.74$$\end{document}</tex-math><inline-graphic xlink:href="41598_2025_15741_Article_IEq1.gif"/></alternatives></inline-formula> minutes and 25-30 fps (see example frames in Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref>). More details about the data can be found in the original study of G&#228;hwiler et al.&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup><fig id="Fig1" position="float" orientation="portrait"><label>Fig. 1</label><caption><p>Random frames containing dogs from the original dataset of G&#228;hwiler et al.&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> shared with permission of the owners.</p></caption><graphic id="MO1" position="float" orientation="portrait" xlink:href="41598_2025_15741_Fig1_HTML.jpg"/></fig></p></sec><sec id="Sec4"><title>Landmark detection</title><p id="Par16">We processed all 84 videos (two videos for each of 42 dogs) using the Ensemble Landmark Detector (ELD)&#160;<sup><xref ref-type="bibr" rid="CR79">79</xref></sup>, trained on the DogFLW dataset&#160;<sup><xref ref-type="bibr" rid="CR82">82</xref></sup>. The output time series contained the frame&#8217;s timestamp, coordinates of 46 facial landmarks, and the model&#8217;s confidence (from 0 to 1), representing the quality of detected landmarks. The confidence was obtained from an output of the custom fully connected neural network classifier, trained on the DogFLW landmarks as positive examples and landmark predictions on random images not containing dog faces as negative examples. By giving a landmark set to this model, we obtained a classification score (softmax output) and interpreted it as a metric of &#8220;goodness&#8221; of the landmark set.</p><p id="Par17">Depending on the video&#8217;s fps, the landmark sets were collected from every 2nd to 3rd frame, resulting in 12-15 landmark sets per second. All landmark sets were saved to csv files and then processed using the Python pandas library.</p><p id="Par18">It is important to note that the subjects included various breeds with different ear shapes, ranging from upright pointy ears to cocked ears, rose ears, and floppy ears (see Supplementary Table 1). To mitigate the impact of this variance, we discarded five landmarks for each ear from the original scheme, leaving only ear base landmarks. This way, we ensured that ear movements were still considered in the landmark scheme and reactive ear movements (due to inertia, etc.) were mitigated. The final landmark scheme is shown in Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>.<fig id="Fig2" position="float" orientation="portrait"><label>Fig. 2</label><caption><p>36 landmarks automatically detected on a dog&#8217;s face. Ear landmarks from the original scheme are discarded due to ear shape variation.</p></caption><graphic id="MO2" position="float" orientation="portrait" xlink:href="41598_2025_15741_Fig2_HTML.jpg"/></fig></p></sec><sec id="Sec5"><title>Statistical analysis</title><p id="Par19">To perform the statistical analysis, we followed the pipeline suggested by Finka et al.&#160;<sup><xref ref-type="bibr" rid="CR77">77</xref></sup> and Gris et al.&#160;<sup><xref ref-type="bibr" rid="CR78">78</xref></sup> First, we filtered landmark sets in all videos by confidence threshold and then by tilt and rotation angles, removing outliers by the 95th percentile. For the confidence threshold, a value of 0.6 was chosen based on the data quality-quantity tradeoff, leaving 15% of the original frames. Head tilt was measured as the angle between the line connecting the inner eye corners (landmarks 6 and 7) and the x-axis, and rotation was measured as the distance difference between the inner eye corners and the nose centre (landmark 22). Then, we filtered landmark sets within videos, applying an inter-sample interval of at least 1 second between sets to ensure the independence of dynamic expressions&#160;<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>. All filtering steps were performed to exclude the poorly detected and repetitive landmark sets, while keeping the most informative ones.</p><p id="Par20">After the initial filtering, we selected only individuals with at least ten landmark sets in each condition, resulting in 11 dogs out of the originally 42 dogs (see Supplementary Table 1 for details on breeds, age, and ear types). This reduction in sample size was due to the great variability in video quality, angles of recording, dogs hiding during the fireworks condition, or issues with a lack of contrast (e.g., a dark dog on a dark background), which made it difficult to detect facial features in many frames (see Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref> for examples). Exclusions were fully automated and based on a confidence threshold for the landmark detection process. The top 10 landmark sets for individuals with more samples were selected based on the verification model&#8217;s confidence to ensure that we used the best images available, while maintaining an automated approach and keeping a dataset size appropriate for the statistical analysis.</p><p id="Par21">Procrustes superimposition was applied to all the landmark coordinates to eliminate scaling, translation, and rotation effects between individuals and poses. Then, we performed a PCA on the Procrustes coordinates to produce a pattern of shape variation. Each principal component was assessed for its contribution to the overall variability, ensuring that we retained the most informative components for subsequent analyses.</p><p id="Par22">To evaluate the impact of condition (firework/control) on the most informative principal components, we conducted an Analysis of Variance (ANOVA) on the PC scores, testing for statistically significant differences in their scores between the firework and control conditions. The normality of the residuals was examined using a Shapiro-Wilk test. Because the principal components were individually tested, we applied the Benjamini-Hochberg False Discovery Rate (FDR) correction to control explicitly for multiple comparisons. All tests were performed using the statsmodels Python library.</p><p id="Par23">Given the reduction in sample size, we conducted a post-hoc power analysis to ensure sufficient statistical power for detecting meaningful differences. This analysis was performed at the individual-subject level, averaging PCA scores across multiple frames per dog to maintain statistical independence.</p><p id="Par24">To remove the potential impact of the general head position, we examined the shape variance of the first three PCs, and applied the within-group pooled regression, since the first three PCs could be particularly associated with head-turning, nodding, or a combination of both&#160;<sup><xref ref-type="bibr" rid="CR78">78</xref></sup>. We then investigated the shape change between conditions using the residuals produced by the regression.</p><p id="Par25">Discriminant analysis was performed to identify shape differences associated with experimental conditions. Canonical variates analysis (CVA) was applied, and the resulting scores were used to visualise the distribution of shapes along the discriminant axis. As part of this analysis, Wilks&#8217; Lambda was calculated to assess the degree of separation between groups. Discriminant analysis was performed using scikit-learn&#8217;s LinearDiscriminantAnalysis.</p></sec></sec><sec id="Sec6"><title>Results</title><p id="Par26">220 landmark sets across two conditions were extracted from the eleven dog subjects in two conditions (10 per dog per condition). Based on the aligned landmarks (after the Procrustes superimposition), mean positions in each condition were calculated, and the shape difference was interpolated (see Fig.&#160;<xref rid="Fig3" ref-type="fig">3</xref>).<fig id="Fig3" position="float" orientation="portrait"><label>Fig. 3</label><caption><p>Mean position of 36 facial landmarks in fireworks and control conditions for all dogs and a heatmap of shape difference values.</p></caption><graphic id="MO3" position="float" orientation="portrait" xlink:href="41598_2025_15741_Fig3_HTML.jpg"/></fig></p><p id="Par27">The first eight principal components explained 90% of variance within the population (see Supplementary Figure 1 for cumulative explained variance), with individual contributions ranging from 41% (PC1) to 2% (PC8) and subsequent components each contributing less than 2%. Across the eight PC components tested, only PC5 (<inline-formula id="IEq2"><alternatives><tex-math id="d33e557">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F=13.57, p=0.004$$\end{document}</tex-math><inline-graphic xlink:href="41598_2025_15741_Article_IEq2.gif"/></alternatives></inline-formula>) showed significant differences between the conditions (see Supplementary Table 2 for details). After correction, PC5 remained statistically significant (corrected <inline-formula id="IEq3"><alternatives><tex-math id="d33e563">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p = 0.034$$\end{document}</tex-math><inline-graphic xlink:href="41598_2025_15741_Article_IEq3.gif"/></alternatives></inline-formula>), confirming that differences observed in this component were robust. Figure&#160;<xref rid="Fig4" ref-type="fig">4</xref>a) shows mean PC5 values in fireworks and control conditions, while Fig.&#160;<xref rid="Fig4" ref-type="fig">4</xref>b) demonstrates the change of mean face shape with the change of PC 5, which correlates with Fig.&#160;<xref rid="Fig3" ref-type="fig">3</xref>.</p><p id="Par28">To validate the statistical power, we calculated the mean differences between the fireworks and control conditions per subject for PC5. The observed effect size was large (paired Cohen&#8217;s <inline-formula id="IEq4"><alternatives><tex-math id="d33e580">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d = 1.11$$\end{document}</tex-math><inline-graphic xlink:href="41598_2025_15741_Article_IEq4.gif"/></alternatives></inline-formula>), resulting in a statistical power of 91.2%. To confirm the normality of residuals, we conducted a Shapiro-Wilk test, which showed no significant deviations from normality for PC5 (<inline-formula id="IEq5"><alternatives><tex-math id="d33e586">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W = 0.957$$\end{document}</tex-math><inline-graphic xlink:href="41598_2025_15741_Article_IEq5.gif"/></alternatives></inline-formula>, <inline-formula id="IEq6"><alternatives><tex-math id="d33e592">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p = 0.434$$\end{document}</tex-math><inline-graphic xlink:href="41598_2025_15741_Article_IEq6.gif"/></alternatives></inline-formula>).</p><p id="Par29">By calculating the residuals of the within-group pooled regression between Procrustes coordinates and the first three PCs, we mitigated the head rotation impact on the mean shapes, as suggested by Gris et al.&#160;<sup><xref ref-type="bibr" rid="CR78">78</xref></sup>. The resulting PC variations and mean shapes indicated the ears were moved medially during the fireworks condition relative to the control condition, which could be interpreted as drawn-back ears (see Fig.&#160;<xref rid="Fig4" ref-type="fig">4</xref>c). Only slight differences in brows and eye shape were apparent, although the brows seem slightly lowered during fireworks, and the eyes appear to be oriented slightly more medially during fireworks. Meanwhile, there are some noticeable differences in the landmarks designating muzzle shape, with the upper landmarks (nose landmarks, as well as landmarks 25 and 28) in a more dorsal position and the lower landmarks (31 and 32) in a more ventral position during fireworks compared to the control situation. This would be consistent with mouth-opening, such as in panting or yawning. Furthermore, the edges of the lips (landmarks 33 and 34) are more lateral during fireworks, which could indicate panting.<fig id="Fig4" position="float" orientation="portrait"><label>Fig. 4</label><caption><p><bold>a)</bold> Mean PC5 values with standard deviation for dogs in fireworks and control conditions; <bold>b)</bold> Mean face shape with relative changes of PC5. The red colour represents the increase by 1 SD from the mean value, and the blue colour represents the decrease by 1 SD; <bold>c)</bold> Mean position of 36 facial landmarks in fireworks and control conditions, and a heatmap of shape difference values after removing variation of head orientation.</p></caption><graphic id="MO4" position="float" orientation="portrait" xlink:href="41598_2025_15741_Fig4_HTML.jpg"/></fig></p><p id="Par30">Discriminant analysis was also used to locate differences related to the condition. A CVA scatterplot (Figure&#160;<xref rid="Fig5" ref-type="fig">5</xref> (top)) shows differences in facial shape between conditions. The overall multivariate Wilks&#8217; Lambda for group separation was 0.058 (approximate <italic toggle="yes">F</italic> = 41.43, <inline-formula id="IEq7"><alternatives><tex-math id="d33e631">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$df_1$$\end{document}</tex-math><inline-graphic xlink:href="41598_2025_15741_Article_IEq7.gif"/></alternatives></inline-formula> = 72, <inline-formula id="IEq8"><alternatives><tex-math id="d33e637">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$df_2$$\end{document}</tex-math><inline-graphic xlink:href="41598_2025_15741_Article_IEq8.gif"/></alternatives></inline-formula> = 183, <inline-formula id="IEq9"><alternatives><tex-math id="d33e643">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p &lt; 0.0001$$\end{document}</tex-math><inline-graphic xlink:href="41598_2025_15741_Article_IEq9.gif"/></alternatives></inline-formula>), indicating a highly significant difference in facial shape between conditions. Moreover, the changes in shape along CV1 demonstrate differences similar to those in the PCA (Fig.&#160;<xref rid="Fig5" ref-type="fig">5</xref> (bottom)).<fig id="Fig5" position="float" orientation="portrait"><label>Fig. 5</label><caption><p>Facial shape variation between conditions after Canonical Variate Analysis. Each colour refers to one condition and 0.9 confidence intervals (CI). The scatterplots below depict changes in shape along the canonical variate CV1 (arrows show the directions from the general mean to the mean of each condition: control on the left (red) and fireworks on the right (blue)).</p></caption><graphic id="MO5" position="float" orientation="portrait" xlink:href="41598_2025_15741_Fig5_HTML.jpg"/></fig></p></sec><sec id="Sec7"><title>Discussion</title><p id="Par31">This paper is the first to apply a fully automated geometric morphometrics-inspired analysis to study dog facial expressions in a fear context. This approach allowed us to deal with the challenging and noisy nature of data obtained outside of standardised laboratory conditions (in people&#8217;s homes during fireworks vs an evening without fireworks). Indeed, only around 40% of videos fulfilled the requirement of dog faces detected in more than 50% of frames, and only one video had a dog&#8217;s face on each frame. The AI-based approach allowed us to effectively and automatically filter informative frames containing actual facial expressions for the analysis. In practice, this led to a reduction in sample size from 42 dogs in the initial dataset to only 11 dogs. Despite the relatively low amount of extracted informative frames, we discovered consistent differences in dogs&#8217; facial shapes between the conditions. This demonstrates the value of the proposed methodology for other noisy &#8220;in-the-wild&#8221; datasets for studying animal facial expressions in different emotional states and other contexts. Figure&#160;<xref rid="Fig6" ref-type="fig">6</xref> shows the schematic representation of stress-related facial expressions identified in this study.<fig id="Fig6" position="float" orientation="portrait"><label>Fig. 6</label><caption><p>Schematic representation of the dogs&#8217; facial expressions: neutral (left), and stressed (right), according to the morphometric analysis.</p></caption><graphic id="MO6" position="float" orientation="portrait" xlink:href="41598_2025_15741_Fig6_HTML.jpg"/></fig></p><p id="Par32">Notably, due to the great variety in morphology of the dogs included, we decided to remove the landmarks representing the ear pinnae from the analysis. This led to certain information loss, and therefore it was not possible for us to analyse differences in ear positions directly (such as in Finka et al.&#160;<sup><xref ref-type="bibr" rid="CR77">77</xref></sup>). Nonetheless, using landmarks on the ear bases indicated that ears were the features that differed most strongly between the fireworks and the control condition: during fireworks, the ears were held more medially, which can be interpreted as being drawn backwards. This result is consistent with the findings of G&#228;hwiler et al&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. Like in the current study, they visually assessed ear position measured at the base of the ear to avoid inconsistencies due to the ear pinnae, and this measure differentiated most strongly of all included measures between the fireworks and the control condition. Our results thus indicate that ear position is a highly relevant potential stress indicator (see also Bremhorst et al.&#160;<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR28">28</xref></sup> on frustration) which can be reliably assessed by automated analysis in a diverse sample of domestic dogs.</p><p id="Par33">Additionally, we found significant differences in landmarks associated with mouth-opening between the two conditions. Interestingly, using DogFACS coding to assess facial expressions of frustration vs positive anticipation, Bremhorst et al. found an association of frustration with the DogFACS action units &#8220;lips part&#8221; and &#8220;jaw drop&#8221;&#160;<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. Additionally, they also recorded a higher frequency of the &#8220;lip corner puller&#8221; and &#8220;tongue show&#8221; during a frustration condition as compared with a positive anticipation condition. In the current study, we did not differentiate between possible different action units, although our results could possibly be interpreted in line with the findings of Bremhorst et al.&#160;<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR28">28</xref></sup> for frustration. Additionally, such a result could be potentially affected by barking, during which the mouth landmarks behave similarly.</p><p id="Par34">Although the difference between landmarks indicating the aperture of the mouth is not extensive (Figure&#160;<xref rid="Fig3" ref-type="fig">3</xref>), it is possible that this finding reflects the incidence of panting in a small subset of dogs, as noted by G&#228;hwiler et al.&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> Indeed, Caeiro et al.&#160;<sup><xref ref-type="bibr" rid="CR52">52</xref></sup> discovered that dogs consistently showed a higher rate of AD126 (action descriptor, panting) during fear contexts. While the extent of mouth opening that can be inferred from the automated analysis in the current study might appear more subtle than panting, this could potentially be an artefact of the high inter-individual variability in reactions to the fireworks. As G&#228;hwiler et al.&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> pointed out, only a small number of dogs showed panting, but with few exceptions, it occurred exclusively in the fireworks condition. Due to our averaging over all participating dogs, the extent of mouth-opening might appear smaller than it actually was in those few dogs that did pant.</p><p id="Par35">This highlights the necessity of careful human interpretation when analysing AI-generated findings. Moreover, unlike panting, the wide opening of the mouth in Caeiro et al.&#160;<sup><xref ref-type="bibr" rid="CR52">52</xref></sup> was significantly associated with states they interpreted as happiness. Thus, attention to detail and to inter-individual variability is paramount to consider in order to obtain valid interpretations from dogs&#8217; facial expressions. Indeed, G&#228;hwiler et al.&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> discussed the high variability in fear behaviour between individual dogs, stating that &#8220;individual differences must be taken into account when aiming to assess an individual&#8217;s level of fear, as relevant measures may not be the same for all individuals&#8221;. Universally, however, the fireworks condition was associated with backwards-directed ears, which represented the best indicator both according to manual coding and the current automated analysis.</p><p id="Par36">As discussed in Bremhorst et al.&#160;<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, it is questionable to what extent we are currently able to differentiate negative emotions (such as fear and frustration) from facial expressions alone, or whether we can only draw conclusions about more universal stress expressions. For instance, studies indicate that backwards-directed ears, mouth-opening/panting and blinking are associated with both fear and frustration&#160;<sup><xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR83">83</xref>&#8211;<xref ref-type="bibr" rid="CR86">86</xref></sup>. Only Caeiro et al.&#160;<sup><xref ref-type="bibr" rid="CR52">52</xref></sup> differentiated expressions associate with fear and frustration based on DogFACS; however, they only found very few (1&#8211;2) action units to be associated with the respective emotion states, possibly because their videos were obtained from social media showing dogs in diverse situations which the authors retrospectively categorised as inducing either fear or frustration. In contrast, the context was clearly defined in Bremhorst et al.&#160;<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR28">28</xref></sup> (positive anticipation vs frustration when a reward is delivered but inaccessible) and G&#228;hwiler et al.&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> (presence or absence of fireworks), and within-subjects analyses were possible.</p><p id="Par37">The only other behaviour that could be considered as a facial expression differentiating between the conditions reported in G&#228;hwiler et al. was an increased frequency of blinking during the firework condition. Using the approach from the current study, this could not be confirmed, as the analysis was based on automatically selected snapshots of dogs&#8217; faces, rather than continuous monitoring. Brief events, such as blinking or barking, could be missed using this approach.</p><p id="Par38">An additional limitation of the static geometric morphometrics-inspired analysis used here is the usage of two-dimensional facial landmarks, since shape variations could potentially be caused not by conditions but by head rotation and perspective distortion. In the current study, we partially mitigated this by regressing Procrustes coordinates onto PCs and using residuals to remove head rotation effects, but the more advanced techniques with depth evaluation and adding the third dimension to landmarks may be needed to totally reduce the drawbacks of the current representation&#160;<sup><xref ref-type="bibr" rid="CR87">87</xref>,<xref ref-type="bibr" rid="CR88">88</xref></sup>.</p><p id="Par39">As Bremhorst et al.&#160;<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> pointed out, individual emotion indicators are generally not sufficient to predict emotions with a high degree of accuracy. However, machine learning offers an advantage by analysing multiple indicators simultaneously. In the current study, we highlighted only one way to &#8220;decipher&#8221; animal visual signals, based on the static approach. Reliability and accuracy of emotion assessments could be improved even further by taking into account behavioural information (such as freezing), bodily signals and posture, vocalisations, and possibly physiological measures such as heart rate, while also considering possible inter-individual variability in emotional expression.</p><p id="Par40">To conclude, this pioneering work demonstrates that automated emotion assessment in morphologically diverse dogs &#8220;in the wild&#8221; is possible. Follow-up studies should extend this work and assess the accuracy of automated analyses for differentiating between situations of different valence (and thus animals&#8217; likely emotional states) based on their facial expressions. Future potential applications of automated dog facial expression analysis include their use in clinical and behavioural studies, as well as implementation of such algorithms into the surveillance systems in veterinary clinics and shelters, where they can be used to detect and alert to certain animal behaviours and conditions based on visual cues in a fully automated manner.</p></sec><sec id="Sec8" sec-type="supplementary-material"><title>Supplementary Information</title><p>
<supplementary-material content-type="local-data" id="MOESM1" position="float" orientation="portrait"><media xlink:href="41598_2025_15741_MOESM1_ESM.docx" position="float" orientation="portrait"><caption><p>Supplementary Information.</p></caption></media></supplementary-material>
</p></sec></body><back><fn-group><fn><p><bold>Publisher&#8217;s note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.1038/s41598-025-15741-y.</p></sec><ack><title>Acknowledgements</title><p>The first author was supported by the Data Science Research Center at the University of Haifa. We thank Anna Zamansky for helpful comments on the manuscript and all dog caretakers who contributed videos of their dogs.</p></ack><notes notes-type="data-availability"><title>Data availability</title><p>The original video dataset for this study was collected by G&#228;hwiler et al.&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. The code generated during this study is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/martvelge/Fireworks_GMM">https://github.com/martvelge/Fireworks_GMM</ext-link>. The landmark dataset generated and analysed during the current study is available from the corresponding author upon request.</p></notes><notes><title>Declarations</title><notes id="FPar4" notes-type="COI-statement"><title>Competing Interests</title><p>The authors declare no competing interests.</p></notes><notes id="FPar1"><title>Ethics declarations</title><p id="Par43">The original study by G&#228;hwiler et al.&#160;<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> was assessed and approved by the cantonal authority for animal experimentation, the Veterinary Office of the Canton of Bern (Switzerland) (Licence number BE28/17) and complies with the &#8220;Guidelines for the Treatment of Animals in Behavioral Research and Teaching&#8221; of the Association for the Study of Animal Behavior (ASAB). All participating owners gave their informed consent to the use of their videos for scientific analysis. No additional video data were collected for the current study.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>&#352;pinka</surname><given-names>M</given-names></name></person-group><article-title>Social dimension of emotions and its implication for animal welfare</article-title><source>Appl. Anim. Behav. Sci.</source><year>2012</year><volume>138</volume><fpage>170</fpage><lpage>181</lpage></element-citation><mixed-citation id="mc-CR1" publication-type="journal">&#352;pinka, M. Social dimension of emotions and its implication for animal welfare. <italic toggle="yes">Appl. Anim. Behav. Sci.</italic><bold>138</bold>, 170&#8211;181 (2012).</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Scherer</surname><given-names>KR</given-names></name></person-group><article-title>What are emotions? And how can they be measured?</article-title><source>Soc. Sci. Inf.</source><year>2005</year><volume>44</volume><fpage>695</fpage><lpage>729</lpage></element-citation><mixed-citation id="mc-CR2" publication-type="journal">Scherer, K. R. What are emotions? And how can they be measured?. <italic toggle="yes">Soc. Sci. Inf.</italic><bold>44</bold>, 695&#8211;729 (2005).</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">Scherer, K.&#160;R. On the nature and function of emotion: A component process approach. In <italic toggle="yes">Approaches to Emotion</italic>. 293&#8211;317 (Psychology Press, 2014).</mixed-citation></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Paul</surname><given-names>ES</given-names></name><name name-style="western"><surname>Sher</surname><given-names>S</given-names></name><name name-style="western"><surname>Tamietto</surname><given-names>M</given-names></name><name name-style="western"><surname>Winkielman</surname><given-names>P</given-names></name><name name-style="western"><surname>Mendl</surname><given-names>MT</given-names></name></person-group><article-title>Towards a comparative science of emotion: Affect and consciousness in humans and animals</article-title><source>Neurosci. Biobehav. Rev.</source><year>2020</year><volume>108</volume><fpage>749</fpage><lpage>770</lpage><pub-id pub-id-type="pmid">31778680</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neubiorev.2019.11.014</pub-id><pub-id pub-id-type="pmcid">PMC6966324</pub-id></element-citation><mixed-citation id="mc-CR4" publication-type="journal">Paul, E. S., Sher, S., Tamietto, M., Winkielman, P. &amp; Mendl, M. T. Towards a comparative science of emotion: Affect and consciousness in humans and animals. <italic toggle="yes">Neurosci. Biobehav. Rev.</italic><bold>108</bold>, 749&#8211;770 (2020).<pub-id pub-id-type="pmid">31778680</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neubiorev.2019.11.014</pub-id><pub-id pub-id-type="pmcid">PMC6966324</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Anderson</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>A framework for studying emotions across species</article-title><source>Cell</source><year>2014</year><volume>157</volume><fpage>187</fpage><lpage>200</lpage><pub-id pub-id-type="pmid">24679535</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.cell.2014.03.003</pub-id><pub-id pub-id-type="pmcid">PMC4098837</pub-id></element-citation><mixed-citation id="mc-CR5" publication-type="journal">Anderson, D. J. &amp; Adolphs, R. A framework for studying emotions across species. <italic toggle="yes">Cell</italic><bold>157</bold>, 187&#8211;200 (2014).<pub-id pub-id-type="pmid">24679535</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.cell.2014.03.003</pub-id><pub-id pub-id-type="pmcid">PMC4098837</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Baciadonna</surname><given-names>L</given-names></name><name name-style="western"><surname>Duepjan</surname><given-names>S</given-names></name><name name-style="western"><surname>Briefer</surname><given-names>EF</given-names></name><name name-style="western"><surname>Padilla de la Torre</surname><given-names>M</given-names></name><name name-style="western"><surname>Nawroth</surname><given-names>C</given-names></name></person-group><article-title>Looking on the bright side of livestock emotions&#8212;The potential of their transmission to promote positive welfare</article-title><source>Front. Vet. Sci.</source><year>2018</year><volume>5</volume><fpage>218</fpage><pub-id pub-id-type="pmid">30258847</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/fvets.2018.00218</pub-id><pub-id pub-id-type="pmcid">PMC6143710</pub-id></element-citation><mixed-citation id="mc-CR6" publication-type="journal">Baciadonna, L., Duepjan, S., Briefer, E. F., Padilla de la Torre, M. &amp; Nawroth, C. Looking on the bright side of livestock emotions&#8212;The potential of their transmission to promote positive welfare. <italic toggle="yes">Front. Vet. Sci.</italic><bold>5</bold>, 218 (2018).<pub-id pub-id-type="pmid">30258847</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/fvets.2018.00218</pub-id><pub-id pub-id-type="pmcid">PMC6143710</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tracy</surname><given-names>JL</given-names></name><name name-style="western"><surname>Randles</surname><given-names>D</given-names></name></person-group><article-title>Four models of basic emotions: A review of Ekman and Cordaro, Izard, Levenson, and Panksepp and Watt</article-title><source>Emot. Rev.</source><year>2011</year><volume>3</volume><fpage>397</fpage><lpage>405</lpage></element-citation><mixed-citation id="mc-CR7" publication-type="journal">Tracy, J. L. &amp; Randles, D. Four models of basic emotions: A review of Ekman and Cordaro, Izard, Levenson, and Panksepp and Watt. <italic toggle="yes">Emot. Rev.</italic><bold>3</bold>, 397&#8211;405 (2011).</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Boissy, A. &amp; Erhard, H.&#160;W. How studying interactions between animal emotions, cognition, and personality can contribute to improve farm animal welfare. In <italic toggle="yes">Genetics and the Behavior of Domestic Animals</italic>. 95&#8211;129 (Elsevier, 2014).</mixed-citation></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Moors</surname><given-names>A</given-names></name><name name-style="western"><surname>Ellsworth</surname><given-names>PC</given-names></name><name name-style="western"><surname>Scherer</surname><given-names>KR</given-names></name><name name-style="western"><surname>Frijda</surname><given-names>NH</given-names></name></person-group><article-title>Appraisal theories of emotion: State of the art and future development</article-title><source>Emot. Rev.</source><year>2013</year><volume>5</volume><fpage>119</fpage><lpage>124</lpage></element-citation><mixed-citation id="mc-CR9" publication-type="journal">Moors, A., Ellsworth, P. C., Scherer, K. R. &amp; Frijda, N. H. Appraisal theories of emotion: State of the art and future development. <italic toggle="yes">Emot. Rev.</italic><bold>5</bold>, 119&#8211;124 (2013).</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Panksepp</surname><given-names>J</given-names></name></person-group><article-title>The basic emotional circuits of mammalian brains: Do animals have affective lives?</article-title><source>Neurosci. Biobehav. Rev.</source><year>2011</year><volume>35</volume><fpage>1791</fpage><lpage>1804</lpage><pub-id pub-id-type="pmid">21872619</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neubiorev.2011.08.003</pub-id></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Panksepp, J. The basic emotional circuits of mammalian brains: Do animals have affective lives?. <italic toggle="yes">Neurosci. Biobehav. Rev.</italic><bold>35</bold>, 1791&#8211;1804 (2011).<pub-id pub-id-type="pmid">21872619</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neubiorev.2011.08.003</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="other">Duncan, I.&#160;J. A concept of welfare based on feelings. <italic toggle="yes">The Well-Being of Farm Animals: Challenges and Solutions</italic>. 85&#8211;101 (2004).</mixed-citation></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fraser</surname><given-names>D</given-names></name></person-group><article-title>Understanding animal welfare</article-title><source>Acta Vet. Scand.</source><year>2008</year><volume>50</volume><fpage>S1</fpage><pub-id pub-id-type="pmid">19049678</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1186/1751-0147-50-S1-S1</pub-id><pub-id pub-id-type="pmcid">PMC4235121</pub-id></element-citation><mixed-citation id="mc-CR12" publication-type="journal">Fraser, D. Understanding animal welfare. <italic toggle="yes">Acta Vet. Scand.</italic><bold>50</bold>, S1 (2008).<pub-id pub-id-type="pmid">19049678</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1186/1751-0147-50-S1-S1</pub-id><pub-id pub-id-type="pmcid">PMC4235121</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dawkins</surname><given-names>MS</given-names></name></person-group><article-title>The science of animal suffering</article-title><source>Ethology</source><year>2008</year><volume>114</volume><fpage>937</fpage><lpage>945</lpage></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Dawkins, M. S. The science of animal suffering. <italic toggle="yes">Ethology</italic><bold>114</bold>, 937&#8211;945 (2008).</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mendl</surname><given-names>M</given-names></name><name name-style="western"><surname>Burman</surname><given-names>OH</given-names></name><name name-style="western"><surname>Paul</surname><given-names>ES</given-names></name></person-group><article-title>An integrative and functional framework for the study of animal emotion and mood</article-title><source>Proc. R. Soc. B Biol. Sci.</source><year>2010</year><volume>277</volume><fpage>2895</fpage><lpage>2904</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1098/rspb.2010.0303</pub-id><pub-id pub-id-type="pmcid">PMC2982018</pub-id><pub-id pub-id-type="pmid">20685706</pub-id></element-citation><mixed-citation id="mc-CR14" publication-type="journal">Mendl, M., Burman, O. H. &amp; Paul, E. S. An integrative and functional framework for the study of animal emotion and mood. <italic toggle="yes">Proc. R. Soc. B Biol. Sci.</italic><bold>277</bold>, 2895&#8211;2904 (2010).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1098/rspb.2010.0303</pub-id><pub-id pub-id-type="pmcid">PMC2982018</pub-id><pub-id pub-id-type="pmid">20685706</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Bremhorst, A., Mills, D., W&#252;rbel, H. &amp; Riemer, S. Evaluating the accuracy of facial expressions as emotion indicators across contexts in dogs. <italic toggle="yes">Anim. Cognit.</italic> 1&#8211;16 (2021).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s10071-021-01532-1</pub-id><pub-id pub-id-type="pmcid">PMC8904359</pub-id><pub-id pub-id-type="pmid">34338869</pub-id></mixed-citation></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>G&#228;hwiler</surname><given-names>S</given-names></name><name name-style="western"><surname>Bremhorst</surname><given-names>A</given-names></name><name name-style="western"><surname>T&#243;th</surname><given-names>K</given-names></name><name name-style="western"><surname>Riemer</surname><given-names>S</given-names></name></person-group><article-title>Fear expressions of dogs during new year fireworks: A video analysis</article-title><source>Sci. Rep.</source><year>2020</year><volume>10</volume><fpage>16035</fpage><pub-id pub-id-type="pmid">32994423</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-020-72841-7</pub-id><pub-id pub-id-type="pmcid">PMC7525486</pub-id></element-citation><mixed-citation id="mc-CR16" publication-type="journal">G&#228;hwiler, S., Bremhorst, A., T&#243;th, K. &amp; Riemer, S. Fear expressions of dogs during new year fireworks: A video analysis. <italic toggle="yes">Sci. Rep.</italic><bold>10</bold>, 16035 (2020).<pub-id pub-id-type="pmid">32994423</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-020-72841-7</pub-id><pub-id pub-id-type="pmcid">PMC7525486</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Riemer</surname><given-names>S</given-names></name></person-group><article-title>Not a one-way road&#8212;Severity, progression and prevention of firework fears in dogs</article-title><source>PLoS One</source><year>2019</year><volume>14</volume><fpage>e0218150</fpage><pub-id pub-id-type="pmid">31490926</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0218150</pub-id><pub-id pub-id-type="pmcid">PMC6730926</pub-id></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Riemer, S. Not a one-way road&#8212;Severity, progression and prevention of firework fears in dogs. <italic toggle="yes">PLoS One</italic><bold>14</bold>, e0218150 (2019).<pub-id pub-id-type="pmid">31490926</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0218150</pub-id><pub-id pub-id-type="pmcid">PMC6730926</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Riemer</surname><given-names>S</given-names></name></person-group><article-title>Effectiveness of treatments for firework fears in dogs</article-title><source>J. Vet. Behav.</source><year>2020</year><volume>37</volume><fpage>61</fpage><lpage>70</lpage></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Riemer, S. Effectiveness of treatments for firework fears in dogs. <italic toggle="yes">J. Vet. Behav.</italic><bold>37</bold>, 61&#8211;70 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Riemer</surname><given-names>S</given-names></name></person-group><article-title>Therapy and prevention of noise fears in dogs&#8212;A review of the current evidence for practitioners</article-title><source>Animals</source><year>2023</year><volume>13</volume><fpage>3664</fpage><pub-id pub-id-type="pmid">38067015</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/ani13233664</pub-id><pub-id pub-id-type="pmcid">PMC10705068</pub-id></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Riemer, S. Therapy and prevention of noise fears in dogs&#8212;A review of the current evidence for practitioners. <italic toggle="yes">Animals</italic><bold>13</bold>, 3664 (2023).<pub-id pub-id-type="pmid">38067015</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/ani13233664</pub-id><pub-id pub-id-type="pmcid">PMC10705068</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Blackwell</surname><given-names>EJ</given-names></name><name name-style="western"><surname>Bradshaw</surname><given-names>JW</given-names></name><name name-style="western"><surname>Casey</surname><given-names>RA</given-names></name></person-group><article-title>Fear responses to noises in domestic dogs: Prevalence, risk factors and co-occurrence with other fear related behaviour</article-title><source>Appl. Anim. Behav. Sci.</source><year>2013</year><volume>145</volume><fpage>15</fpage><lpage>25</lpage></element-citation><mixed-citation id="mc-CR20" publication-type="journal">Blackwell, E. J., Bradshaw, J. W. &amp; Casey, R. A. Fear responses to noises in domestic dogs: Prevalence, risk factors and co-occurrence with other fear related behaviour. <italic toggle="yes">Appl. Anim. Behav. Sci.</italic><bold>145</bold>, 15&#8211;25 (2013).</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dale</surname><given-names>A</given-names></name><name name-style="western"><surname>Walker</surname><given-names>J</given-names></name><name name-style="western"><surname>Farnworth</surname><given-names>M</given-names></name><name name-style="western"><surname>Morrissey</surname><given-names>S</given-names></name><name name-style="western"><surname>Waran</surname><given-names>N</given-names></name></person-group><article-title>A survey of owners&#8217; perceptions of fear of fireworks in a sample of dogs and cats in New Zealand</article-title><source>N. Z. Vet. J.</source><year>2010</year><volume>58</volume><fpage>286</fpage><lpage>291</lpage><pub-id pub-id-type="pmid">21151214</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1080/00480169.2010.69403</pub-id></element-citation><mixed-citation id="mc-CR21" publication-type="journal">Dale, A., Walker, J., Farnworth, M., Morrissey, S. &amp; Waran, N. A survey of owners&#8217; perceptions of fear of fireworks in a sample of dogs and cats in New Zealand. <italic toggle="yes">N. Z. Vet. J.</italic><bold>58</bold>, 286&#8211;291 (2010).<pub-id pub-id-type="pmid">21151214</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1080/00480169.2010.69403</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stellato</surname><given-names>AC</given-names></name><name name-style="western"><surname>Flint</surname><given-names>HE</given-names></name><name name-style="western"><surname>Widowski</surname><given-names>TM</given-names></name><name name-style="western"><surname>Serpell</surname><given-names>JA</given-names></name><name name-style="western"><surname>Niel</surname><given-names>L</given-names></name></person-group><article-title>Assessment of fear-related behaviours displayed by companion dogs (Canis familiaris) in response to social and non-social stimuli</article-title><source>Appl. Anim. Behav. Sci.</source><year>2017</year><volume>188</volume><fpage>84</fpage><lpage>90</lpage></element-citation><mixed-citation id="mc-CR22" publication-type="journal">Stellato, A. C., Flint, H. E., Widowski, T. M., Serpell, J. A. &amp; Niel, L. Assessment of fear-related behaviours displayed by companion dogs (Canis familiaris) in response to social and non-social stimuli. <italic toggle="yes">Appl. Anim. Behav. Sci.</italic><bold>188</bold>, 84&#8211;90 (2017).</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Flint</surname><given-names>HE</given-names></name><name name-style="western"><surname>Coe</surname><given-names>JB</given-names></name><name name-style="western"><surname>Serpell</surname><given-names>JA</given-names></name><name name-style="western"><surname>Pearl</surname><given-names>DL</given-names></name><name name-style="western"><surname>Niel</surname><given-names>L</given-names></name></person-group><article-title>Identification of fear behaviors shown by puppies in response to nonsocial stimuli</article-title><source>J. Vet. Behav.</source><year>2018</year><volume>28</volume><fpage>17</fpage><lpage>24</lpage></element-citation><mixed-citation id="mc-CR23" publication-type="journal">Flint, H. E., Coe, J. B., Serpell, J. A., Pearl, D. L. &amp; Niel, L. Identification of fear behaviors shown by puppies in response to nonsocial stimuli. <italic toggle="yes">J. Vet. Behav.</italic><bold>28</bold>, 17&#8211;24 (2018).</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mota-Rojas</surname><given-names>D</given-names></name><etal/></person-group><article-title>How facial expressions reveal acute pain in domestic animals with facial pain scales as a diagnostic tool</article-title><source>Front. Vet. Sci.</source><year>2025</year><volume>12</volume><fpage>1546719</fpage><pub-id pub-id-type="pmid">40104548</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/fvets.2025.1546719</pub-id><pub-id pub-id-type="pmcid">PMC11913824</pub-id></element-citation><mixed-citation id="mc-CR24" publication-type="journal">Mota-Rojas, D. et al. How facial expressions reveal acute pain in domestic animals with facial pain scales as a diagnostic tool. <italic toggle="yes">Front. Vet. Sci.</italic><bold>12</bold>, 1546719 (2025).<pub-id pub-id-type="pmid">40104548</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/fvets.2025.1546719</pub-id><pub-id pub-id-type="pmcid">PMC11913824</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dalla Costa</surname><given-names>E</given-names></name><etal/></person-group><article-title>Development of the horse grimace scale (HGS) as a pain assessment tool in horses undergoing routine castration</article-title><source>PLOS ONE</source><year>2014</year><volume>9</volume><fpage>e92281</fpage><pub-id pub-id-type="pmid">24647606</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0092281</pub-id><pub-id pub-id-type="pmcid">PMC3960217</pub-id></element-citation><mixed-citation id="mc-CR25" publication-type="journal">Dalla Costa, E. et al. Development of the horse grimace scale (HGS) as a pain assessment tool in horses undergoing routine castration. <italic toggle="yes">PLOS ONE</italic><bold>9</bold>, e92281 (2014).<pub-id pub-id-type="pmid">24647606</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0092281</pub-id><pub-id pub-id-type="pmcid">PMC3960217</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wathan</surname><given-names>J</given-names></name><name name-style="western"><surname>Burrows</surname><given-names>AM</given-names></name><name name-style="western"><surname>Waller</surname><given-names>BM</given-names></name><name name-style="western"><surname>McComb</surname><given-names>K</given-names></name></person-group><article-title>Equifacs: The equine facial action coding system</article-title><source>PLOS ONE</source><year>2015</year><volume>10</volume><fpage>e0131738</fpage><pub-id pub-id-type="pmid">26244573</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0131738</pub-id><pub-id pub-id-type="pmcid">PMC4526551</pub-id></element-citation><mixed-citation id="mc-CR26" publication-type="journal">Wathan, J., Burrows, A. M., Waller, B. M. &amp; McComb, K. Equifacs: The equine facial action coding system. <italic toggle="yes">PLOS ONE</italic><bold>10</bold>, e0131738 (2015).<pub-id pub-id-type="pmid">26244573</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0131738</pub-id><pub-id pub-id-type="pmcid">PMC4526551</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bennett</surname><given-names>V</given-names></name><name name-style="western"><surname>Gourkow</surname><given-names>N</given-names></name><name name-style="western"><surname>Mills</surname><given-names>DS</given-names></name></person-group><article-title>Facial correlates of emotional behaviour in the domestic cat (Felis catus)</article-title><source>Behav. Process.</source><year>2017</year><volume>141</volume><fpage>342</fpage><lpage>350</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.beproc.2017.03.011</pub-id><pub-id pub-id-type="pmid">28341145</pub-id></element-citation><mixed-citation id="mc-CR27" publication-type="journal">Bennett, V., Gourkow, N. &amp; Mills, D. S. Facial correlates of emotional behaviour in the domestic cat (Felis catus). <italic toggle="yes">Behav. Process.</italic><bold>141</bold>, 342&#8211;350 (2017).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.beproc.2017.03.011</pub-id><pub-id pub-id-type="pmid">28341145</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bremhorst</surname><given-names>A</given-names></name><name name-style="western"><surname>Sutter</surname><given-names>NA</given-names></name><name name-style="western"><surname>W&#252;rbel</surname><given-names>H</given-names></name><name name-style="western"><surname>Mills</surname><given-names>DS</given-names></name><name name-style="western"><surname>Riemer</surname><given-names>S</given-names></name></person-group><article-title>Differences in facial expressions during positive anticipation and frustration in dogs awaiting a reward</article-title><source>Sci. Rep.</source><year>2019</year><volume>9</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="pmid">31848389</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-019-55714-6</pub-id><pub-id pub-id-type="pmcid">PMC6917793</pub-id></element-citation><mixed-citation id="mc-CR28" publication-type="journal">Bremhorst, A., Sutter, N. A., W&#252;rbel, H., Mills, D. S. &amp; Riemer, S. Differences in facial expressions during positive anticipation and frustration in dogs awaiting a reward. <italic toggle="yes">Sci. Rep.</italic><bold>9</bold>, 1&#8211;13 (2019).<pub-id pub-id-type="pmid">31848389</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-019-55714-6</pub-id><pub-id pub-id-type="pmcid">PMC6917793</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Boissy</surname><given-names>A</given-names></name><etal/></person-group><article-title>Cognitive sciences to relate ear postures to emotions in sheep</article-title><source>Anim. Welfare</source><year>2011</year><volume>20</volume><fpage>47</fpage><lpage>56</lpage></element-citation><mixed-citation id="mc-CR29" publication-type="journal">Boissy, A. et al. Cognitive sciences to relate ear postures to emotions in sheep. <italic toggle="yes">Anim. Welfare</italic><bold>20</bold>, 47&#8211;56 (2011).</mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Battini</surname><given-names>M</given-names></name><name name-style="western"><surname>Agostini</surname><given-names>A</given-names></name><name name-style="western"><surname>Mattiello</surname><given-names>S</given-names></name></person-group><article-title>Understanding cows&#8217; emotions on farm: Are eye white and ear posture reliable indicators?</article-title><source>Animals</source><year>2019</year><volume>9</volume><fpage>477</fpage><pub-id pub-id-type="pmid">31344842</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/ani9080477</pub-id><pub-id pub-id-type="pmcid">PMC6720764</pub-id></element-citation><mixed-citation id="mc-CR30" publication-type="journal">Battini, M., Agostini, A. &amp; Mattiello, S. Understanding cows&#8217; emotions on farm: Are eye white and ear posture reliable indicators?. <italic toggle="yes">Animals</italic><bold>9</bold>, 477 (2019).<pub-id pub-id-type="pmid">31344842</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/ani9080477</pub-id><pub-id pub-id-type="pmcid">PMC6720764</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lambert</surname><given-names>H</given-names></name><name name-style="western"><surname>Carder</surname><given-names>G</given-names></name></person-group><article-title>Positive and negative emotions in dairy cows: Can ear postures be used as a measure?</article-title><source>Behav. Process.</source><year>2019</year><volume>158</volume><fpage>172</fpage><lpage>180</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.beproc.2018.12.007</pub-id><pub-id pub-id-type="pmid">30543843</pub-id></element-citation><mixed-citation id="mc-CR31" publication-type="journal">Lambert, H. &amp; Carder, G. Positive and negative emotions in dairy cows: Can ear postures be used as a measure?. <italic toggle="yes">Behav. Process.</italic><bold>158</bold>, 172&#8211;180 (2019).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.beproc.2018.12.007</pub-id><pub-id pub-id-type="pmid">30543843</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR32"><label>32.</label><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bremhorst</surname><given-names>A</given-names></name><name name-style="western"><surname>Mills</surname><given-names>D</given-names></name><name name-style="western"><surname>W&#252;rbel</surname><given-names>H</given-names></name><name name-style="western"><surname>Riemer</surname><given-names>S</given-names></name></person-group><article-title>Evaluating the accuracy of facial expressions as emotion indicators across contexts in dogs</article-title><source>Anim. Cognit.</source><year>2022</year><volume>25</volume><fpage>121</fpage><lpage>136</lpage><pub-id pub-id-type="pmid">34338869</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s10071-021-01532-1</pub-id><pub-id pub-id-type="pmcid">PMC8904359</pub-id></element-citation><mixed-citation id="mc-CR32" publication-type="journal">Bremhorst, A., Mills, D., W&#252;rbel, H. &amp; Riemer, S. Evaluating the accuracy of facial expressions as emotion indicators across contexts in dogs. <italic toggle="yes">Anim. Cognit.</italic><bold>25</bold>, 121&#8211;136 (2022).<pub-id pub-id-type="pmid">34338869</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s10071-021-01532-1</pub-id><pub-id pub-id-type="pmcid">PMC8904359</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR33"><label>33.</label><citation-alternatives><element-citation id="ec-CR33" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dolensek</surname><given-names>N</given-names></name><name name-style="western"><surname>Gehrlach</surname><given-names>DA</given-names></name><name name-style="western"><surname>Klein</surname><given-names>AS</given-names></name><name name-style="western"><surname>Gogolla</surname><given-names>N</given-names></name></person-group><article-title>Facial expressions of emotion states and their neuronal correlates in mice</article-title><source>Science</source><year>2020</year><volume>368</volume><fpage>89</fpage><lpage>94</lpage><pub-id pub-id-type="pmid">32241948</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1126/science.aaz9468</pub-id></element-citation><mixed-citation id="mc-CR33" publication-type="journal">Dolensek, N., Gehrlach, D. A., Klein, A. S. &amp; Gogolla, N. Facial expressions of emotion states and their neuronal correlates in mice. <italic toggle="yes">Science</italic><bold>368</bold>, 89&#8211;94 (2020).<pub-id pub-id-type="pmid">32241948</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1126/science.aaz9468</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">Ekman, P. &amp; Keltner, D. Universal facial expressions of emotion. In <italic toggle="yes"> Nonverbal Communication: Where Nature Meets Culture</italic> (Segerstrale, U. &amp; Molnar, P. eds.) . Vol. 27. 46 (1997).</mixed-citation></ref><ref id="CR35"><label>35.</label><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Russell</surname><given-names>JA</given-names></name><name name-style="western"><surname>Bachorowski</surname><given-names>J-A</given-names></name><name name-style="western"><surname>Fern&#225;ndez-Dols</surname><given-names>J-M</given-names></name></person-group><article-title>Facial and vocal expressions of emotion</article-title><source>Annu. Rev. Psychol.</source><year>2003</year><volume>54</volume><fpage>329</fpage><lpage>349</lpage><pub-id pub-id-type="pmid">12415074</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1146/annurev.psych.54.101601.145102</pub-id></element-citation><mixed-citation id="mc-CR35" publication-type="journal">Russell, J. A., Bachorowski, J.-A. &amp; Fern&#225;ndez-Dols, J.-M. Facial and vocal expressions of emotion. <italic toggle="yes">Annu. Rev. Psychol.</italic><bold>54</bold>, 329&#8211;349 (2003).<pub-id pub-id-type="pmid">12415074</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1146/annurev.psych.54.101601.145102</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR36"><label>36.</label><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wolf</surname><given-names>K</given-names></name></person-group><article-title>Measuring facial expression of emotion</article-title><source>Dial. Clin. Neurosci.</source><year>2015</year><volume>17</volume><fpage>457</fpage><lpage>462</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.31887/DCNS.2015.17.4/kwolf</pub-id><pub-id pub-id-type="pmcid">PMC4734883</pub-id><pub-id pub-id-type="pmid">26869846</pub-id></element-citation><mixed-citation id="mc-CR36" publication-type="journal">Wolf, K. Measuring facial expression of emotion. <italic toggle="yes">Dial. Clin. Neurosci.</italic><bold>17</bold>, 457&#8211;462 (2015).<pub-id pub-id-type="doi" assigning-authority="pmc">10.31887/DCNS.2015.17.4/kwolf</pub-id><pub-id pub-id-type="pmcid">PMC4734883</pub-id><pub-id pub-id-type="pmid">26869846</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR37"><label>37.</label><citation-alternatives><element-citation id="ec-CR37" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hess</surname><given-names>U</given-names></name><name name-style="western"><surname>Thibault</surname><given-names>P</given-names></name></person-group><article-title>Darwin and emotion expression</article-title><source>Am. Psychol.</source><year>2009</year><volume>64</volume><fpage>120</fpage><pub-id pub-id-type="pmid">19203144</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1037/a0013386</pub-id></element-citation><mixed-citation id="mc-CR37" publication-type="journal">Hess, U. &amp; Thibault, P. Darwin and emotion expression. <italic toggle="yes">Am. Psychol.</italic><bold>64</bold>, 120 (2009).<pub-id pub-id-type="pmid">19203144</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1037/a0013386</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="other">Descovich, K.&#160;A. et al. Facial expression: An under-utilised tool for the assessment of welfare in mammals. <italic toggle="yes">Altex</italic> (2017).<pub-id pub-id-type="doi" assigning-authority="pmc">10.14573/altex.1607161</pub-id><pub-id pub-id-type="pmid">28214916</pub-id></mixed-citation></ref><ref id="CR39"><label>39.</label><citation-alternatives><element-citation id="ec-CR39" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mota-Rojas</surname><given-names>D</given-names></name><etal/></person-group><article-title>Current advances in assessment of dog&#8217;s emotions, facial expressions, and their use for clinical recognition of pain</article-title><source>Animals</source><year>2021</year><volume>11</volume><fpage>3334</fpage><pub-id pub-id-type="pmid">34828066</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/ani11113334</pub-id><pub-id pub-id-type="pmcid">PMC8614696</pub-id></element-citation><mixed-citation id="mc-CR39" publication-type="journal">Mota-Rojas, D. et al. Current advances in assessment of dog&#8217;s emotions, facial expressions, and their use for clinical recognition of pain. <italic toggle="yes">Animals</italic><bold>11</bold>, 3334 (2021).<pub-id pub-id-type="pmid">34828066</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/ani11113334</pub-id><pub-id pub-id-type="pmcid">PMC8614696</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">Ekman, P. &amp; Friesen, W. Facial action coding system: A technique for the measurement of facial movement. <italic toggle="yes">Environ. Psychol. Nonverb. Behav.</italic> (1978).</mixed-citation></ref><ref id="CR41"><label>41.</label><citation-alternatives><element-citation id="ec-CR41" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Waller</surname><given-names>B</given-names></name><name name-style="western"><surname>Julle-Daniere</surname><given-names>E</given-names></name><name name-style="western"><surname>Micheletta</surname><given-names>J</given-names></name></person-group><article-title>Measuring the evolution of facial &#8216;expression&#8217; using multi-species facs</article-title><source>Neurosci. Biobehav. Rev.</source><year>2020</year><volume>113</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmid">32105704</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neubiorev.2020.02.031</pub-id></element-citation><mixed-citation id="mc-CR41" publication-type="journal">Waller, B., Julle-Daniere, E. &amp; Micheletta, J. Measuring the evolution of facial &#8216;expression&#8217; using multi-species facs. <italic toggle="yes">Neurosci. Biobehav. Rev.</italic><bold>113</bold>, 1&#8211;11 (2020).<pub-id pub-id-type="pmid">32105704</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neubiorev.2020.02.031</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR42"><label>42.</label><citation-alternatives><element-citation id="ec-CR42" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Caeiro</surname><given-names>C</given-names></name><name name-style="western"><surname>Waller</surname><given-names>B</given-names></name><name name-style="western"><surname>Zimmerman</surname><given-names>E</given-names></name><name name-style="western"><surname>Burrows</surname><given-names>A</given-names></name><name name-style="western"><surname>Davila Ross</surname><given-names>M</given-names></name></person-group><article-title>Orangfacs: A muscle-based movement coding system for facial communication in orangutans</article-title><source>Int. J. Primatol.</source><year>2013</year><volume>34</volume><fpage>115</fpage><lpage>129</lpage></element-citation><mixed-citation id="mc-CR42" publication-type="journal">Caeiro, C., Waller, B., Zimmerman, E., Burrows, A. &amp; Davila Ross, M. Orangfacs: A muscle-based movement coding system for facial communication in orangutans. <italic toggle="yes">Int. J. Primatol.</italic><bold>34</bold>, 115&#8211;129 (2013).</mixed-citation></citation-alternatives></ref><ref id="CR43"><label>43.</label><citation-alternatives><element-citation id="ec-CR43" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Parr</surname><given-names>LA</given-names></name><name name-style="western"><surname>Waller</surname><given-names>BM</given-names></name><name name-style="western"><surname>Vick</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Bard</surname><given-names>KA</given-names></name></person-group><article-title>Classifying chimpanzee facial expressions using muscle action</article-title><source>Emotion</source><year>2007</year><volume>7</volume><fpage>172</fpage><pub-id pub-id-type="pmid">17352572</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1037/1528-3542.7.1.172</pub-id><pub-id pub-id-type="pmcid">PMC2826116</pub-id></element-citation><mixed-citation id="mc-CR43" publication-type="journal">Parr, L. A., Waller, B. M., Vick, S. J. &amp; Bard, K. A. Classifying chimpanzee facial expressions using muscle action. <italic toggle="yes">Emotion</italic><bold>7</bold>, 172 (2007).<pub-id pub-id-type="pmid">17352572</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1037/1528-3542.7.1.172</pub-id><pub-id pub-id-type="pmcid">PMC2826116</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR44"><label>44.</label><citation-alternatives><element-citation id="ec-CR44" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Clark</surname><given-names>PR</given-names></name><etal/></person-group><article-title>Morphological variants of silent bared-teeth displays have different social interaction outcomes in crested macaques (Macaca nigra)</article-title><source>Am. J. Phys. Anthropol.</source><year>2020</year><volume>173</volume><fpage>411</fpage><lpage>422</lpage><pub-id pub-id-type="pmid">32820559</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/ajpa.24129</pub-id></element-citation><mixed-citation id="mc-CR44" publication-type="journal">Clark, P. R. et al. Morphological variants of silent bared-teeth displays have different social interaction outcomes in crested macaques (Macaca nigra). <italic toggle="yes">Am. J. Phys. Anthropol.</italic><bold>173</bold>, 411&#8211;422 (2020).<pub-id pub-id-type="pmid">32820559</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/ajpa.24129</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR45"><label>45.</label><citation-alternatives><element-citation id="ec-CR45" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Correia-Caeiro</surname><given-names>C</given-names></name><name name-style="western"><surname>Holmes</surname><given-names>K</given-names></name><name name-style="western"><surname>Miyabe-Nishiwaki</surname><given-names>T</given-names></name></person-group><article-title>Extending the MaqFACS to measure facial movement in Japanese macaques (Macaca fuscata) reveals a wide repertoire potential</article-title><source>PLOS ONE</source><year>2021</year><volume>16</volume><fpage>e0245117</fpage><pub-id pub-id-type="pmid">33411716</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0245117</pub-id><pub-id pub-id-type="pmcid">PMC7790396</pub-id></element-citation><mixed-citation id="mc-CR45" publication-type="journal">Correia-Caeiro, C., Holmes, K. &amp; Miyabe-Nishiwaki, T. Extending the MaqFACS to measure facial movement in Japanese macaques (Macaca fuscata) reveals a wide repertoire potential. <italic toggle="yes">PLOS ONE</italic><bold>16</bold>, e0245117 (2021).<pub-id pub-id-type="pmid">33411716</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0245117</pub-id><pub-id pub-id-type="pmcid">PMC7790396</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR46"><label>46.</label><citation-alternatives><element-citation id="ec-CR46" publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Waller</surname><given-names>B</given-names></name><etal/></person-group><source>DogFACS: The Dog Facial Action Coding System</source><year>2013</year><publisher-name>University of Portsmouth</publisher-name></element-citation><mixed-citation id="mc-CR46" publication-type="book">Waller, B. et al. <italic toggle="yes">DogFACS: The Dog Facial Action Coding System</italic> (University of Portsmouth, 2013).</mixed-citation></citation-alternatives></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="other">Caeiro, C.&#160;C., Burrows, A.&#160;M. &amp; Waller, B.&#160;M. Development and application of catfacs: Are human cat adopters influenced by cat facial expressions? <italic toggle="yes">Appl. Anim. Behav. Sci.</italic> (2017).</mixed-citation></ref><ref id="CR48"><label>48.</label><citation-alternatives><element-citation id="ec-CR48" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Georgevsky</surname><given-names>D</given-names></name><name name-style="western"><surname>Carrasco</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Valenzuela</surname><given-names>M</given-names></name><name name-style="western"><surname>McGreevy</surname><given-names>PD</given-names></name></person-group><article-title>Domestic dog skull diversity across breeds, breed groupings, and genetic clusters</article-title><source>J. Vet. Behav.</source><year>2014</year><volume>9</volume><fpage>228</fpage><lpage>234</lpage></element-citation><mixed-citation id="mc-CR48" publication-type="journal">Georgevsky, D., Carrasco, J. J., Valenzuela, M. &amp; McGreevy, P. D. Domestic dog skull diversity across breeds, breed groupings, and genetic clusters. <italic toggle="yes">J. Vet. Behav.</italic><bold>9</bold>, 228&#8211;234 (2014).</mixed-citation></citation-alternatives></ref><ref id="CR49"><label>49.</label><citation-alternatives><element-citation id="ec-CR49" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Drake</surname><given-names>AG</given-names></name><name name-style="western"><surname>Klingenberg</surname><given-names>CP</given-names></name></person-group><article-title>Large-scale diversification of skull shape in domestic dogs: Disparity and modularity</article-title><source>Am. Nat.</source><year>2010</year><volume>175</volume><fpage>289</fpage><lpage>301</lpage><pub-id pub-id-type="pmid">20095825</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1086/650372</pub-id></element-citation><mixed-citation id="mc-CR49" publication-type="journal">Drake, A. G. &amp; Klingenberg, C. P. Large-scale diversification of skull shape in domestic dogs: Disparity and modularity. <italic toggle="yes">Am. Nat.</italic><bold>175</bold>, 289&#8211;301 (2010).<pub-id pub-id-type="pmid">20095825</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1086/650372</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR50"><label>50.</label><citation-alternatives><element-citation id="ec-CR50" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Burrows</surname><given-names>AM</given-names></name><etal/></person-group><article-title>Dog faces exhibit anatomical differences in comparison to other domestic animals</article-title><source>Anat. Rec.</source><year>2021</year><volume>304</volume><fpage>231</fpage><lpage>241</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/ar.24507</pub-id><pub-id pub-id-type="pmid">32969196</pub-id></element-citation><mixed-citation id="mc-CR50" publication-type="journal">Burrows, A. M. et al. Dog faces exhibit anatomical differences in comparison to other domestic animals. <italic toggle="yes">Anat. Rec.</italic><bold>304</bold>, 231&#8211;241 (2021).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/ar.24507</pub-id><pub-id pub-id-type="pmid">32969196</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR51"><label>51.</label><citation-alternatives><element-citation id="ec-CR51" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hobkirk</surname><given-names>ER</given-names></name><name name-style="western"><surname>Twiss</surname><given-names>SD</given-names></name></person-group><article-title>Domestication constrains the ability of dogs to convey emotions via facial expressions in comparison to their wolf ancestors</article-title><source>Sci. Rep.</source><year>2024</year><volume>14</volume><fpage>10491</fpage><pub-id pub-id-type="pmid">38714729</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-024-61110-6</pub-id><pub-id pub-id-type="pmcid">PMC11076640</pub-id></element-citation><mixed-citation id="mc-CR51" publication-type="journal">Hobkirk, E. R. &amp; Twiss, S. D. Domestication constrains the ability of dogs to convey emotions via facial expressions in comparison to their wolf ancestors. <italic toggle="yes">Sci. Rep.</italic><bold>14</bold>, 10491 (2024).<pub-id pub-id-type="pmid">38714729</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-024-61110-6</pub-id><pub-id pub-id-type="pmcid">PMC11076640</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR52"><label>52.</label><citation-alternatives><element-citation id="ec-CR52" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Caeiro</surname><given-names>C</given-names></name><name name-style="western"><surname>Guo</surname><given-names>K</given-names></name><name name-style="western"><surname>Mills</surname><given-names>D</given-names></name></person-group><article-title>Dogs and humans respond to emotionally competent stimuli by producing different facial actions</article-title><source>Sci. Rep.</source><year>2017</year><volume>7</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmid">29138393</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-017-15091-4</pub-id><pub-id pub-id-type="pmcid">PMC5686192</pub-id></element-citation><mixed-citation id="mc-CR52" publication-type="journal">Caeiro, C., Guo, K. &amp; Mills, D. Dogs and humans respond to emotionally competent stimuli by producing different facial actions. <italic toggle="yes">Sci. Rep.</italic><bold>7</bold>, 1&#8211;11 (2017).<pub-id pub-id-type="pmid">29138393</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-017-15091-4</pub-id><pub-id pub-id-type="pmcid">PMC5686192</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR53"><label>53.</label><citation-alternatives><element-citation id="ec-CR53" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pedretti</surname><given-names>G</given-names></name><etal/></person-group><article-title>Audience effect on domestic dogs&#8217; behavioural displays and facial expressions</article-title><source>Sci. Rep.</source><year>2022</year><volume>12</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="pmid">35697913</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-022-13566-7</pub-id><pub-id pub-id-type="pmcid">PMC9192729</pub-id></element-citation><mixed-citation id="mc-CR53" publication-type="journal">Pedretti, G. et al. Audience effect on domestic dogs&#8217; behavioural displays and facial expressions. <italic toggle="yes">Sci. Rep.</italic><bold>12</bold>, 1&#8211;13 (2022).<pub-id pub-id-type="pmid">35697913</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-022-13566-7</pub-id><pub-id pub-id-type="pmcid">PMC9192729</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR54"><label>54.</label><citation-alternatives><element-citation id="ec-CR54" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sexton</surname><given-names>CL</given-names></name><etal/></person-group><article-title>What is written on a dog&#8217;s face? Evaluating the impact of facial phenotypes on communication between humans and canines</article-title><source>Animals</source><year>2023</year><volume>13</volume><fpage>2385</fpage><pub-id pub-id-type="pmid">37508162</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/ani13142385</pub-id><pub-id pub-id-type="pmcid">PMC10376741</pub-id></element-citation><mixed-citation id="mc-CR54" publication-type="journal">Sexton, C. L. et al. What is written on a dog&#8217;s face? Evaluating the impact of facial phenotypes on communication between humans and canines. <italic toggle="yes">Animals</italic><bold>13</bold>, 2385 (2023).<pub-id pub-id-type="pmid">37508162</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/ani13142385</pub-id><pub-id pub-id-type="pmcid">PMC10376741</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR55"><label>55.</label><citation-alternatives><element-citation id="ec-CR55" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hamm</surname><given-names>J</given-names></name><name name-style="western"><surname>Kohler</surname><given-names>CG</given-names></name><name name-style="western"><surname>Gur</surname><given-names>RC</given-names></name><name name-style="western"><surname>Verma</surname><given-names>R</given-names></name></person-group><article-title>Automated facial action coding system for dynamic analysis of facial expressions in neuropsychiatric disorders</article-title><source>J. Neurosci. Methods</source><year>2011</year><volume>200</volume><fpage>237</fpage><lpage>256</lpage><pub-id pub-id-type="pmid">21741407</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jneumeth.2011.06.023</pub-id><pub-id pub-id-type="pmcid">PMC3402717</pub-id></element-citation><mixed-citation id="mc-CR55" publication-type="journal">Hamm, J., Kohler, C. G., Gur, R. C. &amp; Verma, R. Automated facial action coding system for dynamic analysis of facial expressions in neuropsychiatric disorders. <italic toggle="yes">J. Neurosci. Methods</italic><bold>200</bold>, 237&#8211;256 (2011).<pub-id pub-id-type="pmid">21741407</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jneumeth.2011.06.023</pub-id><pub-id pub-id-type="pmcid">PMC3402717</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR56"><label>56.</label><mixed-citation publication-type="other">den Uyl, M.&#160;J. &amp; van Kuilenburg, H. The facereader: Online facial expression recognition. In <italic toggle="yes">Proceedings of Measuring Behavior</italic>. 589&#8211;590 (2005).</mixed-citation></ref><ref id="CR57"><label>57.</label><mixed-citation publication-type="other">iMotions. Affectiva imotions biometric research platform. <ext-link ext-link-type="uri" xlink:href="https://imotions.com/emotient/">https://imotions.com/emotient/</ext-link> (2015). Accessed 15 Apr 2025.</mixed-citation></ref><ref id="CR58"><label>58.</label><citation-alternatives><element-citation id="ec-CR58" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Boneh-Shitrit</surname><given-names>T</given-names></name><etal/></person-group><article-title>Explainable automated recognition of emotional states from canine facial expressions: The case of positive anticipation and frustration</article-title><source>Sci. Rep.</source><year>2022</year><volume>12</volume><fpage>22611</fpage><pub-id pub-id-type="pmid">36585439</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-022-27079-w</pub-id><pub-id pub-id-type="pmcid">PMC9803655</pub-id></element-citation><mixed-citation id="mc-CR58" publication-type="journal">Boneh-Shitrit, T. et al. Explainable automated recognition of emotional states from canine facial expressions: The case of positive anticipation and frustration. <italic toggle="yes">Sci. Rep.</italic><bold>12</bold>, 22611 (2022).<pub-id pub-id-type="pmid">36585439</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-022-27079-w</pub-id><pub-id pub-id-type="pmcid">PMC9803655</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR59"><label>59.</label><mixed-citation publication-type="other">He, K., Zhang, X., Ren, S. &amp; Sun, J. Deep residual learning for image recognition. In <italic toggle="yes">CVPR</italic> (2016).</mixed-citation></ref><ref id="CR60"><label>60.</label><mixed-citation publication-type="other">Dosovitskiy, A. et al. An image is worth 16x16 words: Transformers for image recognition at scale. In <italic toggle="yes">ICLR</italic> (2021).</mixed-citation></ref><ref id="CR61"><label>61.</label><mixed-citation publication-type="other">Birhane, A. The Unseen Black Faces of AI Algorithms (2022).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/d41586-022-03050-7</pub-id><pub-id pub-id-type="pmid">36261566</pub-id></mixed-citation></ref><ref id="CR62"><label>62.</label><citation-alternatives><element-citation id="ec-CR62" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Klare</surname><given-names>BF</given-names></name><name name-style="western"><surname>Burge</surname><given-names>MJ</given-names></name><name name-style="western"><surname>Klontz</surname><given-names>JC</given-names></name><name name-style="western"><surname>Bruegge</surname><given-names>RWV</given-names></name><name name-style="western"><surname>Jain</surname><given-names>AK</given-names></name></person-group><article-title>Face recognition performance: Role of demographic information</article-title><source>IEEE Trans. Inf. For. Secur.</source><year>2012</year><volume>7</volume><fpage>1789</fpage><lpage>1801</lpage></element-citation><mixed-citation id="mc-CR62" publication-type="journal">Klare, B. F., Burge, M. J., Klontz, J. C., Bruegge, R. W. V. &amp; Jain, A. K. Face recognition performance: Role of demographic information. <italic toggle="yes">IEEE Trans. Inf. For. Secur.</italic><bold>7</bold>, 1789&#8211;1801 (2012).</mixed-citation></citation-alternatives></ref><ref id="CR63"><label>63.</label><citation-alternatives><element-citation id="ec-CR63" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pessanha</surname><given-names>F</given-names></name><name name-style="western"><surname>Salah</surname><given-names>AA</given-names></name><name name-style="western"><surname>van Loon</surname><given-names>T</given-names></name><name name-style="western"><surname>Veltkamp</surname><given-names>R</given-names></name></person-group><article-title>Facial image-based automatic assessment of equine pain</article-title><source>IEEE Trans. Affect. Comput.</source><year>2022</year></element-citation><mixed-citation id="mc-CR63" publication-type="journal">Pessanha, F., Salah, A. A., van Loon, T. &amp; Veltkamp, R. Facial image-based automatic assessment of equine pain. <italic toggle="yes">IEEE Trans. Affect. Comput.</italic>10.1109/TAFFC.2022.3177639 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR64"><label>64.</label><mixed-citation publication-type="other">Liu, J., Kanazawa, A., Jacobs, D. &amp; Belhumeur, P. Dog breed classification using part localization. In <italic toggle="yes">Computer Vision&#8211;ECCV 2012: 12th European Conference on Computer Vision, Florence, Italy, October 7&#8211;13, 2012, Proceedings, Part I 12</italic>. 172&#8211;185 (Springer, 2012).</mixed-citation></ref><ref id="CR65"><label>65.</label><mixed-citation publication-type="other">Khan, M.&#160;H. et al. Animalweb: A large-scale hierarchical dataset of annotated animal faces. In <italic toggle="yes">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>. 6939&#8211;6948 (2020).</mixed-citation></ref><ref id="CR66"><label>66.</label><mixed-citation publication-type="other">Zhang, W., Sun, J. &amp; Tang, X. Cat head detection-how to effectively exploit shape and texture features. In <italic toggle="yes">Computer Vision&#8211;ECCV 2008: 10th European Conference on Computer Vision, Marseille, France, October 12-18, 2008, Proceedings, Part IV 10</italic>. 802&#8211;816 (Springer, 2008).</mixed-citation></ref><ref id="CR67"><label>67.</label><mixed-citation publication-type="other">Cao, J. et al. Cross-domain adaptation for animal pose estimation. In <italic toggle="yes">Proceedings of the IEEE/CVF International Conference on Computer Vision</italic>. 9498&#8211;9507 (2019).</mixed-citation></ref><ref id="CR68"><label>68.</label><mixed-citation publication-type="other">Coffman, E. et al. Cattleface-rgbt: Rgb-t cattle facial landmark benchmark. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2406.03431">arXiv:2406.03431</ext-link> (2024).</mixed-citation></ref><ref id="CR69"><label>69.</label><mixed-citation publication-type="other">Mougeot, G., Li, D. &amp; Jia, S. A deep learning approach for dog face verification and recognition. In <italic toggle="yes">PRICAI 2019: Trends in Artificial Intelligence: 16th Pacific Rim International Conference on Artificial Intelligence, Cuvu, Yanuca Island, Fiji, August 26-30, 2019, Proceedings, Part III 16</italic>. 418&#8211;430 (Springer, 2019).</mixed-citation></ref><ref id="CR70"><label>70.</label><mixed-citation publication-type="other">Sun, Y. &amp; Murata, N. Cafm: A 3D morphable model for animals. In <italic toggle="yes">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision Workshops</italic>. 20&#8211;24 (2020).</mixed-citation></ref><ref id="CR71"><label>71.</label><mixed-citation publication-type="other">Hewitt, C. &amp; Mahmoud, M. Pose-informed face alignment for extreme head pose variations in animals. In <italic toggle="yes">2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)</italic>. 1&#8211;6 (IEEE, 2019).</mixed-citation></ref><ref id="CR72"><label>72.</label><mixed-citation publication-type="other">Yang, H., Zhang, R. &amp; Robinson, P. Human and sheep facial landmarks localisation by triplet interpolated features. In <italic toggle="yes">2016 IEEE Winter Conference on Applications of Computer Vision (WACV)</italic>. 1&#8211;8 (IEEE, 2016).</mixed-citation></ref><ref id="CR73"><label>73.</label><citation-alternatives><element-citation id="ec-CR73" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mitteroecker</surname><given-names>P</given-names></name><name name-style="western"><surname>Gunz</surname><given-names>P</given-names></name></person-group><article-title>Advances in geometric morphometrics</article-title><source>Evolut. Biol.</source><year>2009</year><volume>36</volume><fpage>235</fpage><lpage>247</lpage></element-citation><mixed-citation id="mc-CR73" publication-type="journal">Mitteroecker, P. &amp; Gunz, P. Advances in geometric morphometrics. <italic toggle="yes">Evolut. Biol.</italic><bold>36</bold>, 235&#8211;247. 10.1007/s11692-009-9055-x (2009).</mixed-citation></citation-alternatives></ref><ref id="CR74"><label>74.</label><citation-alternatives><element-citation id="ec-CR74" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gower</surname><given-names>JC</given-names></name></person-group><article-title>Generalized procrustes analysis</article-title><source>Psychometrika</source><year>1975</year><volume>40</volume><fpage>33</fpage><lpage>51</lpage></element-citation><mixed-citation id="mc-CR74" publication-type="journal">Gower, J. C. Generalized procrustes analysis. <italic toggle="yes">Psychometrika</italic><bold>40</bold>, 33&#8211;51. 10.1007/BF02291478 (1975).</mixed-citation></citation-alternatives></ref><ref id="CR75"><label>75.</label><mixed-citation publication-type="other">Mitter&#246;cker, P. Morphometrics in evolutionary developmental biology. In <italic toggle="yes">Evolutionary Developmental Biology: A Reference Guide</italic> (Nu&#241;o de la Rosa, L. &amp; M&#252;ller, G.&#160;B. eds.). 941&#8211;951. 10.1007/978-3-319-33038-9_119 (Springer, 2021).</mixed-citation></ref><ref id="CR76"><label>76.</label><citation-alternatives><element-citation id="ec-CR76" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Holden</surname><given-names>E</given-names></name><etal/></person-group><article-title>Evaluation of facial expression in acute pain in cats</article-title><source>J. Small Anim. Pract.</source><year>2014</year><volume>55</volume><fpage>615</fpage><lpage>621</lpage><pub-id pub-id-type="pmid">25354833</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1111/jsap.12283</pub-id></element-citation><mixed-citation id="mc-CR76" publication-type="journal">Holden, E. et al. Evaluation of facial expression in acute pain in cats. <italic toggle="yes">J. Small Anim. Pract.</italic><bold>55</bold>, 615&#8211;621 (2014).<pub-id pub-id-type="pmid">25354833</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1111/jsap.12283</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR77"><label>77.</label><citation-alternatives><element-citation id="ec-CR77" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Finka</surname><given-names>LR</given-names></name><etal/></person-group><article-title>Geometric morphometrics for the study of facial expressions in non-human animals, using the domestic cat as an exemplar</article-title><source>Sci. Rep.</source><year>2019</year><volume>9</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmid">31285531</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-019-46330-5</pub-id><pub-id pub-id-type="pmcid">PMC6614427</pub-id></element-citation><mixed-citation id="mc-CR77" publication-type="journal">Finka, L. R. et al. Geometric morphometrics for the study of facial expressions in non-human animals, using the domestic cat as an exemplar. <italic toggle="yes">Sci. Rep.</italic><bold>9</bold>, 1&#8211;12 (2019).<pub-id pub-id-type="pmid">31285531</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-019-46330-5</pub-id><pub-id pub-id-type="pmcid">PMC6614427</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR78"><label>78.</label><citation-alternatives><element-citation id="ec-CR78" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gris</surname><given-names>VN</given-names></name><etal/></person-group><article-title>Author correction: Investigating subtle changes in facial expression to assess acute pain in Japanese macaques</article-title><source>Sci. Rep.</source><year>2023</year><volume>13</volume><fpage>12931</fpage><pub-id pub-id-type="pmid">37558672</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-023-40053-4</pub-id><pub-id pub-id-type="pmcid">PMC10412631</pub-id></element-citation><mixed-citation id="mc-CR78" publication-type="journal">Gris, V. N. et al. Author correction: Investigating subtle changes in facial expression to assess acute pain in Japanese macaques. <italic toggle="yes">Sci. Rep.</italic><bold>13</bold>, 12931. 10.1038/s41598-023-40053-4 (2023).<pub-id pub-id-type="pmid">37558672</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-023-40053-4</pub-id><pub-id pub-id-type="pmcid">PMC10412631</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR79"><label>79.</label><citation-alternatives><element-citation id="ec-CR79" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Martvel</surname><given-names>G</given-names></name><name name-style="western"><surname>Shimshoni</surname><given-names>I</given-names></name><name name-style="western"><surname>Zamansky</surname><given-names>A</given-names></name></person-group><article-title>Automated detection of cat facial landmarks</article-title><source>Int. J. Comput. Vis.</source><year>2024</year><volume>132</volume><fpage>3103</fpage><lpage>3118</lpage></element-citation><mixed-citation id="mc-CR79" publication-type="journal">Martvel, G., Shimshoni, I. &amp; Zamansky, A. Automated detection of cat facial landmarks. <italic toggle="yes">Int. J. Comput. Vis.</italic><bold>132</bold>, 3103&#8211;3118. 10.1007/s11263-024-02006-w (2024).</mixed-citation></citation-alternatives></ref><ref id="CR80"><label>80.</label><citation-alternatives><element-citation id="ec-CR80" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Martvel</surname><given-names>G</given-names></name><etal/></person-group><article-title>Automated video-based pain recognition in cats using facial landmarks</article-title><source>Sci. Rep.</source><year>2024</year><volume>14</volume><fpage>28006</fpage><pub-id pub-id-type="pmid">39543343</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-024-78406-2</pub-id><pub-id pub-id-type="pmcid">PMC11564822</pub-id></element-citation><mixed-citation id="mc-CR80" publication-type="journal">Martvel, G. et al. Automated video-based pain recognition in cats using facial landmarks. <italic toggle="yes">Sci. Rep.</italic><bold>14</bold>, 28006. 10.1038/s41598-024-78406-2 (2024).<pub-id pub-id-type="pmid">39543343</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-024-78406-2</pub-id><pub-id pub-id-type="pmcid">PMC11564822</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR81"><label>81.</label><citation-alternatives><element-citation id="ec-CR81" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Martvel</surname><given-names>G</given-names></name><etal/></person-group><article-title>Automated landmark-based cat facial analysis and its applications</article-title><source>Front. Vet. Sci.</source><year>2024</year><volume>11</volume><fpage>1442634</fpage><pub-id pub-id-type="pmid">39717789</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/fvets.2024.1442634</pub-id><pub-id pub-id-type="pmcid">PMC11663861</pub-id></element-citation><mixed-citation id="mc-CR81" publication-type="journal">Martvel, G. et al. Automated landmark-based cat facial analysis and its applications. <italic toggle="yes">Front. Vet. Sci.</italic><bold>11</bold>, 1442634. 10.3389/fvets.2024.1442634 (2024).<pub-id pub-id-type="pmid">39717789</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/fvets.2024.1442634</pub-id><pub-id pub-id-type="pmcid">PMC11663861</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR82"><label>82.</label><mixed-citation publication-type="other">Martvel, G. et al. Dogflw: Dog facial landmarks in the wild dataset. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2405.11501">arXiv:2405.11501</ext-link> (2024).</mixed-citation></ref><ref id="CR83"><label>83.</label><citation-alternatives><element-citation id="ec-CR83" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gruen</surname><given-names>ME</given-names></name><etal/></person-group><article-title>The use of an open-field model to assess sound-induced fear and anxiety-associated behaviors in labrador retrievers</article-title><source>J. Vet. Behav.</source><year>2015</year><volume>10</volume><fpage>338</fpage><lpage>345</lpage><pub-id pub-id-type="pmid">26273235</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jveb.2015.03.007</pub-id><pub-id pub-id-type="pmcid">PMC4530634</pub-id></element-citation><mixed-citation id="mc-CR83" publication-type="journal">Gruen, M. E. et al. The use of an open-field model to assess sound-induced fear and anxiety-associated behaviors in labrador retrievers. <italic toggle="yes">J. Vet. Behav.</italic><bold>10</bold>, 338&#8211;345. 10.1016/j.jveb.2015.03.007 (2015).<pub-id pub-id-type="pmid">26273235</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jveb.2015.03.007</pub-id><pub-id pub-id-type="pmcid">PMC4530634</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR84"><label>84.</label><citation-alternatives><element-citation id="ec-CR84" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sheppard</surname><given-names>G</given-names></name><name name-style="western"><surname>Mills</surname><given-names>DS</given-names></name></person-group><article-title>Evaluation of dog-appeasing pheromone as a potential treatment for dogs fearful of fireworks</article-title><source>Vet. Rec.</source><year>2003</year><volume>152</volume><fpage>432</fpage><lpage>436</lpage><pub-id pub-id-type="pmid">12708592</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1136/vr.152.14.432</pub-id></element-citation><mixed-citation id="mc-CR84" publication-type="journal">Sheppard, G. &amp; Mills, D. S. Evaluation of dog-appeasing pheromone as a potential treatment for dogs fearful of fireworks. <italic toggle="yes">Vet. Rec.</italic><bold>152</bold>, 432&#8211;436. 10.1136/vr.152.14.432 (2003).<pub-id pub-id-type="pmid">12708592</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1136/vr.152.14.432</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR85"><label>85.</label><citation-alternatives><element-citation id="ec-CR85" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dreschel</surname><given-names>NA</given-names></name><name name-style="western"><surname>Granger</surname><given-names>DA</given-names></name></person-group><article-title>Physiological and behavioral reactivity to stress in thunderstorm-phobic dogs and their caregivers</article-title><source>Appl. Anim. Behav. Sci.</source><year>2005</year><volume>95</volume><fpage>153</fpage><lpage>168</lpage></element-citation><mixed-citation id="mc-CR85" publication-type="journal">Dreschel, N. A. &amp; Granger, D. A. Physiological and behavioral reactivity to stress in thunderstorm-phobic dogs and their caregivers. <italic toggle="yes">Appl. Anim. Behav. Sci.</italic><bold>95</bold>, 153&#8211;168. 10.1016/j.applanim.2005.04.009 (2005).</mixed-citation></citation-alternatives></ref><ref id="CR86"><label>86.</label><citation-alternatives><element-citation id="ec-CR86" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Franzini de Souza</surname><given-names>CC</given-names></name><name name-style="western"><surname>Maccariello</surname><given-names>CEM</given-names></name><name name-style="western"><surname>Dias</surname><given-names>DPM</given-names></name><name name-style="western"><surname>dos Santos Almeida</surname><given-names>NA</given-names></name><name name-style="western"><surname>de Medeiros</surname><given-names>MA</given-names></name></person-group><article-title>Autonomic, endocrine and behavioural responses to thunder in laboratory and companion dogs</article-title><source>Physiol. Behav.</source><year>2017</year><volume>169</volume><fpage>208</fpage><lpage>215</lpage><pub-id pub-id-type="pmid">27939362</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.physbeh.2016.12.006</pub-id></element-citation><mixed-citation id="mc-CR86" publication-type="journal">Franzini de Souza, C. C., Maccariello, C. E. M., Dias, D. P. M., dos Santos Almeida, N. A. &amp; de Medeiros, M. A. Autonomic, endocrine and behavioural responses to thunder in laboratory and companion dogs. <italic toggle="yes">Physiol. Behav.</italic><bold>169</bold>, 208&#8211;215. 10.1016/j.physbeh.2016.12.006 (2017).<pub-id pub-id-type="pmid">27939362</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.physbeh.2016.12.006</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR87"><label>87.</label><mixed-citation publication-type="other">Jeni, L.&#160;A., Cohn, J.&#160;F. &amp; Kanade, T. Dense 3d face alignment from 2d videos in real-time. In <italic toggle="yes">2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)</italic>. Vol.&#160;1. 1&#8211;8. 10.1109/FG.2015.7163081 (IEEE, 2015).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/FG.2015.7163142</pub-id><pub-id pub-id-type="pmcid">PMC4900890</pub-id><pub-id pub-id-type="pmid">27293385</pub-id></mixed-citation></ref><ref id="CR88"><label>88.</label><mixed-citation publication-type="other">Yu, Y., Funes Mora, K.&#160;A. &amp; Odobez, J.-M. Robust and accurate 3d head pose estimation through 3dmm and online head model reconstruction. In <italic toggle="yes">2017 12th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2017)</italic>. 711&#8211;718. 10.1109/FG.2017.86 (IEEE, 2017).</mixed-citation></ref></ref-list></back></article>
        
    </metadata>
</record>
    </GetRecord>

</OAI-PMH>