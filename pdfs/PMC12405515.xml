


<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
    <responseDate>2025-09-09T13:47:50Z</responseDate>
    <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:12405515" metadataPrefix="pmc">https://pmc.ncbi.nlm.nih.gov/api/oai/v1/mh/</request>
    
    <GetRecord>
        <record>
    <header>
    <identifier>oai:pubmedcentral.nih.gov:12405515</identifier>
    <datestamp>2025-09-04</datestamp>
    
        
        <setSpec>ncomms</setSpec>
        
    
        
        <setSpec>pmc-open</setSpec>
        
    
</header>
    <metadata>
        
        <article xmlns="https://jats.nlm.nih.gov/ns/archiving/1.4/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.4/ https://jats.nlm.nih.gov/archiving/1.4/xsd/JATS-archivearticle1-4.xsd" article-type="research-article" xml:lang="en" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Nat Commun</journal-id><journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id><journal-id journal-id-type="pmc-domain-id">2873</journal-id><journal-id journal-id-type="pmc-domain">ncomms</journal-id><journal-title-group><journal-title>Nature Communications</journal-title></journal-title-group><issn pub-type="epub">2041-1723</issn><publisher><publisher-name>Nature Publishing Group</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12405515</article-id><article-id pub-id-type="pmcid-ver">PMC12405515.1</article-id><article-id pub-id-type="pmcaid">12405515</article-id><article-id pub-id-type="pmcaiid">12405515</article-id><article-id pub-id-type="pmid">40897731</article-id><article-id pub-id-type="doi">10.1038/s41467-025-63478-z</article-id><article-id pub-id-type="publisher-id">63478</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Prediction of cellular morphology changes under perturbations with a transcriptome-guided diffusion model</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-9961-0017</contrib-id><name name-style="western"><surname>Wang</surname><given-names initials="X">Xuesong</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0009-0002-6514-5588</contrib-id><name name-style="western"><surname>Fan</surname><given-names initials="Y">Yimin</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0743-0308</contrib-id><name name-style="western"><surname>Guo</surname><given-names initials="Y">Yucheng</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0009-0008-7515-1985</contrib-id><name name-style="western"><surname>Fu</surname><given-names initials="C">Chenghao</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0009-0000-6832-9863</contrib-id><name name-style="western"><surname>Lee</surname><given-names initials="K">Kinhei</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0009-0002-1555-6581</contrib-id><name name-style="western"><surname>Dallakyan</surname><given-names initials="K">Khachatur</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0009-0007-3985-1573</contrib-id><name name-style="western"><surname>Li</surname><given-names initials="Y">Yaxuan</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-5284-2259</contrib-id><name name-style="western"><surname>Yin</surname><given-names initials="Q">Qijin</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-3664-6722</contrib-id><name name-style="western"><surname>Li</surname><given-names initials="Y">Yu</given-names></name><address><email>yuli@cuhk.edu.hk</email></address><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-9655-2787</contrib-id><name name-style="western"><surname>Song</surname><given-names initials="L">Le</given-names></name><address><email>le.song@mbzuai.ac.ae</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><aff id="Aff1"><label>1</label>BioMap Research, Palo Alto, CA USA </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00t33hh48</institution-id><institution-id institution-id-type="GRID">grid.10784.3a</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 0482</institution-id><institution>Department of Computer Science and Engineering, </institution><institution>The Chinese University of Hong Kong, </institution></institution-wrap>Hong Kong SAR, China </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00t33hh48</institution-id><institution-id institution-id-type="GRID">grid.10784.3a</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 0482</institution-id><institution>The Chinese University of Hong Kong Shenzhen Research Institute, </institution></institution-wrap>Shenzhen, China </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0258gkt32</institution-id><institution-id institution-id-type="GRID">grid.508355.e</institution-id><institution>Mohamed bin Zayed University of Artificial Intelligence, </institution></institution-wrap>Abu Dhabi, UAE </aff></contrib-group><pub-date pub-type="epub"><day>2</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>16</volume><issue-id pub-id-type="pmc-issue-id">478256</issue-id><elocation-id>8210</elocation-id><history><date date-type="received"><day>17</day><month>7</month><year>2024</year></date><date date-type="accepted"><day>21</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>02</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>04</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-04 00:25:59.930"><day>04</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#8217;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#8217;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><self-uri content-type="pmc-pdf" xlink:href="41467_2025_Article_63478.pdf"/><abstract id="Abs1"><p id="Par1">Investigating cell morphology changes after perturbations using high-throughput image-based profiling is increasingly important for phenotypic drug discovery, including predicting mechanisms of action (MOA) and compound bioactivity. The vast space of chemical and genetic perturbations makes it impractical to explore all possibilities using conventional methods. Here we propose MorphDiff, a transcriptome-guided latent diffusion model that simulates high-fidelity cell morphological responses to perturbations. We demonstrate MorphDiff&#8217;s effectiveness on three large-scale datasets, including two drug perturbation and one genetic&#160;perturbation dataset, covering thousands of perturbations. Extensive benchmarking shows MorphDiff accurately predicts cell morphological changes under unseen perturbations. Additionally, MorphDiff enhances MOA retrieval, achieving an accuracy comparable to ground-truth morphology and outperforming baseline methods by 16.9% and 8.0%, respectively. This work highlights MorphDiff&#8217;s potential to accelerate phenotypic screening and improve MOA identification, making it a powerful tool in drug discovery.</p></abstract><abstract id="Abs2" abstract-type="web-summary"><p id="Par2">Wang, Fan, Guo, and colleagues present MorphDiff, a transcriptome-guided latent diffusion model that accurately predicts cell morphological responses to perturbations, enhancing MOA identification and phenotypic drug discovery.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Phenotypic screening</kwd><kwd>Molecular medicine</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">501100004853</institution-id><institution>Chinese University of Hong Kong (CUHK)</institution></institution-wrap></funding-source><award-id>4937025, 4937026, 5501517, 5501329, SHIAE BME-p1-24</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution>Chinese University of Hong Kong IdeaBooster Fund (IDBF23ENG05 and IDBF24ENG06). Research Matching Grant Scheme at CUHK (award numbers 8601603 and 8601663)</institution></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#169; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par3">Characterizing and predicting cell states under genetic and drug perturbations remains one of the most challenging and meaningful directions in the single-cell biology domain. By understanding how individual cells respond to specific genetic and drug perturbations, researchers can better map the pathways that contribute to particular cell states and identify potential targets for therapeutic intervention. Multiple aspects of cell states may change under perturbations, including but not limited to gene expression profile, proteomic composition, metabolic status, and cell morphology. Among the various modalities of cell states, the investigation of cell morphology responses to perturbations through high-throughput image-based profiling has gained significant interest due to its wide applications in phenotypic drug discovery. These applications encompass the prediction of MOAs (Mechanism of Actions), the prediction of compound bioactivity, and drug repurposing<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>.</p><p id="Par4">However, considering the vast number of synthesizable chemical compounds and genes in the perturbation space, it is infeasible to profile the cell morphology for all possible perturbations. Therefore, developing an in-silico method to simulate cell morphological responses to perturbations emerges as a challenging and meaningful topic<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. With a powerful and reliable tool to infer the cell morphology change under perturbations, the exploration of the vast perturbation space can be significantly accelerated, further promoting downstream drug discovery pipelines, such as MOA prediction. Computational approaches have been proposed to predict the cell morphology<sup><xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR4">4</xref></sup>. However, the precision and fidelity of these methods remain inadequate. First, as indicated by existing work IMPA (IMage Perturbation Autoencoder)<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, prediction on unseen perturbations will only perform well if the model has seen a similar perturbation with a similar effect in the training dataset. As structurally similar drugs or co-expression genetic perturbations may have different effects<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, it is critical to faithfully encode and represent perturbations to improve the generalizability of prediction in unseen perturbations. Second, in addition to the perturbations, cellular morphology is influenced by a wide range of factors, including but not limited to batch and well position effects<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, which leads to a high noise level in the cell morphology data.</p><p id="Par5">Therefore, we developed MorphDiff, a scalable transcriptome-guided diffusion model for predicting cell morphology responses to unseen perturbations. MorphDiff predicts the perturbed cell morphology with the perturbed L1000 gene expression profile as the condition. The following motivations inspire the choice of using gene expression profiles as the condition. First, gene expression plays a crucial role in determining cell morphology by directing the synthesis of proteins that regulate cellular structure and dynamics<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup>. Although the relationship between cell morphology and gene expression is complex, there remains shared and complementary information between them<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, making the prediction between gene expression and cell morphology feasible<sup><xref ref-type="bibr" rid="CR9">9</xref>&#8211;<xref ref-type="bibr" rid="CR12">12</xref></sup>. Therefore, perturbed gene expression is more informative in determining cell morphology than the prior knowledge-guided encoding of the perturbation, such as drug SMILES (Simplified Molecular Input Line Entry Specification) representation and Gene2vec<sup><xref ref-type="bibr" rid="CR13">13</xref></sup> embedding. Second, the L1000 assay offers a much larger pool of publicly available datasets compared to cell morphology profiling<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. Thus, obtaining the gene expression of cells treated with unseen perturbations is much easier than obtaining the cell morphology, enabling our tool to be potentially applicable in broader scenarios.</p><p id="Par6">The architecture of MorphDiff is based on the Latent Diffusion Model<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, an advanced generative model inspired by thermodynamics that learns to reverse the data from an unordered state to an ordered state. Intuitively, by learning to recursively add Gaussian distributions to noisy images, diffusion models could generate high-quality images. Concretely, we utilize the Morphology Variational Autoencoder (MVAE, see Methods Section) to compress the high-dimensional morphology of cells into low-dimensional embeddings, and then train a latent diffusion model<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> using these embeddings with gene expression profiles as the condition. Compared to traditional generative models such as the Generative Adversarial Network (GAN)<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> used in MorphNet<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> and IMPA<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, the diffusion-based architecture has the following advantages. First, the latent diffusion model is highly robust to noise, as, by design, diffusion models transform data into a noisy state and learn to reconstruct the original data, which makes it highly suitable for cell morphology datasets. Second, the latent diffusion model supports flexible conditioning, further enhancing the utility of MorphDiff. In addition to relying solely on the perturbed transcriptome as input, the pre-trained MorphDiff model can also take an unperturbed cell morphology as input while using the perturbed cell transcriptome as the condition. This allows MorphDiff to infer the continuous transition of cell morphology from unperturbed to perturbed without requiring additional training. Third, diffusion models usually perform better on general image synthesis tasks than GAN-based generative models<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>.</p><p id="Par7">To evaluate MorphDiff&#8217;s capability for predicting cell morphology responses to novel perturbations, we established a comprehensive assessment framework. Our methodology tested the model&#8217;s performance across three extensive datasets encompassing a wide range of genetic and drug perturbations. We assessed the model using both standard image generation metrics and measures of biological relevance by analyzing interpretable morphological features extracted through established computational tools such as CellProfiler<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> and DeepProfiler<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. Furthermore, we examined MorphDiff&#8217;s effectiveness in capturing correlations between transcriptional and morphological responses to perturbations, potentially providing insights into how changes in gene expression manifest as alterations in cellular morphology.</p><p id="Par8">A key application we aim to investigate is MorphDiff&#8217;s potential in phenotypic drug discovery, particularly for MOAs retrieval. While traditional approaches focus on drug structure analysis and transcriptome response analysis<sup><xref ref-type="bibr" rid="CR19">19</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>, we emphasize that cell morphology information-whether directly observed or computationally inferred-provides complementary and valuable signals for MOA identification. Through our designed MOA retrieval pipeline, we demonstrated that MorphDiff-generated morphologies achieve comparable performance to ground-truth morphologies and outperform existing baseline methods and gene expression-based approaches. Furthermore, we explored the potential of our approach to discover drugs with different molecular structures but similar MOA. In summary, MorphDiff is a powerful tool in phenotypic drug discovery by accurately generating cell morphology under unseen perturbations, with promising applications in facilitating the exploration of the vast phenotypic perturbation screening space and assisting in determining the MOAs of structurally diverse drugs.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Method overview</title><p id="Par9">MorphDiff maps L1000 gene expression to cell morphology images through a Latent Diffusion Framework<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. Concretely, as shown in Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref>a, paired L1000 gene expression and cell morphology images are curated for the same perturbations. The cell morphology images are acquired by the Cell Painting<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> platform and are usually composed of five channels, including DNA, ER, RNA, AGP, and Mito (Supplementary Table&#160;<xref rid="MOESM1" ref-type="media">1</xref>). MorphDiff is made up of two main components (Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref>b), Morphology VAE (MVAE) and Latent Diffusion Model (LDM). MVAE consists of the encoder and decoder parts. The encoder takes the high-dimensional cell morphology images composed of five channels as input and outputs the low-dimensional latent representations, while the decoder reconstructs the original input images based on the latent representation. This step compresses the cell morphology images into meaningful low-dimensional representation so that training the diffusion models can be easier. The latent diffusion model is trained to generate cell morphology low-dimensional representation conditioned on the perturbed gene expression profiles. The Latent Diffusion Model (LDM) consists of the noising process and denoising processes. In the noising process, Gaussian random noise is sequentially added to the latent representation of morphology for multiple steps, from 0 to <italic toggle="yes">T</italic>. The final <bold>Z</bold><sub><bold>T</bold></sub> follows the standard Gaussian distribution. In the denoising process, in each step <italic toggle="yes">t</italic>, LDM is trained to recursively remove the noise from <bold>Z</bold><sub><bold>t</bold></sub> conditioned on the L1000 gene expression as <italic toggle="yes">t</italic> decreases from <italic toggle="yes">T</italic> to 0. LDM is implemented with denoising U-Net architecture (based on convolutional neural networks) augmented with an attention mechanism<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. As the input condition, L1000 gene expression is combined with the model parameters of LDM, specifically the key and value of the attention mechanism in LDM. Training an LDM minimizes the variational upper bound, which serves as a proxy for reducing noise prediction error and ensures the generated samples match the ground-truth distribution. More technical details are described in the MorphDiff Model section. As illustrated in Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref>c, pre-trained MorphDiff can be applied in two ways. In the first mode (referred to as MorphDiff(G2I)), it takes the L1000 gene expression as the condition and denoises the corresponding cell morphology images from random noise distribution. In the second mode (referred to as MorphDiff(I2I)), it takes the L1000 gene expression for one specific perturbation as the condition and transforms the morphology images from the control cell morphology to the predicted perturbed morphology images. Compared to previous works in generating cell morphology images, MorphDiff is the only tool that supports generation from gene expression to morphology and transformation from unperturbed morphology to perturbed morphology. In Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref>d, we outlined the key applications of MorphDiff in practice. Primarily, MorphDiff can predict cell morphology resulting from unseen perturbations not encountered during training, which fulfills our main objective of exploring the vast perturbation space through in-silico inference. Furthermore, our framework incorporates CellProfiler<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> and DeepProfiler<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> to generate biologically meaningful morphological features and embeddings, respectively. This integration enables researchers to probe specific morphological feature changes following perturbation, thereby enhancing interpretability and practical applicability. As a critical application, the generated morphological profiles can be utilized for retrieval and identification of drug MOA, establishing MorphDiff as a powerful tool in phenotypic drug discovery.<fig id="Fig1" position="float" orientation="portrait"><label>Fig. 1</label><caption><title>Overview of the MorphDiff framework.</title><p><bold>a</bold> In this study, the multimodal dataset consists of the morphology images with five channels collected using CP (Cell Painting), and the gene expressions collected using L1000 assays. CellProfiler is then used to segment the cells and extract CellProfiler features at the single-cell level. Morphology images and gene expression together characterize the cell morphology responses to specific perturbations. The scale bar is 20&#8201;&#956;m. <bold>b</bold> MorphDiff is composed of two main components: Morphology VAE (MVAE) and Latent Diffusion Model (LDM). The MVAE encoder encodes the multi-channel cell morphology images into latent representation, and the decoder reconstructs the original cell morphology images based on the latent representation. LDM is trained to denoise from Gaussian random noise <bold>Z</bold><sub><bold>T</bold></sub> to morphology latent representation <bold>Z</bold><sub><bold>0</bold></sub>, recursively conditioned on L1000 gene expression. The scale bar is 20&#8201;&#956;m. <bold>c</bold> MorphDiff can be applied in two ways to generate cell morphology images with perturbations: L1000 gene expression to cell morphology generation (G2I, Gene to Image) and perturbed L1000 gene expression combined with control morphology images to perturbed cell morphology images generation (I2I, Image To Image). I2I is implemented with SDEdit<sup><xref ref-type="bibr" rid="CR62">62</xref></sup> without re-training. The scale bar is 20&#8201;&#956;m. <bold>d</bold> Illustration of the downstream applications of MorphDiff, including prediction on unseen perturbations, feature analysis with CellProfiler, as well as morphology-based MOA retrieval with DeepProfiler. DMSO stands for Dimethyl sulfoxide, which is considered as control group without perturbation. The scale bar is 20&#8201;&#956;m. <bold>a</bold>, <bold>b</bold>, <bold>c</bold>, <bold>d</bold> are created in BioRender. Group, A. (2025) <ext-link ext-link-type="uri" xlink:href="https://BioRender.com/nu1zlqw">https://BioRender.com/nu1zlqw</ext-link>.</p></caption><graphic id="d33e438" position="float" orientation="portrait" xlink:href="41467_2025_63478_Fig1_HTML.jpg"/></fig></p><p id="Par10">For model evaluation and applications, we collected three large-scale cell morphology image datasets for model training, evaluation, and analysis, which include 1028 drug perturbations from the CDRP dataset<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, 130 genetic perturbations from the JUMP dataset<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> on the U2OS cell line, and 61 drug perturbations from the LINCS dataset on the A549 cell line<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>. After pre-processing and splitting these datasets, we obtained the following datasets for training and evaluation: JUMP Training set, JUMP ID (in-distribution) set, and JUMP OOD (out-of-distribution) set; the CDRP Training set, CDRP ID set, CDRP OOD set, and CDRP Target_MOA set; the LINCS Target leave-one-out set and LINCS MOA leave-one-out set. Details of the dataset splits are provided in the Datasets section.</p><p id="Par11">For benchmarking and downstream tasks, we generated gene embeddings and drug embeddings as conditions for baseline methods, respectively, for genetic perturbation and drug perturbation prediction tasks, following the implementation described in IMPA<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. The gene embeddings are generated with Gene2vec<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, and drug embeddings are generated with RDKit<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>.</p></sec><sec id="Sec4"><title>MorphDiff accurately predicts changes in cell morphology with genetic perturbations</title><p id="Par12">To illustrate the superiority of MorphDiff, we benchmarked the general generative performance on the JUMP OOD dataset. We compared MorphDiff with a wide range of baseline methods, including MorphNet<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>, DMIT (Disentanglement for Multi-mapping Image-to-Image Translation)<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>, DRIT++ (Disentangled Representation for Image-to-Image Translation)<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, StarGANv1<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>, IMPA<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, VQGAN (Vector Quantized Generative Adversarial Network)<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>, and MDTv2 (Masked Diffusion Transformers)<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. For some baseline methods, including IMPA, DRIT++, DMIT, StarGANv1, VQGAN, and MDTv2, we followed the implementation in IMPA<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, using gene embeddings (Gene2vec<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>) as conditions. In contrast, MorphNet<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> generates morphology images based on gene expression profiles that have been corrected using scVI<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. The details of these methods can be found in Supplementary Notes&#160;<xref rid="MOESM1" ref-type="media">1</xref>.</p><p id="Par13">First, we conducted a visual assessment of the generation quality between MorphDiff methods and baseline approaches, as illustrated in Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>a. For this visual comparison, we presented results from the <italic toggle="yes">SREBF1</italic> genetic perturbation, which represents an out-of-distribution (OOD) perturbation. Visualizations for the additional nine OOD genetic perturbations are available in Supplementary Figs.&#160;<xref rid="MOESM1" ref-type="media">1</xref>&#8211;<xref rid="MOESM1" ref-type="media">3</xref>. The specific criteria used for selecting these images for visualization are detailed in Supplementary Notes&#160;<xref rid="MOESM1" ref-type="media">2</xref>. The generated outputs of both modes of MorphDiff display colors and morphological structures that closely resemble the ground truth. DMIT, IMPA, and MDTv2 produce reasonably good images that adequately capture the general morphological features, but they fall short in detail and clarity. MorphNet shows promise in generating reasonable images with some detail, but it lacks diversity. StarGAN produces diverse outputs with good morphological structures, but it exhibits subtle color bias compared to the ground truth. For DRIT++ and VQGAN, the visual quality appears worse than other methods, with either reduced clarity or noticeable color bias. Overall, MorphDiff (I2I), MorphDiff (G2I), IMPA, and DMIT demonstrate the highest image generation quality, with both MorphDiff variants producing images that closely resemble the ground truth.<fig id="Fig2" position="float" orientation="portrait"><label>Fig. 2</label><caption><title>MorphDiff predicts changes in cell morphology with genetic perturbations.</title><p><bold>a</bold> Visualization of the generated outputs from MorphDiff and baseline methods for the <italic toggle="yes">SREBF1</italic>. The corresponding information for the original channels and fluorophores can be found in Supplementary Table&#160;<xref rid="MOESM1" ref-type="media">1</xref>, and the weights of composition are detailed in the Evaluation Setup part of the Methods section. The scale bar is 20&#8201;&#956;m. <bold>b</bold> Performance benchmarking on the JUMP OOD set. Each method was evaluated 10 times for robust assessment. Methods requiring reference control DMSO morphology as input used 10 distinct control image groups from independent plates (<italic toggle="yes">n</italic>&#8201;=&#8201;10 biological replicates), while methods without this requirement used 10 sampling iterations with different random seeds. Linear normalization was conducted on the reciprocals of FID, CMMD, and on the other three metrics separately to convert their values to the range of 0&#8211;1. A larger value indicates better performance. One-sided Wilcoxon signed-rank test with Bonferroni correction was conducted between MorphDiff(I2I) and other methods. &#8220;*&#8221; indicates that MorphDiff(I2I) surpasses the baseline method with a <italic toggle="yes">p</italic>&#160;value&#160;&lt;0.05. The &#8220;ns&#8221; represents the situation of no significant difference. Data are presented as mean values&#8201;&#177;&#8201;SD. <bold>c</bold> UMAP visualization of CellProfiler features for IMPA and MorphDiff(G2I) under two genetic perturbations. DMSO (Dimethyl sulfoxide) serves as the untreated control. <bold>d</bold> CellProfiler feature distributions comparing ground truth with IMPA, MorphDiff(G2I), and MorphDiff(I2I) outputs for <italic toggle="yes">RAC1</italic> perturbation. Abbreviations: E ERSyto, EB ERSytoBleed, H Hoechst, Pg Ph_golgi, LQ lower quartile, Var variance, Tex texture, Corr correlation, Int intensity. <bold>e</bold> The two-sided Wilcoxon signed-rank test results to test the difference between the generated and ground-truth CellProfiler features. The <italic toggle="yes">y</italic>-axis indicates the proportion of generated CellProfiler features not significantly differ from the ground-truth CellProfiler features through a Wilcoxon signed-rank test (<italic toggle="yes">p</italic>&#160;&#160;value&#160;&gt;0.05). 232 features are tested in total. <bold>f</bold> The heatmap of the correlation between the CellProfiler features of the ground-truth morphology, MorphDiff(G2I)-generated morphology, and IMPA-generated morphology with L1000 gene expression. Source data are provided as a <xref rid="MOESM11" ref-type="media">Source data</xref> file for (<bold>b</bold>&#8211;<bold>f</bold>).</p></caption><graphic id="d33e595" position="float" orientation="portrait" xlink:href="41467_2025_63478_Fig2_HTML.jpg"/></fig></p><p id="Par14">Quantitatively, we evaluated these methods using several metrics, including FID<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>, IS (Inception Score)<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>, CMMD<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>, as well as density and coverage<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. FID measures the distance between the distributions of the ground-truth and generated images in the feature space, using features extracted from Inception V3<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. The IS assesses the quality of the generated images based on how effectively they can be classified by the Inception V3 model. Both FID and IS utilize Inception V3<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>, which is pre-trained on ImageNet<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>. To enhance the reliability and robustness of our comparisons, we incorporated CMMD, which calculates the Maximum Mean Discrepancy (MMD) distance based on features extracted by a CLIP model pre-trained on 400 million image-text pairs containing more complex scenes<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>. We also included density and coverage metrics, as these metrics are robust against outlier samples and could better measure the diversity and fidelity of the generated samples<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. In general, lower FID and CMMD values indicate better performance, while higher density, IS, and coverage scores reflect better generation quality. For convenience of presentation, we used the reciprocals of FID and CMMD, denoted as FID(-1) and CMMD(-1), for comparison and analysis. To ensure statistical reliability and robustness of our results, we employed different sampling approaches based on method requirements. For methods requiring reference control DMSO morphology images as input (Supplementary Table&#160;<xref rid="MOESM1" ref-type="media">2</xref>), we generated outputs using 10 distinct groups of control images, each group derived from an independent plate (<italic toggle="yes">n</italic>&#8201;=&#8201;10 biological replicates). Each plate represented a separate experimental unit, indicating that the statistical analysis derived from 10 independent biological replicates (10 distinct plates). For methods that do not rely on reference control DMSO images, we conducted 10 separate sampling iterations, each with a different random seed. We performed the one-sided Wilcoxon signed-rank test for each comparison with Bonferroni correction to further enhance the statistical significance of our tests. It should be noted that star (&#8220;&#8727;&#8221;) means that MorphDiff surpasses the baseline method with a <italic toggle="yes">p</italic>&#160;value &lt;0.05. The &#8220;ns&#8221; represents the situation of no significant difference. The same notation for performance tests is used in the following sections. As depicted in Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>b, MorphDiff (I2I) and MorphDiff (G2I) rank as the top two methods across these evaluation metrics compared with other baseline approaches, highlighting the effectiveness of our model. We also observed that all methods relying on reference control DMSO morphology images exhibit larger performance variance compared to those that do not, as the quality of the control cell morphology images may impact the model performance in terms of general evaluation metrics (Supplementary Notes&#160;<xref rid="MOESM1" ref-type="media">3</xref>). The results also show that MorphNet achieves a nearly zero coverage score, demonstrating that the generative output of MorphNet lacks diversity, which aligns with the visualization in Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>a. Based on both qualitative visualizations and quantitative metrics, MorphDiff (both modes) demonstrates more superior performance in terms of generalization, fidelity, and diversity compared to other generative models, ultimately resulting in superior generation quality.</p><p id="Par15">Furthermore, we performed an in-depth analysis of whether MorphDiff can accurately predict changes in cell morphology under genetic perturbations. We performed a quantitative analysis using the CellProfiler features to demonstrate the effectiveness of MorphDiff. CellProfiler features are a set of morphological features extracted with CellProfiler related to cell morphology, which measure the texture, intensity, and granularity within each morphology channel and the correlation between different morphology channels. In Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>c, we used UMAP to project the morphological features into two dimensions for visualization. We selected the 10 most important CellProfiler features discriminative of the perturbation types to form the morphological feature vector. The details of the feature selection strategy are discussed in the Evaluation Setup section (Morphological feature selection based on discriminability of perturbations). For <italic toggle="yes">ARAF</italic> and <italic toggle="yes">STAT3</italic> genetic perturbations, we can observe that the distribution of ground-truth perturbed cell morphology has an apparent variance. The generated outputs of IMPA form a dense cluster and are far away from the ground-truth distribution. In contrast, the outputs of MorphDiff(G2I) are much more diverse and resemble the ground-truth distribution. We conducted the same analysis on other genetic perturbations, and the results in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">4</xref> display a consistent effect. We also evaluated MorphDiff(I2I) using similar methods in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">5</xref> and found a higher overlap between the ground-truth feature distribution and the MorphDiff (I2I) generated feature distribution.</p><p id="Par16">Then, we turned to a more fine-grained analysis of how well the generated morphology aligns with the ground-truth morphology regarding the values of individual CellProfiler features. In Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>d, we visualized the values of the 10 most important cell morphology features from the ground-truth perturbation morphology, the morphology generated by MorphDiff(G2I), MorphDiff(I2I), and the morphology generated by IMPA on <italic toggle="yes">RAC1</italic> genetic perturbation. We can see that the MorphDiff-generated morphology aligns well with the ground-truth morphology compared with the IMPA-generated morphology. The results of more perturbations on the top 20 most important CellProfiler features are shown in Supplementary Figs.&#160;<xref rid="MOESM1" ref-type="media">6</xref> and &#160;<xref rid="MOESM1" ref-type="media">7</xref>. To have a more holistic view of how closely the MorphDiff-generated morphology aligns with the ground-truth distribution, we performed statistical tests for a more quantitative comparison. Concretely, for each feature out of all CellProfiler features extracted, we conducted the two-sided Wilcoxon signed-rank test across the CellProfiler features of the ground-truth and the generated output. If the <italic toggle="yes">p</italic>&#160;value of the Wilcoxon signed-rank test is larger than 0.05, we conclude that insufficient evidence shows significant differences between the generated perturbation morphological features and the ground-truth perturbation morphological features. As shown in Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>e, the proportion of the generated CellProfiler features that align with the ground-truth features of MorphDiff(G2I) is much larger than IMPA. For MorphDiff(G2I), more than seventy percent of the generated CellProfiler morphology features align with the ground-truth perturbation CellProfiler features, which demonstrates the effectiveness of MorphDiff in accurately predicting the perturbation morphology. We also repeated the analysis in Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>e with other types of statistical tests and metrics, including t-test, Kolmogorov-Smirnov test, and KL-divergence, in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">8</xref> for MorphDiff(G2I), MorphDiff(I2I), and IMPA to further demonstrate the robustness and consistency of our conclusion.</p><p id="Par17">Subsequently, we validated the effectiveness of MorphDiff in capturing the correlation between perturbed gene expression and perturbed morphology. For better clarity, we selected the CellProfiler features that MorphDiff(G2I) and IMPA can best recover. The details of feature selection are described in the Evaluation Setup Section (Morphological feature selection based on predictability). Figure&#160;<xref rid="Fig2" ref-type="fig">2</xref>f shows the correlation between gene expression and CellProfiler features of the ground truth, MorphDiff(G2I), and IMPA, respectively. In Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>f, we observed that several groups of genes and CellProfiler features have a high correlation with each other. For example, the group on the top left of the heatmap mainly consists of features related to Correlation and Intensity associated with ER, Mito, and AGP channels (Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">9</xref>). Another group on the bottom right mainly consists of features related to the intensity of DNA and ER channels (Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">9</xref>). The detailed correlation of MorphDiff(G2I) and IMPA can be found in Supplementary Figs.&#160;<xref rid="MOESM1" ref-type="media">10</xref> and&#160;<xref rid="MOESM1" ref-type="media">11</xref>. We computed the correlation between the correlation map of the generated samples and ground-truth samples. We observed that the samples generated with MorphDiff(G2I) have a much higher correlation (0.47) than the samples generated with IMPA (0.27). Therefore, MorphDiff(G2I) effectively captures the pattern of cell morphological feature changes across different genetic perturbations, while IMPA fails to capture the correlation pattern between gene expression and cell CellProfiler features. We performed a similar analysis for MorphDiff(I2I) and IMPA in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">12</xref> and also validated the superiority of MorphDiff(I2I).</p></sec><sec id="Sec5"><title>MorphDiff captures morphological changes in cells across thousands of drug treatments</title><p id="Par18">We first benchmarked all methods on the CDRP OOD set with the general evaluation metrics, in which the meanings of stars are the same as in the previous section, and the hashtag (&#8216;#&#8217;) indicates the situation where the baseline performs significantly better. As shown in Fig.&#160;<xref rid="Fig3" ref-type="fig">3</xref>a, both modes of MorphDiff substantially outperform other methods in most cases. While DMIT and MDTv2 achieve high scores in IS, density, and coverage, they obtain relatively lower scores in FID(-1) and CMMD(-1) compared to MorphDiff (both modes). This suggests that DMIT and MDTv2 struggle to produce high-quality samples. Similar to the results on the JUMP dataset, MorphNet performs well in terms of density score, but it is nearly ineffective in terms of coverage, demonstrating its lack of generalizability and diversity. Ideally, an effective generative model should achieve low FID, CMMD, and high scores in IS, density, and coverage to ensure that it produces outputs of high quality and fidelity, while also generating diverse outputs that closely align with the ground-truth distribution. MorphDiff (both modes) outperforms baseline methods considering these criteria, demonstrating its comprehensive generative capability and stability. To further demonstrate the generalizability of our model, we performed evaluation in a stricter setting. We conducted leave-one-out validation on the LINCS dataset (A549 cell line) for 10 different targets and 10 different MOAs. We selected targets and MOAs with sufficient cell morphology images for a robust evaluation. The detailed validation setting can be found in the Datasets section (LINCS dataset). The results displayed in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">13</xref> demonstrate that MorphDiff consistently achieves the most comprehensive generative performance for different MOAs and targets in the leave-one-out setting.<fig id="Fig3" position="float" orientation="portrait"><label>Fig. 3</label><caption><title>MorphDiff captures morphological changes across thousands of drug treatments.</title><p><bold>a</bold> General generative evaluation of pre-trained MorphDiff and IMPA. Methods requiring reference control images used 10 distinct control image groups from independent plates (<italic toggle="yes">n</italic>&#8201;=&#8201;10 biological replicates), while other methods used 10 sampling iterations with different random seeds. Linear normalization converted FID and CMMD reciprocals, plus three other metrics, to 0&#8211;1 range. Statistical comparisons used one-sided Wilcoxon signed-rank tests with Bonferroni correction (<italic toggle="yes">p</italic>&#160;value&#160;&lt;&#8201;0.05). &#8220;*&#8221; indicates MorphDiff(I2I) superiority; &#8220;ns&#8221; indicates non-significance; hashtag (&#8220;#&#8221;) indicates the baseline performs better significantly. Data are presented as mean values&#8201;&#177;&#8201;SD. <bold>b</bold> The <italic toggle="yes">R</italic><sup>2</sup> score between the ground-truth CellProfiler feature vectors and the generated CellProfiler feature vectors on the CDRP ID set. The <italic toggle="yes">x</italic>-axis represents the <italic toggle="yes">R</italic><sup>2</sup> scores between IMPA and ground truth for each sample. The <italic toggle="yes">y</italic>-axis represents the <italic toggle="yes">R</italic><sup>2</sup> scores of MorphDiff(G2I) and MorphDiff(I2I) against ground truth respectively. The <italic toggle="yes">p</italic>&#160;values calculated by one-sided Wilcoxon signed-rank test indicate the significance of the distribution of the <italic toggle="yes">y</italic>-axis being greater than that of the <italic toggle="yes">x</italic>-axis. <bold>c</bold> The difference between control and perturbations for specific CellProfiler features on the CDRP ID set. The <italic toggle="yes">x</italic>-axis displays the difference between the ground-truth perturbations and the control, while the <italic toggle="yes">y</italic>-axis displays the difference between the generated perturbations and the control. The higher the point density along the diagonal, the closer the generated difference is to the ground truth. More results can be found in the Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">14b, c</xref>. The <italic toggle="yes">R</italic><sup>2</sup> score measuring the similarity between the predicted difference and ground-truth difference. <bold>d</bold> The <italic toggle="yes">x</italic>-axis represents the ground-truth classification accuracy scores between different pairs of perturbations, and the <italic toggle="yes">y</italic>-axis means the classification accuracy scores of the corresponding samples generated by different methods. Source data are provided as a <xref rid="MOESM11" ref-type="media">Source data</xref> file for (<bold>a</bold>&#8211;<bold>d</bold>).</p></caption><graphic id="d33e816" position="float" orientation="portrait" xlink:href="41467_2025_63478_Fig3_HTML.jpg"/></fig></p><p id="Par19">We further investigated the responses of cell morphology to small molecular compounds by validating whether the generated output aligns well with the ground truth on the CellProfiler features. We extracted the CellProfiler features from the generated morphologies and compared them with the features extracted from the ground-truth morphologies. Concretely, we extracted CellProfiler features from 3000 ground-truth images sampled from the CDRP ID set and from the corresponding images generated by MorphDiff(I2I), MorphDiff(G2I), and IMPA. Over 200 informative CellProfiler features are extracted and analyzed. We calculated <italic toggle="yes">R</italic><sup>2</sup> scores between the ground-truth CellProfiler feature vectors and the corresponding generated CellProfiler feature vectors. A higher <italic toggle="yes">R</italic><sup>2</sup> score indicates better proximity between the generated and the ground-truth CellProfiler feature vectors. We compared the <italic toggle="yes">R</italic><sup>2</sup> score of MorphDiff versus ground truth (<italic toggle="yes">y</italic>-axis) and IMPA versus ground truth (<italic toggle="yes">x</italic>-axis) in Fig.&#160;<xref rid="Fig3" ref-type="fig">3</xref>b, with each point indicating a unique cell morphology. Figure&#160;<xref rid="Fig3" ref-type="fig">3</xref>b shows that MorphDiff(I2I) and MorphDiff(G2I) both outperform baselines significantly with a <italic toggle="yes">p</italic>&#160;value&#160;&lt;&#8201;0.0001 through the one-sided Wilcoxon signed-rank test. In more detail, 89% of the generated samples from MorphDiff(I2I) exhibit an <italic toggle="yes">R</italic><sup>2</sup> score greater than 0.5, with 27.2% surpass 0.8. For MorphDiff(G2I), 87.6% of the samples have an <italic toggle="yes">R</italic><sup>2</sup> score greater than 0.5, and 16.2% exceed 0.8. In contrast, 78.3% of the samples from IMPA exceed 0.5, but none reach 0.8. This indicates that MorphDiff (both modes) can well capture the feature distribution of the drug perturbation dataset. We conducted the same analysis for the CDRP OOD set (Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">14a</xref>) and for the LINCS leave-one-out set (Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">16a</xref>), and found that both modes of MorphDiff consistently outperform the baseline method with the <italic toggle="yes">p</italic>&#160;value&#160;&lt;&#8201;0.0001, demonstrating the generalizability of our method.</p><p id="Par20">Furthermore, we performed a fine-grained analysis on the effectiveness of our tool in predicting the features that undergo the most significant changes after perturbation. For each CellProfiler feature, we conducted a chi-square test between the ground-truth control CellProfiler features and ground-truth perturbed CellProfiler features to determine which features change significantly after perturbation. We picked the features with <italic toggle="yes">p</italic>&#160;value &lt;&#8201;0.05 as significantly changed and calculated the <italic toggle="yes">R</italic><sup>2</sup> score between the ground-truth and generated samples for each feature across 3000 images. To intuitively demonstrate the superiority of MorphDiff, we displayed 10 most significantly changed features (with the lowest <italic toggle="yes">p</italic>&#160;value) by using a scatter plot to illustrate the degree of proximity between the ground truth and the generated images as shown in Fig.&#160;<xref rid="Fig3" ref-type="fig">3</xref>c and Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">14b, c</xref>. The <italic toggle="yes">x</italic>-axis represents the difference between the ground-truth CellProfiler features and control CellProfiler features, while the <italic toggle="yes">y</italic>-axis represents the difference between the generated CellProfiler features and control CellProfiler features. Considering the high density on the diagonal and the corresponding <italic toggle="yes">R</italic><sup>2</sup> scores, it is evident that MorphDiff(I2I) can accurately predict morphological changes on these significantly changed CellProfiler features. To further evaluate the generalizability of MorphDiff, we performed the same analysis on the CDRP OOD set and LINCS leave-one-out set in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">15</xref> and &#160;<xref rid="MOESM1" ref-type="media">16c</xref>, respectively. Our conclusion is consistent across different settings and datasets.</p><p id="Par21">Moreover, it is crucial to evaluate whether the model can capture the diversity among different perturbations and generate cell morphology with specificity to perturbations. We utilized DeepProfiler<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> to extract morphological embeddings from 10 CDRP OOD perturbations with the most images, and we term them as DeepProfiler embeddings. Subsequently, we trained an SVM binary classifier<sup><xref ref-type="bibr" rid="CR38">38</xref></sup> for each pair of perturbations on the ground-truth cell morphology and calculated the classification accuracy for the DeepProfiler embeddings generated by MorphDiff(I2I), MorphDiff(G2I), and IMPA. The results in Fig.&#160;<xref rid="Fig3" ref-type="fig">3</xref>d clearly show that MorphDiff(G2I) achieves the highest accuracy among the three methods, which indicates that it best captures the perturbation-specific cell morphology patterns. We showed the SMILES of the corresponding drugs in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">17a</xref>. We conducted the same analysis on 10 drugs selected from the LINCS leave-one-out set with the most ground-truth images. The results shown in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">16b</xref> further confirm the superiority of MorphDiff. The SMILES for these drugs can be found in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">17b</xref>. The results also indicate that the generated output of MorphDiff(G2I) has higher perturbation specificity than that of MorphDiff(I2I) at the drug level. This is because MorphDiff(I2I) additionally uses control images as input, which can be influenced by technical variations that may introduce substantial biases and further affect the detection of perturbation-specific change, especially when the phenotypic changes caused by the perturbation are subtle<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>.</p></sec><sec id="Sec6"><title>Pre-trained MorphDiff as a promising tool in phenotypic drug discovery</title><p id="Par22">Small-molecule compounds are agents that modify a target to affect its functionality<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. These compounds can either reduce or accelerate the activity of a target, which is typically a biomolecule like a protein, enzyme, receptor, or gene. These biomolecules are involved in signaling or metabolic pathways, often specific to diseases<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>. Biomolecules play a pivotal role in disease development and progression, primarily through communication facilitated by interactions between proteins and nucleic acids or proteins themselves. These interactions often lead to signal amplification or metabolic process alterations, further affecting disease development. Typically, a target can be associated with multiple drugs. For instance, amcinonide, dexamethasone, and betamethasone can all impact the gene <italic toggle="yes">NR3C1</italic>, while LFM-A12, RG-14620, WHI-P154, and chrysophanol can affect the gene <italic toggle="yes">EGFR</italic>. Based on these observations, we aim to investigate whether drugs acting on the same target will exhibit similar influences on morphological changes compared to control images, and we wonder whether MorphDiff can capture such patterns. We selected 10 targets (CDRP Target_MOA set, see the Datasets section) with sufficient corresponding compounds to include enough cell morphology for analysis, and these data are not present in the CDRP Training set for MorphDiff and IMPA. Firstly, we assessed the models&#8217; generative performance. We conducted a benchmark test with the pre-trained MorphDiff(I2I), MorphDiff(G2I), and IMPA on the CDRP Target_MOA dataset in the same way as in the previous section. These models were pre-trained on the CDRP Training set. As illustrated in Fig.&#160;<xref rid="Fig4" ref-type="fig">4</xref>a, MorphDiff(I2I) significantly outperforms IMPA across all image generation quality metrics, with a corrected <italic toggle="yes">p</italic>&#160;value of &lt;0.05, as determined by the one-sided Wilcoxon signed-rank test and Bonferroni correction. For the comparison between MorphDiff(I2I) and MorphDiff(G2I), there is no significant difference. We further investigated how the performance of MorphDiff methods varies across different MOAs and targets. Specifically, we evaluated how performance is affected by the distance between the CDRP Training set and the evaluated CDRP Target_MOA dataset. As detailed analysis in Supplementary Notes&#160;<xref rid="MOESM1" ref-type="media">4</xref>, we found that model performance is influenced by the similarity between training and evaluation datasets, with performance degrading as the evaluation compounds become more distant from the training data. Consequently, when applying MorphDiff methods, researchers should consider potential performance limitations for test compounds that differ significantly from those in the training set.<fig id="Fig4" position="float" orientation="portrait"><label>Fig. 4</label><caption><title>Pre-trained MorphDiff potentially promotes drug discovery.</title><p><bold>a</bold> General generative evaluation of pre-trained MorphDiff and IMPA. Methods requiring reference control images used 10 distinct control image groups from independent plates (<italic toggle="yes">n</italic>&#8201;=&#8201;10 biological replicates), while other methods used 10 sampling iterations with different random seeds. Statistical comparisons used one-sided Wilcoxon signed-rank tests with Bonferroni correction (<italic toggle="yes">p</italic>&#160;value&#160;&lt;&#8201;0.05). <bold>b</bold> F1 scores measure performance in identifying whether more than 200 CellProfiler features undergo significant changes under drug perturbations across various targets (<italic toggle="yes">n</italic>&#8201;=&#8201;10 biological replicates). The tests are one-sided Wilcoxon signed-rank tests with Bonferroni correction (<italic toggle="yes">p</italic>&#160;value&#160;&lt;&#8201;0.05). For <bold>a</bold>, <bold>b</bold>, &#8220;*&#8221; indicates significance; &#8220;ns&#8221; indicates non-significance; hashtag (&#8220;#&#8221;) indicates the situation that the baseline performs better significantly. Data presented as mean values&#8201;&#177;&#8201;SD. <bold>c</bold> Wasserstein distance between different pairs of target-level perturbations for the ground-truth and generated cell morphology, computed with DeepProfiler embeddings. For each pair of target-level perturbations, the ground-truth Wasserstein distance is the <italic toggle="yes">x</italic>-axis, and the corresponding generated Wasserstein distance is the <italic toggle="yes">y</italic>-axis. <bold>d</bold> Schematic overview of retrieval workflow. Created in BioRender. Group, A. (2025) <ext-link ext-link-type="uri" xlink:href="https://BioRender.com/492h3v7">https://BioRender.com/492h3v7</ext-link>. <bold>e</bold> Top 5 MOA retrieval results across modalities. Sixty-nine drugs were randomly divided into reference (47) and query (22) sets across 10 iterations. Boxplots show median, quartiles, and range. The whiskers in the boxplots mark the minima to maxima. <bold>f</bold> MOA matching performance using generated cell morphology DeepProfiler embeddings: Mean Average Precision (<italic toggle="yes">x</italic>-axis) versus Folds of Enrichment (<italic toggle="yes">y</italic>-axis). Points represent means across all query morphologies using 0.90 threshold (top 10%). <bold>g</bold> UMAP projections by drug MOAs across modalities: drug structure embeddings, gene expression, and DeepProfiler embeddings from ground-truth and generated cell morphology. BML-259, RG-14620, and BRD-A72066420 structures shown in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">23</xref>. Source data are provided as a <xref rid="MOESM11" ref-type="media">Source data</xref> file for (<bold>a</bold>&#8211;<bold>g</bold>).</p></caption><graphic id="d33e1032" position="float" orientation="portrait" xlink:href="41467_2025_63478_Fig4_HTML.jpg"/></fig></p><p id="Par23">To determine whether the images of perturbations related to these targets are significantly different from the control images, we extracted CellProfiler feature vectors from the ground-truth and the generated images, then projected the CellProfiler features through UMAP<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>, as depicted in Supplementary Figs.&#160;<xref rid="MOESM1" ref-type="media">18</xref> and <xref rid="MOESM1" ref-type="media">19</xref>. We observed that the ground-truth CellProfiler feature vectors induced by various drugs are clearly distinct from the ground-truth control set in the CellProfiler feature space. The CellProfiler feature vectors generated by the pre-trained MorphDiff (both modes) drive a consistent effect with the ground truth after UMAP projection. On the other hand, IMPA generates multiple clusters of perturbations targeting the same gene, while these perturbations should have a similar effect according to the ground truth, which indicates its poor generalization performance. Additionally, the Wasserstein distance computed between the perturbed and control CellProfiler features quantitatively demonstrates the advantages of MorphDiff.</p><p id="Par24">Moreover, we investigated whether our method could identify the significantly changed CellProfiler features after being treated with drugs that target different genes. First, we adopted the chi-square test between the ground-truth control and the perturbed morphology to identify significantly changed CellProfiler features with the <italic toggle="yes">p</italic>&#160;value threshold at 0.05. Then, we calculated the F1 score between the significantly changed CellProfiler features identified with the generated and ground-truth morphology. We also sampled 10 times for each model to determine the significance of the results. Figure&#160;<xref rid="Fig4" ref-type="fig">4</xref>b demonstrates that MorphDiff(I2I) effectively identifies significantly changed CellProfiler features, outperforming IMPA for 6 of 10 targets with corrected <italic toggle="yes">p</italic>&#160;value &lt;&#8201;0.05. MorphDiff(I2I) also outperforms MorphDiff(G2I) for 5 targets, while MorphDiff(G2I) outperforms MorphDiff(I2I) for 2 targets significantly. In addition, we also validated whether the relative distance between cell morphology from different targets could be preserved with our generative model. We used DeepProfiler<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> to extract DeepProfiler embeddings of cell morphology from different targets, and computed Wasserstein distance to measure the pairwise distance between them. We found that the Wasserstein distance computed from the generated morphology by MorphDiff(I2I) and MorphDiff(G2I) is highly consistent with the ground truth, as Fig.&#160;<xref rid="Fig4" ref-type="fig">4</xref>c shows, where the correlation score is up to 0.97. These results demonstrate that MorphDiff, in both modes, exhibits strong generalization ability. It effectively learns complex and in-depth relationships between drug perturbations and morphology, predicting morphological changes and capturing diversity at the target level.</p><p id="Par25">To further explore the potential utility of MorphDiff as a valuable tool in advancing drug discovery, we then focused on an important direction in drug discovery: identifying the MOA of a compound. We investigated whether cell morphology provides necessary information in the identification of drug MOA and whether the cell morphology inferred by MorphDiff also contains such information. Concretely, as demonstrated in Fig.&#160;<xref rid="Fig4" ref-type="fig">4</xref>d, we designed a framework for MOA retrieval with cell morphology images. Given query cell DeepProfiler embeddings, we retrieved possible MOAs based on the minimum distance between query morphology images and known morphology images corresponding to certain MOAs. Due to the highly diverse and noisy properties of cell morphology, we adopted for DeepProfiler embedding retrieval to better account for the variance of cell morphology. The same framework can also be applied to MOA retrieval with gene expression by simply replacing the DeepProfiler embeddings with gene expression vectors and using the Euclidean distance metric.</p><p id="Par26">The retrieval experiments were conducted on the CDRP Target_MOA dataset. For the 69 drugs that act on 10 targets, we used different random seeds to divide them into two groups: one group of 47 (reference set) and another of 22 (query set). We retain the cases where the MOAs corresponding to the query drugs are present in the reference set for validation purposes. These 69 drugs correspond to 35 distinct Mechanisms of Action (MOAs), with some drugs associated with multiple MOAs. This complexity makes the retrieval task challenging. By calculating the Wasserstein distance (DeepProfiler embeddings) and MSE (Gene Expression) between the query set and the reference set, we selected the top <italic toggle="yes">k</italic> closest drugs in the reference set as retrieval results for each query drug. If the correct MOA(s) are the same as or intersect with the MOA(s) of the top <italic toggle="yes">k</italic> nearest drugs, we consider it a correct retrieval. We conducted the top 5 retrieval of MOA(s) on ground-truth DeepProfiler embeddings, MorphDiff(I2I)-generated DeepProfiler embeddings, MorphDiff(G2I)-generated DeepProfiler embeddings, IMPA-generated DeepProfiler embeddings, gene expression, and random retrieval results. To assess the significance of the experimental results, we randomly split the dataset 10 times with different random seeds. Figure&#160;<xref rid="Fig4" ref-type="fig">4</xref>e demonstrates that MorphDiff not only outperforms gene expression but also significantly eclipses IMPA regarding retrieval accuracy, as indicated by <italic toggle="yes">p</italic>&#160;value of &lt;0.05, based on one-sided Wilcoxon signed-rank test with Bonferroni correction. The average accuracy of MorphDiff-generated output outperforms IMPA and gene expression-based retrieval by 16.9% and 8.0% respectively. To further validate the robustness of our methods, we also experimented with <italic toggle="yes">k</italic>&#8201;=&#8201;6,&#160;7,&#160;8,&#160;9,&#160;10 as Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">20</xref> shows and found that both modes of MorphDiff consistently outperform the baseline methods.</p><p id="Par27">In addition to the above evaluation for MOA retrieval, to further demonstrate the effectiveness of the methods, we also evaluated MOA matching. We used two metrics, folds of enrichment<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> and mAP<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>. The details of these two metrics are shown in the Evaluation Metrics section. Intuitively, for each generated cell morphology, these metrics measure whether the top similar ground-truth cell morphology is treated by the drug belonging to the same MOA. As shown in Fig.&#160;<xref rid="Fig4" ref-type="fig">4</xref>f, we found that both modes of MorphDiff consistently outperform the baseline methods when the threshold is set to the top 10%. We also provided the results for different thresholds in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">21</xref> to validate the robustness of our method. As the L1000 gene expression database is much larger than the current cell morphology database, we further explored the potential application of our model to generate the morphology images using the L1000 gene expression data without the corresponding ground-truth morphology images. We constructed a reference set of existing ground-truth morphology images covering 60 types of MOAs and 26112 images, which covers all drugs with available MOAs in the collected CDRP dataset and does not overlap with the CDRP Training set. Subsequently, we generated 2930 cell morphology images for 8 drugs whose MOAs are included in the reference set, but the ground-truth cell morphology images are not yet profiled, allowing us to evaluate the exploration capabilities through MOA matching. Detailed information on these drugs can be found in the Datasets section. The results shown in Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">22</xref> indicate that MorphDiff, in both modes, achieves higher scores on two metrics in different threshold settings, demonstrating its potential to explore the massive perturbed gene expression space.</p><p id="Par28">Furthermore, drugs with similar structures usually have the same target and MOA(s) in most cases<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>. However, it would be more interesting to investigate the drugs with the same MOA(s) but that are structurally dissimilar<sup><xref ref-type="bibr" rid="CR44">44</xref>,<xref ref-type="bibr" rid="CR45">45</xref></sup> to improve biological safety and drug development flexibility. Therefore, we explored whether other modalities, such as gene expression and cell morphology, can provide complementary information to identify these drugs, and we also investigated whether the cell morphology generated by MorphDiff on specific perturbations contains such complementary information.</p><p id="Par29">As shown in Fig.&#160;<xref rid="Fig4" ref-type="fig">4</xref>g, we showed that dimethylfraxetin and dichlorphenamide both belong to Carbonic anhydrase inhibitor, yet their structures are distinctly dissimilar. Meanwhile, the drug embeddings and gene expression of dimethylfraxetin and dichlorphenamide are of substantial distances. In the drug embedding space, BML-259, annotated with the CDK inhibitor, and RD-14620, annotated with the EGFR inhibitor, exhibit structural similarities to dichlorphenamide. Meanwhile, BRD-A72066420, with the PPAR receptor antagonist, is closer to dimethylfraxetin. The structures of these drugs can be found in Fig.&#160;<xref rid="Fig4" ref-type="fig">4</xref>g and Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">23</xref>. In contrast, in the cell morphology space characterized by the DeepProfiler embeddings, we observed that cell morphology treated with dimethylfraxetin and dichlorphenamide have similar feature distributions and can be clearly separated from cell morphology treated with drugs from other MOAs, which indicates that cell morphology could provide complementary information in addition to drug structure and gene expression to identify the MOAs of drugs. We also observed that the cell morphology generated with both modes of MorphDiff also exhibited these patterns, with an overlapping distribution of cell morphology features treated with dimethylfraxetin and dichlorphenamide. The baseline method IMPA, as it only relies on the drug structure to generate the perturbed cell morphology, only generates biased predictions with cell morphology treated with dimethylfraxetin and dichlorphenamide separated far away. An additional example is bezafibrate, BRD-K54708045, and ciglitazone, which are all PPAR receptor agonists. In Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">24</xref>, we observed that their drug embeddings and gene expression are not closely distributed, but BRD-K64402243, belonging to Caspase inhibitor, is closer to ciglitazone, annotated with PPAR receptor agonist. However, in the cell morphology space, we can see that the DeepProfiler embeddings of these three drugs from the same MOA clustered together. Similar to the previous example, MorphDiff(I2I) and MorphDiff(G2I) both successfully capture this pattern, while IMPA generates biased cell morphology. Based on these observations, we found that the relationship between MOAs and gene expression, drug structure, and morphology is complex. None of these modalities alone can perfectly predict the MOA; thus, the retrieval and prediction of MOAs is still a challenging task<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. Integrating shared and complementary information across these modalities will be a key to improving the identification of MOAs of drugs<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> and further advancing drug discovery. In summary, we validated the potential capability of MorphDiff to retrieve and identify MOAs of specific drug perturbations, with consistently better accuracy than IMPA and gene expression and comparable performance with the ground truth. Furthermore, we showed that cell morphology contains complementary information to identify structurally dissimilar drugs with the same MOA, with potential application in advancing phenotypic drug discovery.</p></sec></sec><sec id="Sec7" sec-type="discussion"><title>Discussion</title><p id="Par30">The exploration of cellular state transformation under genetic and drug perturbations enables numerous applications in drug discovery and biological research. Morphological profiling can cost-effectively capture thousands of features across perturbations by disease, mutation, or drug treatments and provide a unique view of cell state. Therefore, we propose MorphDiff, a diffusion-based generative model that can generate high-quality perturbed cell morphology conditioned with perturbed gene expression, efficiently leveraging the shared information between gene expression and cell morphology. We compared MorphDiff with several baseline methods and demonstrated its superiority with extensive experiments on three large-scale datasets. For genetic perturbation datasets, we analyzed the correlation between genes and morphological features, and the results show that MorphDiff effectively captures the pattern between gene expression and morphological profile, establishing a bridge to study the shared information between them. In the case of drug perturbations, MorphDiff successfully predicts the morphological changes caused by various drug perturbations. Furthermore, we applied the pre-trained MorphDiff model to unseen perturbations affecting specific targets and demonstrated its ability to capture diversity at the target level. This showcases the generalizability of MorphDiff and its potential to facilitate the discovery of drug targets. Moreover, our experiments demonstrate further applications in drug discovery, enabling the investigation of drug MOAs through our advanced retrieval pipeline.</p><p id="Par31">MorphDiff operates in two distinct modes: I2I and G2I. The G2I mode utilizes gene expression data exclusively as input, whereas the I2I mode incorporates both gene expression data and control cell morphology images. We have observed that the I2I mode exhibits greater variance in performance compared to the G2I mode. This variability can be attributed primarily to the quality and distribution characteristics of the selected control cell morphology sets used as input for the I2I mode. Our analysis indicates that the quality of the control cell morphology may potentially influence the quality of the generated output. Detailed analysis and tips for filtering DMSO control images can be referred to the Supplementary Notes&#160;<xref rid="MOESM1" ref-type="media">3</xref> and Supplementary Fig.&#160;<xref rid="MOESM1" ref-type="media">25</xref>. Both modes of MorphDiff satisfy the criteria for effective generative modeling, achieving low FID, CMMD, and high scores in Inception Score, density, and coverage metrics. For most application scenarios, either mode is appropriate. However, when users specifically aim to analyze morphological feature changes relative to certain control cells-as discussed in Figs.&#160;<xref rid="Fig3" ref-type="fig">3</xref>c and <xref rid="Fig4" ref-type="fig">4</xref>b MorphDiff (I2I) represents the more suitable option. Nevertheless, users should carefully examine the quality and distribution of selected control morphology images, as these factors can potentially impact the generative performance.</p><p id="Par32">Due to the data heterogeneity and lack of high-quality and massive datasets with matched time-point and concentration information, we do not explicitly encode these properties in our framework. In the future, if there are new datasets with massive L1000 gene expression profiles and cell morphology datasets with high-quality matched time-point and concentration information, our framework can also be easily extended to support explicit encodings of this information. As our model is based on the latent diffusion framework<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, which supports flexible conditioning, we can also add time-point and concentration embeddings as input conditions along with the gene expression profile so that our model could explicitly encode this information as input.</p><p id="Par33">For future work, first, MorphDiff is conditioned on perturbed gene expression, which means that MorphDiff cannot directly be applied to perturbations unmeasured by transcriptomic profiling experiments. Although the L1000 assay<sup><xref ref-type="bibr" rid="CR46">46</xref></sup> already profiles a vast number of diverse perturbations, there are still expectedly diverse new perturbations in the drug development process. Therefore, integrating MorphDiff with methods that can predict changes in gene expression under unseen perturbations, such as GEARS<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>, is a possible extension. Second, the inference of MorphDiff is still costly as it is based on the diffusion model, which is known to be relatively slow in generating new samples. Therefore, the adaptation of more advanced sampling techniques for diffusion models in the future may further improve the efficiency of MorphDiff. Furthermore, though existing works<sup><xref ref-type="bibr" rid="CR9">9</xref>&#8211;<xref ref-type="bibr" rid="CR12">12</xref></sup> and the analyses in this paper have demonstrated remarkable precision in the prediction between gene expression and cell morphology, this problem still remains challenging in some cases. Some perturbations only significantly affect either the transcriptome or cell morphology, while having only subtle and difficult-to-observe effects on the other<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. This phenomenon may arise from the underlying mechanisms of the cell responses to perturbations and various technical confounders in the experimental setup. Such complexity increases the difficulty of accurate prediction and analysis between gene expression and cell morphology, so addressing this challenge could be a meaningful future direction. Thus, incorporating more diverse input conditions, including but not limited to text description, drug structure, and chromatin accessibility in addition to gene expression, may further enhance the utility and generalizability of MorphDiff, making it a more powerful tool in predicting the cell morphology response under various perturbations. In addition, while extensive benchmarks have demonstrated that MorphDiff outperforms other baseline methods in predicting out-of-distribution perturbations, we observed that its performance may degrade when applied to perturbations that deviate significantly from the training dataset distributions (Supplementary Notes&#160;<xref rid="MOESM1" ref-type="media">4</xref>). Although this limitation is expected for most deep learning methods in predicting perturbation response, including previous works such as CellOT<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> and IMPA<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, the curation of large-scale, high-quality, comprehensive datasets and the development of advanced learning paradigms may further enhance generalization performance when predicting responses to distant perturbations, and could be a promising direction for future research. Lastly, MOA prediction remains &#8220;notoriously challenging&#8221; as a major bottleneck in drug discovery, and there is no assay that can reliably be used to identify a majority of known MOA classes successfully<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. Therefore, integrating multimodal information, including but not limited to gene expression, morphological profile, and drug structures, may improve MOA identification accuracy, and combining MorphDiff-generated cell morphology profile is a possible direction in achieving this goal.</p><p id="Par34">The recent explosion of generative AI (GenAI)<sup><xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR49">49</xref>,<xref ref-type="bibr" rid="CR50">50</xref></sup> has significantly transformed many areas. Vivid and high-resolution images and videos can now be generated with simple text descriptions at ultra-speed and impressive quality. We anticipate that cell morphology, as a particular type of image, will also benefit significantly from the advancements of GenAI. Our work MorphDiff, has demonstrated the potential of large-scale generative models to generate high-quality and high-fidelity cell morphology and has explored several potential biological applications. It is anticipated that large-scale pre-training on the increasingly available high-throughput cell morphology profiling datasets<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, combined with rapidly advancing GenAI methods, will enhance the precision and fidelity of cell morphology generation and further advance phenotypic drug discovery.</p></sec><sec id="Sec8"><title>Methods</title><sec id="Sec9"><title>Problem definition</title><p id="Par35">We collected <italic toggle="yes">M</italic> cell morphology <inline-formula id="IEq1"><alternatives><tex-math id="d33e1230">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\{{{{\bf{Y}}}}_{i}\}}_{i=1}^{M}$$\end{document}</tex-math><mml:math id="d33e1235"><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq1.gif"/></alternatives></inline-formula> corresponding to <italic toggle="yes">N</italic> unique perturbations <inline-formula id="IEq2"><alternatives><tex-math id="d33e1259">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\{{p}_{j}\}}_{j=1}^{N}$$\end{document}</tex-math><mml:math id="d33e1264"><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq2.gif"/></alternatives></inline-formula> that can either be genetic perturbation or drug treatment. DMSO refers to cells cultured in Dimethyl sulfoxide, which serves as the control group without perturbation. We use <bold>Y</bold><sub>DMSO</sub> as the cell morphology for the control group. The perturbation for cell morphology <bold>Y</bold><sub><italic toggle="yes">i</italic></sub> is denoted as <italic toggle="yes">q</italic><sub><italic toggle="yes">i</italic></sub>, thus <inline-formula id="IEq3"><alternatives><tex-math id="d33e1301">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${q}_{i}\in {\{{p}_{j}\}}_{j=1}^{N}$$\end{document}</tex-math><mml:math id="d33e1306"><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#8712;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq3.gif"/></alternatives></inline-formula>. The L1000 gene expression corresponds to perturbation <italic toggle="yes">q</italic><sub><italic toggle="yes">i</italic></sub> is denoted as <inline-formula id="IEq4"><alternatives><tex-math id="d33e1339">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{l}}}}_{{q}_{i}}$$\end{document}</tex-math><mml:math id="d33e1344"><mml:msub><mml:mrow><mml:mi mathvariant="bold">l</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq4.gif"/></alternatives></inline-formula>. Our main objective is to train a model <italic toggle="yes">f</italic> that generates the cell morphology conditioned on L1000 gene expression with high fidelity. Concretely, we aim to<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="d33e1360">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\min {\sum }_{i=1}^{M}{{\rm{Distance}}}({{{\bf{Y}}}}_{i},f({{{\bf{l}}}}_{{q}_{i}}))$$\end{document}</tex-math><mml:math id="d33e1366"><mml:mi>min</mml:mi><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msubsup><mml:mi mathvariant="normal">Distance</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">l</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ1.gif"/></alternatives></disp-formula></p><p id="Par36">The cell morphology of the control group may serve as prior information for modeling the cell morphology after perturbation. Thus, <italic toggle="yes">f</italic> can also take <bold>Y</bold><sub>DMSO</sub> as input, which can be written as <inline-formula id="IEq5"><alternatives><tex-math id="d33e1416">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f({{{\bf{l}}}}_{{q}_{i}},{{{\bf{Y}}}}_{{{\rm{DMSO}}}})$$\end{document}</tex-math><mml:math id="d33e1421"><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">l</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">DMSO</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq5.gif"/></alternatives></inline-formula>.</p></sec><sec id="Sec10"><title>MorphDiff model</title><p id="Par37">Following<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, MorphDiff is composed of two parts: Morphology VAE (MVAE) and Latent Diffusion Model (LDM). MVAE compresses the high-dimensional multichannel cell morphology images to low-dimensional latent representation with minimal information loss. LDM is trained to denoise from random Gaussian noise to low-dimensional latent representation by recursively adding Gaussian noise. In practice, a random vector is sampled from the Gaussian distribution and then passed to LDM for the denoise process. Subsequently, the predicted high-quality cell morphology can be decoded from the denoised output of LDM using the MVAE decoder. Such an approach offers a unique advantage: by compressing the high-dimensional cell morphology image to a low-dimensional latent representation, MorphDiff is computationally efficient, as sampling is performed on a low-dimensional space.</p><sec id="Sec11"><title>Morphology VAE (MVAE)</title><p id="Par38">Morphology VAE (MVAE) comprises two parts, encoder <italic toggle="yes">E</italic> and decoder <italic toggle="yes">D</italic>. Given the cell morphology <inline-formula id="IEq6"><alternatives><tex-math id="d33e1465">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\bf{Y}}}\in {{\mathbb{R}}}^{H\times W\times 5}$$\end{document}</tex-math><mml:math id="d33e1470"><mml:mi mathvariant="bold">Y</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>W</mml:mi><mml:mo>&#215;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq6.gif"/></alternatives></inline-formula>, the encoder <italic toggle="yes">E</italic> encodes <bold>Y</bold> into a latent vector <bold>z</bold>&#8201;=&#8201;<italic toggle="yes">E</italic>(<bold>Y</bold>) and the decoder <italic toggle="yes">D</italic> reconstructs the cell morphology <inline-formula id="IEq7"><alternatives><tex-math id="d33e1505">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{{\bf{Y}}}}=D({{\bf{z}}})$$\end{document}</tex-math><mml:math id="d33e1510"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq7.gif"/></alternatives></inline-formula>. Thus, a reconstructive loss <italic toggle="yes">L</italic><sub>rec</sub> can be calculated between <bold>Y</bold> and <inline-formula id="IEq8"><alternatives><tex-math id="d33e1535">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{{\bf{Y}}}}$$\end{document}</tex-math><mml:math id="d33e1540"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq8.gif"/></alternatives></inline-formula>. MVAE is trained in an adversarial manner following<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>, where a patch-based discriminator <italic toggle="yes">D</italic><sub><italic toggle="yes">&#981;</italic></sub> is optimized to classify the original cell morphology from the reconstructed morphology <italic toggle="yes">D</italic>(<bold>z</bold>). The patch-based discriminator is implemented with a multilayer convolutional neural network. On the other hand, it is a common practice in VAE training to regularize the latent <bold>z</bold> to be zero-centered and enforce small variance by introducing a regularizing loss term <italic toggle="yes">L</italic><sub>reg</sub>. A Kullback-Leibler term <italic toggle="yes">L</italic><sub>reg</sub> between <inline-formula id="IEq9"><alternatives><tex-math id="d33e1578">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${q}_{E}({{\bf{z}}}| {{\bf{Y}}})={{\mathcal{N}}}({{\bf{z}}};{E}_{\mu },{E}_{{\sigma }^{2}})$$\end{document}</tex-math><mml:math id="d33e1583"><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">z</mml:mi><mml:mo>&#8739;</mml:mo><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">z</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>&#956;</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq9.gif"/></alternatives></inline-formula> and the standard normal distribution <inline-formula id="IEq10"><alternatives><tex-math id="d33e1625">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\mathcal{N}}}({{\bf{z}}};0,{{\bf{I}}})$$\end{document}</tex-math><mml:math id="d33e1630"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">z</mml:mi><mml:mo>;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq10.gif"/></alternatives></inline-formula> is adopted to regularize the latent representation <italic toggle="yes">z</italic>. Additionally, a LPIPS loss<sup><xref ref-type="bibr" rid="CR51">51</xref></sup> (<italic toggle="yes">L</italic><sub>lpips</sub>) is applied to minimize the difference between the latent features of ground-truth images and those of generated images. The overall objective of training MVAE can be summarized as follows:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="d33e1658">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{{\rm{MVAE}}}}={\min }_{E,D}{\max }_{\phi }({L}_{{{\rm{rec}}}}({{\bf{Y}}},D(E({{\bf{Y}}})))+\log {D}_{\phi }({{\bf{Y}}})+{L}_{{{\rm{reg}}}}({{\bf{Y}}};E,D))+{L}_{{{\rm{lpips}}}}({{\bf{Y}}},D(E({{\bf{Y}}})))$$\end{document}</tex-math><mml:math id="d33e1664"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">MVAE</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mrow><mml:mi>&#981;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">rec</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>&#981;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">reg</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi><mml:mo>;</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">lpips</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ2.gif"/></alternatives></disp-formula></p></sec><sec id="Sec12"><title>Learned perceptual image patch similarity (LPIPS) loss in MVAE</title><p id="Par39">The origin framework of VAE in the Stable Diffusion model<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> employs LPIPS loss<sup><xref ref-type="bibr" rid="CR51">51</xref></sup> to minimize the difference between ground-truth images and generated images. The principle of LPIPS loss is to extract features of images with 5 conv layers from a pre-trained VGG network<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>, and compute <italic toggle="yes">l</italic><sub>2</sub> distance between ground-truth features and the generated features output from each layer. The integration of LPIPS will significantly improve the fidelity of VAE generation. However, as the pre-trained VGG model was trained with 3-channel images (RGB input), it is inconsistent with our 5-channel input (DNA, ER, RNA, AGP, Mito input). Therefore, we duplicate each channel from a shape of (128, 128) to (3, 128, 128) to ensure that the images from each channel are compatible with the input shape required by VGG. We compute LPIPS loss for each channel, respectively, and average the sum of loss across five channels. The formulation can be written as:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="d33e1790">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{i}({{{\bf{x}}}}_{i},{{{\bf{x}}}}_{0i})={\sum}_{l}\frac{1}{{H}_{l}{W}_{l}}{\sum}_{h,w}| | {{{\bf{w}}}}_{l}\odot ({\hat{{{\bf{y}}}}}_{{{\rm{ihw}}}}^{l}-{\hat{{{\bf{y}}}}}_{{{\rm{0ihw}}}}^{l})| {| }_{2}^{2}$$\end{document}</tex-math><mml:math id="d33e1796"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>&#8739;</mml:mo><mml:mo>&#8739;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>&#8857;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ihw</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">0ihw</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8739;</mml:mo><mml:msubsup><mml:mrow><mml:mo>&#8739;</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ3.gif"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="d33e1900">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d({{\bf{x}}},{{{\bf{x}}}}_{0})=\frac{1}{5}{\sum}_{i}{d}_{i}({{{\bf{x}}}}_{i},{{{\bf{x}}}}_{0i})$$\end{document}</tex-math><mml:math id="d33e1906"><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ4.gif"/></alternatives></disp-formula><italic toggle="yes">l</italic> represents <italic toggle="yes">l</italic>th layer in 5-layer VGG, and <bold>w</bold><sup><italic toggle="yes">l</italic></sup> is the parameter used to scale the activations. <bold>x</bold><sub><italic toggle="yes">i</italic></sub> and <bold>x</bold><sub>0<italic toggle="yes">i</italic></sub> represent the ground-truth image and the generated image in ith channel, respectively, while <inline-formula id="IEq11"><alternatives><tex-math id="d33e1983">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{{{\bf{y}}}}}_{i}^{l}$$\end{document}</tex-math><mml:math id="d33e1988"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq11.gif"/></alternatives></inline-formula> and <inline-formula id="IEq12"><alternatives><tex-math id="d33e2003">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{{{\bf{y}}}}}_{0i}^{l}$$\end{document}</tex-math><mml:math id="d33e2008"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq12.gif"/></alternatives></inline-formula> are adopted as corresponding features obtained from the <italic toggle="yes">l</italic>th layer. H<italic toggle="yes">l</italic> and W<italic toggle="yes">l</italic> are height and width of embeddings output from the <italic toggle="yes">l</italic>th layer.</p></sec><sec id="Sec13"><title>Latent diffusion model (LDM)</title><p id="Par40">Latent diffusion model (LDM) contains a noising and denoising process. Given a sample <bold>z</bold><sub>0</sub>&#160;&#8712;&#160;<italic toggle="yes">q</italic>(<bold>z</bold>) where <italic toggle="yes">q</italic>(<bold>z</bold>) is the distribution of cell morphology latent representation. The noising process progressively adds Gaussian noise for <italic toggle="yes">T</italic> steps and obtains <bold>z</bold><sub>1</sub>,&#160;<bold>z</bold><sub>2</sub>,&#160;&#8230;,&#160;<bold>z</bold><sub><italic toggle="yes">T</italic></sub>. The formulation of the noising process can be written as:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="d33e2076">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$q({{{\bf{z}}}}_{t}| {{{\bf{z}}}}_{t-1})={{\mathcal{N}}}({{{\bf{z}}}}_{t};\sqrt{{\alpha }_{t}}{{{\bf{z}}}}_{t-1},(1-{\alpha }_{t}){{\bf{I}}})$$\end{document}</tex-math><mml:math id="d33e2082"><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#8739;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ5.gif"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="d33e2147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$q({{{\bf{z}}}}_{1:T}| {{{\bf{z}}}}_{0})={\prod }_{t=1}^{T}q({{{\bf{z}}}}_{t}| {{{\bf{z}}}}_{t-1})$$\end{document}</tex-math><mml:math id="d33e2153"><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>&#8739;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8719;</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#8739;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ6.gif"/></alternatives></disp-formula>where <italic toggle="yes">q</italic>(<bold>z</bold><sub><italic toggle="yes">t</italic></sub>&#8739;<bold>z</bold><sub><italic toggle="yes">t</italic>&#8722;1</sub>) can be interpreted as obtaining <bold>z</bold><sub><italic toggle="yes">t</italic></sub> by adding Gaussian noise to <bold>z</bold><sub><italic toggle="yes">t</italic>&#8722;1</sub> parameterized by 1&#8201;&#8722;&#8201;<italic toggle="yes">&#945;</italic><sub><italic toggle="yes">t</italic></sub>. We denote <inline-formula id="IEq13"><alternatives><tex-math id="d33e2243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\alpha }_{t}={\prod }_{i=1}^{t}{\alpha }_{i}$$\end{document}</tex-math><mml:math id="d33e2248"><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>&#8719;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq13.gif"/></alternatives></inline-formula>. The denoising process aims to train a denoising network to recursively remove the noise from <bold>z</bold><sub><italic toggle="yes">t</italic></sub>
<inline-formula id="IEq14"><alternatives><tex-math id="d33e2278">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({{{\bf{z}}}}_{t}=\sqrt{{\alpha }_{t}}{{{\bf{z}}}}_{t-1}+(1-{\alpha }_{t})\epsilon )$$\end{document}</tex-math><mml:math id="d33e2283"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#1013;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq14.gif"/></alternatives></inline-formula> and <inline-formula id="IEq15"><alternatives><tex-math id="d33e2325">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon \sim {{\mathcal{N}}}(0,{{\bf{I}}})$$\end{document}</tex-math><mml:math id="d33e2330"><mml:mi>&#1013;</mml:mi><mml:mo>~</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq15.gif"/></alternatives></inline-formula>. Concretely, the denoising process can be formulated as follows, where <italic toggle="yes">p</italic><sub><italic toggle="yes">&#952;</italic></sub>(<bold>z</bold><sub><italic toggle="yes">t</italic>&#8722;1</sub>&#8739;<bold>z</bold><sub><italic toggle="yes">t</italic></sub>) denotes the probability distribution of <bold>z</bold><sub><italic toggle="yes">t</italic>&#8722;1</sub> given <bold>z</bold><sub><italic toggle="yes">t</italic></sub>:<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="d33e2379">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{\theta }({{{\bf{z}}}}_{t-1}| {{{\bf{z}}}}_{t})={{\mathcal{N}}}({{{\bf{z}}}}_{t-1};{\mu }_{\theta }({{{\bf{z}}}}_{t},t),{\Sigma }_{\theta }({{{\bf{z}}}}_{t},t))$$\end{document}</tex-math><mml:math id="d33e2385"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#8739;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>&#956;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">&#931;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ7.gif"/></alternatives></disp-formula><disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="d33e2463">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{\theta }({{{\bf{z}}}}_{0:T})=p({{{\bf{z}}}}_{T}){\prod }_{t=1}^{T}{p}_{\theta }({{{\bf{z}}}}_{t-1}| {{{\bf{z}}}}_{t})$$\end{document}</tex-math><mml:math id="d33e2469"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8719;</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#8739;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ8.gif"/></alternatives></disp-formula><italic toggle="yes">&#956;</italic><sub><italic toggle="yes">&#952;</italic></sub>(<bold>z</bold><sub><italic toggle="yes">t</italic></sub>,&#160;<italic toggle="yes">t</italic>) and <italic toggle="yes">&#931;</italic><sub><italic toggle="yes">&#952;</italic></sub>(<bold>z</bold><sub><italic toggle="yes">t</italic></sub>,&#160;<italic toggle="yes">t</italic>) are the Gaussian mean and variance by the denoising network <italic toggle="yes">&#952;</italic>. Similar to other generative models, the loss function of LDM can be formulated as maximizing the log-likelihood of the samples generated belonging to the original data distribution (<inline-formula id="IEq16"><alternatives><tex-math id="d33e2568">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\log ({p}_{\theta }({{{\bf{z}}}}_{0}))$$\end{document}</tex-math><mml:math id="d33e2573"><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq16.gif"/></alternatives></inline-formula>). However, direct optimization is intractable, as we need to integrate the <italic toggle="yes">T</italic> steps into the latent space. For L1000 gene expression <bold>l</bold>, we encode it as an intermediate representation and map it to UNet through cross-attention. Note that the encoding process is not learnable and is a simple linear transformation, which is different from the training method in conditional latent diffusion<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. This is because L1000 gene counts are already processed in ref. <sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, so we believe it is better to map it to UNet directly. The encoder is represented as EC. Following DDPM<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>, we can simplify the learning objective as:<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="d33e2615">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L={{\mathbb{E}}}_{{{\bf{z}}},\epsilon \sim {{\mathcal{N}}}(0,{{\bf{I}}}),t}| | \epsilon -{\epsilon }_{\theta }({{{\bf{z}}}}_{t},t,{{\rm{EC}}}({{\bf{l}}}))| {| }_{2}^{2}$$\end{document}</tex-math><mml:math id="d33e2621"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">z</mml:mi><mml:mo>,</mml:mo><mml:mi>&#1013;</mml:mi><mml:mo>~</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#8739;</mml:mo><mml:mo>&#8739;</mml:mo><mml:mi>&#1013;</mml:mi><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>&#1013;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">EC</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8739;</mml:mo><mml:msubsup><mml:mrow><mml:mo>&#8739;</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ9.gif"/></alternatives></disp-formula><bold>z</bold><sub><italic toggle="yes">t</italic></sub> is a noisy version of <bold>z</bold><sub>0</sub> at step <italic toggle="yes">t</italic> and <italic toggle="yes">&#1013;</italic><sub><italic toggle="yes">&#952;</italic></sub>(<bold>z</bold><sub><italic toggle="yes">t</italic></sub>,&#160;<italic toggle="yes">t</italic>,&#160;EC(<bold>l</bold>)) is a denoising network intended to predict <italic toggle="yes">&#1013;</italic> from <bold>z</bold><sub><italic toggle="yes">t</italic></sub> conditioned on L1000 gene expression <bold>l</bold>. The cross-attention for the intermediate layer <italic toggle="yes">ith</italic> in UNet can be represented as <inline-formula id="IEq17"><alternatives><tex-math id="d33e2734">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\rm{Attention}}}({{\bf{Q}}},{{\bf{K}}},{{\bf{V}}})={{\rm{softmax}}}(\frac{{{{\bf{QK}}}}^{T}}{\sqrt{d}})\cdot {{\bf{V}}}$$\end{document}</tex-math><mml:math id="d33e2739"><mml:mi mathvariant="normal">Attention</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">K</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">softmax</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">QK</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8901;</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq17.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq18"><alternatives><tex-math id="d33e2778">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\bf{Q}}}={{{\bf{W}}}}_{{{\bf{Q}}}}^{(i)}\cdot {\varphi }_{i}({{{\bf{z}}}}_{t}),{{\bf{K}}}={{{\bf{W}}}}_{k}^{(i)}\cdot {{\rm{EC}}}({{\bf{l}}}),{{\bf{V}}}={{{\bf{W}}}}_{{{\bf{V}}}}^{(i)}\cdot {{\rm{EC}}}({{\bf{l}}})$$\end{document}</tex-math><mml:math id="d33e2783"><mml:mi mathvariant="bold">Q</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#8901;</mml:mo><mml:msub><mml:mrow><mml:mi>&#966;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="bold">K</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#8901;</mml:mo><mml:mi mathvariant="normal">EC</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#8901;</mml:mo><mml:mi mathvariant="normal">EC</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq18.gif"/></alternatives></inline-formula>. <italic toggle="yes">&#966;</italic><sub><italic toggle="yes">i</italic></sub>(<bold>z</bold><sub><italic toggle="yes">t</italic></sub>) denotes an intermediate representation in UNet, and <inline-formula id="IEq19"><alternatives><tex-math id="d33e2883">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{W}}}}_{{{\bf{Q}}}}^{(i)},{{{\bf{W}}}}_{{{\bf{K}}}}^{(i)}$$\end{document}</tex-math><mml:math id="d33e2888"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq19.gif"/></alternatives></inline-formula> and <inline-formula id="IEq20"><alternatives><tex-math id="d33e2918">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{W}}}}_{{{\bf{V}}}}^{(i)}$$\end{document}</tex-math><mml:math id="d33e2923"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq20.gif"/></alternatives></inline-formula> are learnable matrices. Following DDPM<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>, the detailed LDM training and sampling algorithm is shown as Algorithm 1 and Algorithm 2:</p><sec id="FPar1"><title>Algorithm 1</title><p id="Par41">Training Algorithm of MorphDiff</p><p id="Par42">1: <bold>repeat</bold></p><p id="Par43">2: &#8195;<bold>z</bold><sub>0</sub>&#160;~&#160;<italic toggle="yes">q</italic>(<bold>z</bold><sub>0</sub>)</p><p id="Par44">3: &#8195;<italic toggle="yes">t</italic>&#160;~&#160;Uniform({1,&#160;&#8230;,&#160;<italic toggle="yes">T</italic>&#8201;})</p><p id="Par45">4: &#8195;<inline-formula id="IEq21"><alternatives><tex-math id="d33e2974">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon \sim {{\mathcal{N}}}(0,{{\bf{I}}})$$\end{document}</tex-math><mml:math id="d33e2979"><mml:mi>&#1013;</mml:mi><mml:mo>~</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq15.gif"/></alternatives></inline-formula></p><p id="Par46">5: Take the gradient descent step on <inline-formula id="IEq22"><alternatives><tex-math id="d33e2995">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\nabla }_{\theta }\parallel \epsilon -{\epsilon }_{\theta }\left(\sqrt{{\overline{\alpha }}_{t}}{z}_{0}+\sqrt{1-{\overline{\alpha }}_{t}}\epsilon,t,{{\rm{EC}}}({{\bf{l}}})\right){\parallel }^{2}$$\end{document}</tex-math><mml:math id="d33e3000"><mml:msub><mml:mrow><mml:mo>&#8711;</mml:mo></mml:mrow><mml:mrow><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mo>&#8741;</mml:mo><mml:mi>&#1013;</mml:mi><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>&#1013;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mo accent="true">&#175;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mo accent="true">&#175;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mi>&#1013;</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">EC</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfenced><mml:msup><mml:mrow><mml:mo>&#8741;</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq22.gif"/></alternatives></inline-formula></p><p id="Par47">6: <bold>until</bold> converged</p></sec><sec id="FPar2"><title>Algorithm 2</title><p id="Par48">Sampling Algorithm of MorphDiff</p><p id="Par49">1: &#8201;&#8201;&#8201;<inline-formula id="IEq23"><alternatives><tex-math id="d33e3075">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{z}}}}_{T} \sim {{\mathcal{N}}}(0,{{\bf{I}}})$$\end{document}</tex-math><mml:math id="d33e3080"><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq23.gif"/></alternatives></inline-formula></p><p id="Par50">2: &#8201;&#8201;<bold>for</bold>
<italic toggle="yes">t</italic>&#8201;=&#8201;<italic toggle="yes">T</italic>,&#160;&#8230;,&#160;1 <bold>do</bold></p><p id="Par51">3: &#8201;&#8201;&#8195;<bold>if</bold>
<italic toggle="yes">t</italic>&#8201;&gt;&#8201;1 <bold>then</bold></p><p id="Par52">4: &#8201;&#8201;&#8195;&#8195;<inline-formula id="IEq24"><alternatives><tex-math id="d33e3124">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\bf{z}}} \sim {{\mathcal{N}}}(0,{{\bf{I}}})$$\end{document}</tex-math><mml:math id="d33e3129"><mml:mi mathvariant="bold">z</mml:mi><mml:mo>~</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq24.gif"/></alternatives></inline-formula></p><p id="Par53">5: &#8201;&#8201;&#8195;<bold>else</bold></p><p id="Par54">6: &#8201;&#8201;&#8195;&#8195;<bold>z</bold>&#8201;=&#8201;0</p><p id="Par55">7: &#8201;&#8201;&#8195;<bold>end if</bold></p><p id="Par56">8: &#8201;&#8201;&#8195;<inline-formula id="IEq25"><alternatives><tex-math id="d33e3159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{z}}}}_{t-1}=\frac{1}{\sqrt{{\alpha }_{t}}}\left({{{\bf{z}}}}_{t}-\frac{1-{\alpha }_{t}}{1-\sqrt{{\overline{\alpha }}_{t}}}{\epsilon }_{\theta }({{{\bf{z}}}}_{t},t,{{\rm{EC}}}({{\bf{l}}}))\right)+{\sigma }_{t}{{\bf{z}}}$$\end{document}</tex-math><mml:math id="d33e3164"><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mo accent="true">&#175;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>&#1013;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">EC</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">z</mml:mi></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq25.gif"/></alternatives></inline-formula></p><p id="Par57">9: &#8201;&#8201;<bold>end for</bold></p><p id="Par58">10: <bold>return</bold><bold>z</bold><sub>0</sub></p></sec></sec><sec id="Sec14"><title>Implementation of LDM</title><p id="Par59">LDM (<italic toggle="yes">&#1013;</italic><sub><italic toggle="yes">&#952;</italic></sub>(<bold>z</bold><sub><italic toggle="yes">t</italic></sub>,&#160;<italic toggle="yes">t</italic>,&#160;<bold>l</bold>)) is implemented with the UNet<sup><xref ref-type="bibr" rid="CR54">54</xref></sup> architecture augmented with an attention mechanism following<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. Concretely, the base UNet architecture uses a stack of residual layers and downsampling convolutions, followed by a stack of residual layers with upsampling convolutions, with skip connections connecting the layers with the same spatial size. We use the UNet variant from<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> and replace the self-attention layer with alternating layers of (a) self-attention, (b) position-wise MLP, and (c) cross-attention layer. To inject the L1000 gene expression <italic toggle="yes">l</italic> as a condition in the denoising UNet, we use the encoder(EC) same as when training to project <bold>l</bold> into an intermediate representation EC(<bold>l</bold>). The intermediate representation EC(<bold>l</bold>) is then mapped to each cross-attention layer (<inline-formula id="IEq26"><alternatives><tex-math id="d33e3312">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\rm{Attention}}}({{\bf{Q}}},{{\bf{K}}},{{\bf{V}}})={{\rm{softmax}}}\left(\frac{{{{\bf{QK}}}}^{T}}{\sqrt{d}}\right){{\bf{V}}}$$\end{document}</tex-math><mml:math id="d33e3317"><mml:mi mathvariant="normal">Attention</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">K</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">softmax</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">QK</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mi mathvariant="bold">V</mml:mi></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq26.gif"/></alternatives></inline-formula>) of UNet with<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="d33e3353">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\bf{Q}}}={{{\bf{W}}}}_{{{\bf{Q}}}}^{(i)}\cdot {\phi }_{i}({{{\bf{z}}}}_{t}),{{\bf{K}}}={{{\bf{W}}}}_{{{\bf{K}}}}^{(i)}\cdot {\tau }_{\theta }({{\bf{l}}}),{{\bf{V}}}={{{\bf{W}}}}_{{{\bf{V}}}}^{(i)}\cdot {{\rm{EC}}}({{\bf{l}}})$$\end{document}</tex-math><mml:math id="d33e3359"><mml:mi mathvariant="bold">Q</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#8901;</mml:mo><mml:msub><mml:mrow><mml:mi>&#981;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="bold">K</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#8901;</mml:mo><mml:msub><mml:mrow><mml:mi>&#964;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#8901;</mml:mo><mml:mi mathvariant="normal">EC</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ10.gif"/></alternatives></disp-formula><italic toggle="yes">&#981;</italic><sub><italic toggle="yes">i</italic></sub>(<bold>z</bold><sub><italic toggle="yes">t</italic></sub>) is the learnable intermediate representation in the latent space of the denoising UNet and <inline-formula id="IEq27"><alternatives><tex-math id="d33e3462">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{W}}}}_{{{\bf{Q}}}}^{(i)}$$\end{document}</tex-math><mml:math id="d33e3467"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq27.gif"/></alternatives></inline-formula>, <inline-formula id="IEq28"><alternatives><tex-math id="d33e3483">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{W}}}}_{{{\bf{V}}}}^{(i)}$$\end{document}</tex-math><mml:math id="d33e3488"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq20.gif"/></alternatives></inline-formula> and <inline-formula id="IEq29"><alternatives><tex-math id="d33e3504">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{W}}}}_{{{\bf{K}}}}^{(i)}$$\end{document}</tex-math><mml:math id="d33e3509"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq29.gif"/></alternatives></inline-formula> are learnable matrices.</p></sec></sec><sec id="Sec15"><title>Datasets</title><sec id="Sec16"><title>Image processing</title><p id="Par60">The images collected from CDRP<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, JUMP<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>, and LINCS<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> are all bulk-level cell plate images. To enable fine-grained analysis at the single-cell image level. We used the CellProfiler software<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> version 4.2.5 to segment bulk-level cell plate images and get the single-cell level images. Concretely, we used the IdentifyPrimaryObejects and IdentifySecondaryObjects functions to identify individual objects(cells) in the images. The threshold strategy is set to global, and the thresholding method is set to minimum cross-entropy.</p></sec><sec id="Sec17"><title>JUMP dataset (U2OS cell line)</title><p id="Par61">We collected cell morphology images of cells treated with 130 different gene overexpression perturbations from the JUMP Cell Painting dataset<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> with the script from <ext-link ext-link-type="uri" xlink:href="https://github.com/jump-cellpainting/datasets/">https://github.com/jump-cellpainting/datasets/</ext-link>. Each image consists of five channels, namely mitochondria (MitoTracker; Mito), nucleus (Hoechst; DNA), nucleoli and cytoplasmic RNA (SYTO 14; RNA), endoplasmic reticulum (concanavalin A; ER), Golgi and plasma membrane (wheat germ agglutinin (WGA); AGP) and actin cytoskeleton (phalloidin; AGP). Meanwhile, we collected the bulk gene expression from the database<sup><xref ref-type="bibr" rid="CR46">46</xref></sup> with the same cell line and perturbations. L1000 gene expression in this dataset contains 12328 genes. The gene expression and the cell morphology images can thus be aligned according to perturbation information. The total number of categories is 131, including 130 perturbations and control set. After that, we split the dataset into three sets, which are the training set, ID (in-distribution) set, and OOD (out-of-distribution) set. Firstly, we randomly picked 10 percent of perturbations as OOD sets, resulting in 13 perturbations. The remaining parts were randomly split into training set (90 percent) and ID set(10 percent), which indicates that the training set and the ID set contain both control and perturbation data. We termed them as JUMP Training set, JUMP ID set, and JUMP OOD set. Detailed information on these genes and their related pathways can be found in Supplementary Data&#160;<xref rid="MOESM4" ref-type="media">1</xref>.</p></sec><sec id="Sec18"><title>CDRP dataset (U2OS cell line)</title><p id="Par62">We collected cell morphology images of cells treated with 959 different small molecules on 10 different plates (plate 25593, 25594, 25598, 25599, 26128, 26133, 26135, 26601, 266607, 26608) from CDRP<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, by script <ext-link ext-link-type="uri" xlink:href="https://github.com/gigascience/paper-bray2017/blob/master/download_cil_images.sh">https://github.com/gigascience/paper-bray2017/blob/master/download_cil_images.sh</ext-link>. All images consist of five channels, recording information from nucleus, Endoplasmic reticulum, Nucleoli and cytoplasmic RNA, Golgi and plasma membrane, and Mitochondria. The concrete correspondence between dye names, cell structures, and CellProfiler names can be found in Supplementary Table&#160;<xref rid="MOESM1" ref-type="media">1</xref>. We also collected the bulk gene expression from <ext-link ext-link-type="uri" xlink:href="https://broad.io/rosetta/">https://broad.io/rosetta/</ext-link>&#160;and L1000 gene expression in this dataset containing 977 genes. After aligning the gene expression data with morphological images for the same perturbations at identical concentrations, we identified a total of 960 categories, comprising 959 perturbations and a control set. Following the same split principle as the JUMP dataset, we obtained 96 perturbations of the OOD set and 863 perturbations plus control for the training set and the ID set. We termed them as CDRP Training set, CDRP ID set, and CDRP OOD set. Detailed information on these drugs can be found in Supplementary Data&#160;<xref rid="MOESM5" ref-type="media">2</xref>.</p><p id="Par63">To assess our model&#8217;s ability to capture features on target and MOAs levels, we collected data with target and MOA labels. We additionally selected 10 targets (69 drugs annotated with 35 MOAs) from CDRP<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> (from plate 24277, 24278, 24294, 24301, 24305, 24310, 24319, 25739), for which enough corresponding drugs, gene expression<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, and images could be collected for analysis and test. These data do not overlap with the CDRP Train set mentioned above. The targets are <italic toggle="yes">NR3C1</italic>, <italic toggle="yes">EGFR</italic>, <italic toggle="yes">PPARG</italic>, <italic toggle="yes">CASP3</italic>, <italic toggle="yes">CDK2</italic>, <italic toggle="yes">CDK1</italic>, <italic toggle="yes">HMGCR</italic>, <italic toggle="yes">CA12</italic>, <italic toggle="yes">PRKACA</italic> and <italic toggle="yes">TOP2A</italic>. After the matching and cropping process, we got 2222 images for <italic toggle="yes">NR3C1</italic>, 707 images for <italic toggle="yes">EGFR</italic>, 793 images for <italic toggle="yes">PPARG</italic>, 466 images for <italic toggle="yes">CASP3</italic>, 435 images for <italic toggle="yes">CDK2</italic>, 342 images for <italic toggle="yes">CDK1</italic>, 475 images for <italic toggle="yes">HMGCR</italic>, 327 images for <italic toggle="yes">CA12</italic>, 496 images for <italic toggle="yes">PRKACA</italic>, 51 images for <italic toggle="yes">EGFR</italic>. We termed this set as CDRP Target_MOA set. Detailed information on these compounds can be found in the Supplementary Data&#160;<xref rid="MOESM6" ref-type="media">3</xref>.</p></sec><sec id="Sec19"><title>LINCS dataset (A549 cell line)</title><p id="Par64">We collected the bulk gene profiles from<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> (LINCS part) and downloaded the corresponding images from<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>. In this dataset, we selected 61 drugs that have sufficient images, along with available MOA and target labels. The components of these images are the same as those in the U2OS dataset. We matched the gene expression and morphology images in the same way as CDRP. To construct the dataset for model validation, we first divided the data into 10 folds according to the 10 targets corresponding to 21 drugs. We termed it as LINCS Target leave-one-out set. For each experiment, we trained the model on another 9 folds and validated it on the remaining fold. We performed the same operation for the 10 MOAs (42 drugs) and termed it as LINCS MOA leave-one-out set. The details of the drug can be found in the Supplementary Data&#160;<xref rid="MOESM7" ref-type="media">4</xref> and <xref rid="MOESM8" ref-type="media">5</xref>.</p></sec><sec id="Sec20"><title>Exploratory analysis on L1000 dataset without corresponding morphology images</title><p id="Par65">As the L1000 datasets cover more perturbations compared with the Cell Painting datasets, we added additional evaluation on datasets containing L1000 perturbed gene expression profiles, and the perturbations covered in the dataset have not been applied to Cell Painting assays. Thus, there are no ground-truth cell morphology datasets regarding these perturbations. For evaluation purposes, we only retained the drugs whose MOA annotations are present in our collected CDRP dataset.</p><p id="Par66">We constructed a reference set containing perturbed morphology images, comprising 251 drugs annotated with 60 MOAs, containing 26,112 single-cell images. These images were downloaded from CDRP<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> and processed using CellProfiler. In particular, these drugs do not overlap with the CDRP training set used to pre-train the model. For L1000 gene expression data without corresponding annotations (query drugs), we collected 8 drugs annotated with 6 MOAs (293 gene expressions) from<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, with their MOAs available in the reference set to facilitate validation of the MOA matching performance. We generated 2930 single-cell images for query drugs. Detailed information on query drugs and reference drugs can be found in the supplementary files Supplementary Data&#160;<xref rid="MOESM9" ref-type="media">6</xref> and &#160;<xref rid="MOESM10" ref-type="media">7</xref>.</p></sec><sec id="Sec21"><title>Statistical tests for assessing the distribution difference</title><p id="Par67">We performed statistical tests to assess whether the OOD set and leave-one-out set exhibit statistically significant distribution differences from the training set. Specifically, we conducted two statistical tests: Energy Distance tests<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>, and Maximum Mean Discrepancy tests<sup><xref ref-type="bibr" rid="CR56">56</xref></sup> to evaluate the distribution differences between the DeepProfiler embeddings of the training set and the ID/OOD sets. For the Energy Distance test, we employed the dcor.homogeneity.energy_test function from the dcor package<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>. The energy test assesses whether multiple groups originate from the same distribution by examining the Euclidean distances between data points. This method compares point-pairwise distances within each group to those between different groups. If points are more closely clustered within their own groups than with points from other groups, this pattern indicates that these groups likely stem from different underlying distributions. For the Maximum Mean Discrepancy (MMD) tests<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>, we determined if two groups come from different distributions by measuring their distance in a high-dimensional feature space. The key steps are: (1) transform data using an RBF kernel, (2) calculate the MMD statistic by comparing within-group similarities to between-group similarities, and (3) assess significance through permutation testing-repeatedly shuffling labels and recalculating MMD statistic to generate a null distribution. Due to the computational complexity of these two analysis, we randomly sampled 2000 cell morphology images from each dataset and conducted tests using 999 permutations. To ensure robustness and stability, we repeated all statistical tests for 10 rounds. The statistic values and <italic toggle="yes">p</italic>&#160;values for the JUMP dataset, CDRP dataset, LINCS Target leave-one-out set, and LINCS MOA leave-one-out set across all three types of tests are presented in Supplementary Tables&#8201;<xref rid="MOESM1" ref-type="media">3</xref>&#8211;<xref rid="MOESM1" ref-type="media">10</xref>. The statistical testing results consistently demonstrate that the training set and the OOD or leave-one-out sets derive from distributions with statistically significant differences, while the training set and the ID set derive from distributions with no significant differences. This validation confirms that our performance evaluation on the OOD set and leave-one-out set effectively assesses model performance on distributions outside the domain of the training set.</p></sec></sec><sec id="Sec22"><title>Evaluation setup</title><sec id="Sec23"><title>Evaluation setup across baseline methods</title><p id="Par68">Among all the baseline methods evaluated in the manuscript, only MorphDiff and IMPA support training and generation with the original five-channel input images, while the other baseline methods only support three-channel RGB images as input and output. Therefore, to fairly assess different methods, we devised the following evaluation strategy following previous works<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. During training, methods that directly support five-channel cell morphology images as input (MorphDiff and IMPA) were trained using these five-channel images. For methods that originally could only process RGB three-channel images, we modified their implementations to enable them to accept and generate five-channel images. For performance benchmarking, the five generative metrics can only be applied to three-channel RGB images. Therefore, we converted the five-channel output to three-channel images for benchmarking, following the methodology outlined in CellProfiler<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. The weights assigned to the different channels are as follows: <bold>ER</bold>(1,&#160;0,&#160;0), <bold>RNA</bold>(0,&#160;1,&#160;0), <bold>DNA</bold>(0,&#160;0,&#160;1), <bold>Mito</bold>(0.5,&#160;0.5,&#160;0), <bold>AGP</bold>(0.5,&#160;0,&#160;0.5). Consequently, the resulting composited image is calculated as: (1&#8727;<bold>ER</bold>&#8201;+&#8201;0.5&#8727;<bold>Mito</bold>&#8201;+&#8201;0.5&#8727;<bold>AGP</bold>,&#160;1&#8727;<bold>RNA</bold>&#8201;+&#8201;0.5&#8727;<bold>Mito</bold>,&#160;1&#8727;<bold>DNA</bold>&#8201;+0.5&#8727;<bold>AGP</bold>).</p></sec><sec id="Sec24"><title>Morphological feature extraction</title><p id="Par69">To evaluate the fidelity of the generated single-cell morphology images, we utilized widely used single-cell morphology feature extraction methods, including CellProfiler<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> and DeepProfiler<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. CellProfiler is based on traditional image feature extraction methods, which could produce interpretable morphological features, while DeepProfiler is based on a trained deep neural network to extract low-dimensional dense embeddings of cell morphology images. CellProfiler is used to extract features from single-cell morphology images, allowing for a comparison between the features of ground-truth cell morphology and those of generated cell morphology. This evaluation is mainly for assessing the similarity between ground truth and generated cell morphology images on the interpretable feature sets because these features are usually involved in downstream analysis with respect to cell morphology images, such as BioMorph<sup><xref ref-type="bibr" rid="CR57">57</xref></sup> and Cytominer<sup><xref ref-type="bibr" rid="CR58">58</xref></sup>. Some functions provided by CellProfiler are merely used for the extraction of bulk-level image characteristics, thus, we selected several functions that can extract meaningful features from single-cell images. We employed MeasureColocalization (Measuring the correlation between any two channels), MeasureGranularity (Measuring the size and intensity of granular structures), MeasureImageIntensity (Measuring the intensity), MeasureTexture (Measuring the smoothness, coarseness, and regularity). Features with NaN values and zero variance are removed. Meanwhile, features with duplicated meaning and functions are also removed (e.g., sum and mean of intensity). After these processing and filtering steps, more than 200 CellProfiler features are kept for further analysis.</p><p id="Par70">DeepProfiler<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> is a tool that can extract dense embeddings from morphology images with a five-channel input. We used it following the handbook provided by the authors. The handbook can be found at <ext-link ext-link-type="uri" xlink:href="https://cytomining.github.io/DeepProfiler-handbook/docs/00-welcome.html">https://cytomining.github.io/DeepProfiler-handbook/docs/00-welcome.html</ext-link>.</p></sec><sec id="Sec25"><title>Morphological feature selection based on discriminability of perturbations</title><p id="Par71">CellProfiler Morphological features measure the cell morphology from multiple perspectives. Some morphological features may be highly correlated with the gene expression, while some may not depend on gene expression or perturbation. Thus, to select the most informative morphological features related to gene expression and perturbation for downstream analysis, we trained a random forest classifier from morphological features to predict the corresponding perturbations. We set the number of estimators to 100 and selected the top 10 features of the highest importance. The features of the highest importance in the classifier are considered the most discriminative features of perturbations.</p></sec><sec id="Sec26"><title>Morphological feature selection based on predictability</title><p id="Par72">We selected the most predictable morphological features to visualize the relationship between gene expression and cell morphological features. Concretely, we computed the <italic toggle="yes">R</italic><sup>2</sup> score of each predicted cell morphological feature with respect to ground-truth cell morphological feature. Only features with <italic toggle="yes">R</italic><sup>2</sup> score higher than 0.5 were kept. 36 features from the prediction of MorphDiff and 8 features from IMPA meet this criteria, and 42 most predictable features are kept considering the overlap between two feature sets.</p></sec></sec><sec id="Sec27"><title>Evaluation metrics</title><p id="Par73">We denote the ground truth images and the generated images as <bold>X</bold> and <inline-formula id="IEq30"><alternatives><tex-math id="d33e3857">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{X}}}}^{{\prime} }$$\end{document}</tex-math><mml:math id="d33e3862"><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq30.gif"/></alternatives></inline-formula> respectively, and the number of images is <italic toggle="yes">N</italic>.</p><sec id="Sec28"><title>Fr&#233;chet Inception Distance (FID)</title><p id="Par74">The Fr&#233;chet Inception Distance measures the similarity between two sets of images. It was proposed by ref. <sup><xref ref-type="bibr" rid="CR33">33</xref></sup> to quantify the similarity of the generated images to the ground-truth ones. Concretely, the generated images and ground-truth images are passed to the Inception V3 model pre-trained on ImageNet. The output encodings of ground-truth images and generated images are denoted as <bold>E</bold> and <inline-formula id="IEq31"><alternatives><tex-math id="d33e3885">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{E}}}}^{{\prime} }$$\end{document}</tex-math><mml:math id="d33e3890"><mml:msup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq31.gif"/></alternatives></inline-formula> with dimension (<italic toggle="yes">N</italic>,&#160;2048), respectively (<italic toggle="yes">N</italic> is the number of images in the dataset, and 2048 is the dimension of Inception V3 model encodings). The mean embedding vector of <bold>E</bold> and <inline-formula id="IEq32"><alternatives><tex-math id="d33e3909">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{E}}}}^{{\prime} }$$\end{document}</tex-math><mml:math id="d33e3914"><mml:msup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq31.gif"/></alternatives></inline-formula> are denoted as <bold>m</bold> and <inline-formula id="IEq33"><alternatives><tex-math id="d33e3926">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{m}}}}^{{\prime} }$$\end{document}</tex-math><mml:math id="d33e3931"><mml:msup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq33.gif"/></alternatives></inline-formula>, and the covariance matrices <bold>E</bold> and <inline-formula id="IEq34"><alternatives><tex-math id="d33e3943">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{E}}}}^{{\prime} }$$\end{document}</tex-math><mml:math id="d33e3948"><mml:msup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq31.gif"/></alternatives></inline-formula> are denoted as <bold>C</bold> and <inline-formula id="IEq35"><alternatives><tex-math id="d33e3961">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{C}}}}^{{\prime} }$$\end{document}</tex-math><mml:math id="d33e3966"><mml:msup><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq35.gif"/></alternatives></inline-formula>. The final FID score is computed as <inline-formula id="IEq36"><alternatives><tex-math id="d33e3975">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\rm{FID}}}({{\bf{E}}},{{{\bf{E}}}}^{{\prime} })=| | {{\bf{m}}}-{{{\bf{m}}}}^{{\prime} }| {| }_{2}^{2}+{{\rm{Tr}}}({{\bf{C}}}+{{{\bf{C}}}}^{{\prime} }-2{({{{\bf{CC}}}}^{{\prime} })}^{1/2})$$\end{document}</tex-math><mml:math id="d33e3980"><mml:mi mathvariant="normal">FID</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">E</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>&#8739;</mml:mo><mml:mo>&#8739;</mml:mo><mml:mi mathvariant="bold">m</mml:mi><mml:mo>&#8722;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup><mml:mo>&#8739;</mml:mo><mml:msubsup><mml:mrow><mml:mo>&#8739;</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Tr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">C</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">CC</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq36.gif"/></alternatives></inline-formula>. <inline-formula id="IEq37"><alternatives><tex-math id="d33e4053">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\rm{Tr}}}$$\end{document}</tex-math><mml:math id="d33e4058"><mml:mi mathvariant="normal">Tr</mml:mi></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq37.gif"/></alternatives></inline-formula> denotes the trace of the matrix. A lower FID score indicates better performance of the generative model.</p></sec><sec id="Sec29"><title>Inception Score</title><p id="Par75">Inception Score was introduced in ref. <sup><xref ref-type="bibr" rid="CR34">34</xref></sup> to measure the diversity and quality of the generated images. Mathematically, the Inception Score can be written as <inline-formula id="IEq38"><alternatives><tex-math id="d33e4071">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\rm{InceptionScore}}}({{{\bf{X}}}}^{{\prime} })=\exp ({{\mathbb{E}}}_{{{{\bf{X}}}}^{{\prime} }}{D}_{{{\rm{KL}}}}(p(y| {{{\bf{X}}}}^{{\prime} })| | p(\,y)))$$\end{document}</tex-math><mml:math id="d33e4076"><mml:mi mathvariant="normal">InceptionScore</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">KL</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>&#8739;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8739;</mml:mo><mml:mo>&#8739;</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mspace width="0.25em"/><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq38.gif"/></alternatives></inline-formula>. <italic toggle="yes">y</italic> is the marginal distribution of the Inception V3 model. First, the generated images are passed through the Inception V3 model to get the conditional distribution <inline-formula id="IEq39"><alternatives><tex-math id="d33e4143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(y| {{{\bf{x}}}}^{{\prime} }),{{{\bf{x}}}}^{{\prime} }\in {{{\bf{X}}}}^{{\prime} }$$\end{document}</tex-math><mml:math id="d33e4148"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>&#8739;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup><mml:mo>&#8712;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq39.gif"/></alternatives></inline-formula>, then the marginal distribution <italic toggle="yes">p</italic>(<italic toggle="yes">y</italic>) is also computed by averaging <inline-formula id="IEq40"><alternatives><tex-math id="d33e4185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(y| {{{\bf{x}}}}^{{\prime} })$$\end{document}</tex-math><mml:math id="d33e4190"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>&#8739;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq40.gif"/></alternatives></inline-formula> over all the images. The KL divergence between <inline-formula id="IEq041"><alternatives><tex-math id="d33e4206">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(y)$$\end{document}</tex-math><mml:math id="d33e4211"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq041.gif"/></alternatives></inline-formula> and <inline-formula id="IEq41"><alternatives><tex-math id="d33e4220">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(y| {{{\bf{x}}}}^{{\prime} })$$\end{document}</tex-math><mml:math id="d33e4225"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>&#8739;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq40.gif"/></alternatives></inline-formula> is calculated and averaged on all images. The exponential of the averaged KL divergence is used as the Inception Score. A higher Inception Score means better performance of the generative model.</p></sec><sec id="Sec30"><title>Density and coverage</title><p id="Par76">Density and coverage introduced by<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> provide additional measures for assessing the fidelity and diversity of the generated images. Basically, we assume that <bold>E</bold>&#8201;=&#8201;{<bold>E</bold><sub>1</sub>,&#160;<bold>E</bold><sub>2</sub>,&#160;&#8230;,&#160;<bold>E</bold><sub><italic toggle="yes">N</italic></sub>} and <inline-formula id="IEq42"><alternatives><tex-math id="d33e4267">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{E}}}}^{{\prime} }=\{{{{\bf{E}}}}_{1}^{{\prime} },{{{\bf{E}}}}_{2}^{{\prime} },\ldots,{{{{\bf{E}}}}}_{N}^{{\prime} }\}$$\end{document}</tex-math><mml:math id="d33e4272"><mml:msup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq42.gif"/></alternatives></inline-formula> are the Inception V3 model encodings of the ground-truth images and generated images, respectively. We can approximate a manifold of <bold>E</bold> as<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="d33e4317">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\rm{manifold}}}({{{\bf{E}}}}_{1},{{{\bf{E}}}}_{2},\ldots,{{{\bf{E}}}}_{N})={\bigcup }_{i=1}^{N}B({{{\bf{E}}}}_{i},{{{\rm{NND}}}}_{k}({{{\bf{E}}}}_{i}))$$\end{document}</tex-math><mml:math id="d33e4323"><mml:mi mathvariant="normal">manifold</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8899;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">NND</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ11.gif"/></alternatives></disp-formula>The sphere, denoted as <italic toggle="yes">B</italic>(<bold>x</bold>,&#160;<italic toggle="yes">d</italic>), is characterized by its center at the point <bold>x</bold> and its radius <italic toggle="yes">d</italic>. NND<sub><italic toggle="yes">k</italic></sub>(<bold>x</bold>) denotes the distance from point <bold>x</bold> to the <italic toggle="yes">kth</italic> nearest neighbor <bold>x</bold> among excluding itself. Then, we can define density as<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="d33e4426">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\rm{Density}}}=\frac{1}{kN}{\sum }_{j=1}^{N}{\sum }_{i=1}^{N}{1}_{{{{\bf{E}}}}_{j}^{{\prime} }\in B({{{\bf{E}}}}_{i},{{{\rm{NND}}}}_{k}({{{\bf{E}}}}_{i}))}$$\end{document}</tex-math><mml:math id="d33e4432"><mml:mi mathvariant="normal">Density</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#8712;</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">NND</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ12.gif"/></alternatives></disp-formula>Density quantifies the concentration of generated samples within high-probability regions of the real data distribution. Specifically, it measures how well the generated samples populate the neighborhoods of real data points, reflecting the local consistency and quality of the generated distribution. Meanwhile, coverage assesses the extent to which the generated samples span the full support of the real data distribution. It evaluates whether the generative model captures all major modes of the true data, ensuring diverse and comprehensive generation. Coverage is defined as:<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="d33e4505">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\rm{Coverage}}}=\frac{1}{N}{\sum }_{i=1}^{N}{1}_{{{{\bf{E}}}^{\prime}_{i}} \in B({{{\bf{E}}}}_{i},{{{\rm{NND}}}}_{k}({{{\bf{E}}}}_{i}))}$$\end{document}</tex-math><mml:math id="d33e4511"><mml:mi mathvariant="normal">Coverage</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#8712;</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">NND</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ13.gif"/></alternatives></disp-formula>Intuitively, the density and coverage score will be higher if the generated distribution effectively aligns with the ground-truth distribution while of great diversity.</p></sec><sec id="Sec31"><title>CLIP embeddings and maximum mean discrepancy</title><p id="Par77">The CMMD (CLIP-MMD) metric represents the squared MMD (Maximum Mean Discrepancy) distance between the CLIP embeddings<sup><xref ref-type="bibr" rid="CR59">59</xref></sup> of the ground-truth image set and those of the generated image set<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>. CLIP embeddings are effective in representing the diverse and intricate content in images, benefitting from training an image encoder and a text encoder together using 400 million image-text pairs.</p><p id="Par78">Intuitively, given the <bold>E</bold>&#8201;=&#8201;{<bold>E</bold><sub>1</sub>,&#160;<bold>E</bold><sub>2</sub>,&#160;&#8230;,&#160;<bold>E</bold><sub><italic toggle="yes">m</italic></sub>} as CLIP-encoded embeddings of ground-truth images, and <inline-formula id="IEq43"><alternatives><tex-math id="d33e4605">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\bf{E}}}}^{{\prime} }=\{{{\bf{E}}}_{1}^{\prime},{{\bf{E}}}_{2}^{\prime},\ldots,{{{\bf{E}}}}_{n}^{{\prime} }\}$$\end{document}</tex-math><mml:math id="d33e4610"><mml:msup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq43.gif"/></alternatives></inline-formula> representing CLIP-encoded embeddings of generated images, and <italic toggle="yes">k</italic> denoted as kernel function, an unbiased estimator of <inline-formula id="IEq44"><alternatives><tex-math id="d33e4655">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\rm{dist}}}}_{{{\rm{MMD}}}}^{2}({{\bf{E}}},{{{\bf{E}}}}^{{\prime} })$$\end{document}</tex-math><mml:math id="d33e4660"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">dist</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">MMD</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">E</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq44.gif"/></alternatives></inline-formula> is given by:<disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="d33e4685">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\rm{dist}}}}_{{{\rm{MMD}}}}^{2}({{\bf{E}}},{{{\bf{E}}}}^{{\prime} }) =	\frac{1}{m(m-1)}{\sum }_{i=1}^{m}{\sum }_{i\ne j}^{m}k({{{\bf{E}}}}_{i},{{{\bf{E}}}}_{j})+\frac{1}{n(n-1)}{\sum }_{i=1}^{n}{\sum }_{i\ne j}^{n}k({{{\bf{E}}}^{\prime}_{i}},{{{\bf{E}}}^{\prime}_{j}} )\\ 	 -\frac{1}{mn}{\sum }_{i=1}^{m}{\sum }_{i=j}^{n}k({{{\bf{E}}}}_{i},{{{\bf{E}}}^{\prime}_{j}} )$$\end{document}</tex-math><mml:math id="d33e4691"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">dist</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">MMD</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">E</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8800;</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8800;</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8722;</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ14.gif"/></alternatives></disp-formula></p><p id="Par79">Note that a lower CMMD score means better generative performance.</p></sec><sec id="Sec32"><title>Mean average precision</title><p id="Par80">Mean average precision (mAP) is an evaluation metric assessing the probability that samples of interest will rank highly on a list of samples rank-ordered by some distance or similarity metric<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>, such as cosine&#160;similarity, Euclidean, Mahalanobis, etc. The mAP framework is agnostic to the choice of this distance metric. Given <italic toggle="yes">q</italic>th sample as <italic toggle="yes">q</italic> (generated cell morphology image), annotated with <italic toggle="yes">l</italic><sub><italic toggle="yes">q</italic></sub> (drug, MOA, or genetic perturbation). Assume that there are <italic toggle="yes">n</italic> ground-truth cell morphology images. TP<sub><italic toggle="yes">k</italic></sub> represents true positive when ranking the top <italic toggle="yes">k</italic> ground-truth samples by distance with <italic toggle="yes">q</italic>, while TN<sub><italic toggle="yes">k</italic></sub>, FP<sub><italic toggle="yes">k</italic></sub>, and FN<sub><italic toggle="yes">k</italic></sub> are defined similarly. Then the precision and recall at each rank can be calculated as <inline-formula id="IEq45"><alternatives><tex-math id="d33e4918">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${P}_{k}=\frac{{{{\rm{TP}}}}_{k}}{{{{\rm{TP}}}}_{k}}+{{{\rm{FP}}}}_{k}$$\end{document}</tex-math><mml:math id="d33e4923"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">FP</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq45.gif"/></alternatives></inline-formula> and <inline-formula id="IEq46"><alternatives><tex-math id="d33e4954">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${R}_{k}=\frac{{{{\rm{TP}}}}_{k}}{{{{\rm{TP}}}}_{n}+{{{\rm{FN}}}}_{n}}$$\end{document}</tex-math><mml:math id="d33e4959"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">FN</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq46.gif"/></alternatives></inline-formula>. We can then calculate AP and mAP:<disp-formula id="Equ15"><label>15</label><alternatives><tex-math id="d33e4990">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{\rm{AP}}}}_{q}={\sum}_{k}({R}_{k}-{R}_{k-1}{P}_{k})$$\end{document}</tex-math><mml:math id="d33e4996"><mml:msub><mml:mrow><mml:mi mathvariant="normal">AP</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ15.gif"/></alternatives></disp-formula><disp-formula id="Equ16"><label>16</label><alternatives><tex-math id="d33e5033">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\rm{mAP}}}={\sum }_{q=1}^{N}\frac{{{{\rm{AP}}}}_{q}}{N}$$\end{document}</tex-math><mml:math id="d33e5039"><mml:mi mathvariant="normal">mAP</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">AP</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ16.gif"/></alternatives></disp-formula></p></sec><sec id="Sec33"><title>Folds of enrichment</title><p id="Par81">Folds of Enrichment is an evaluation metric assessing whether the perturbed cell morphology and ground-truth cell morphology belonging to the same MOA or genetic perturbation will have high similarity<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. Concretely, for each generated cell morphology image, we calculated the odds ratio of a one-sided Fisher&#8217;s exact test. The test is calculated using a 2&#8201;&#215;&#8201;2 table. The first row contains the number of ground-truth cell morphology treated with the same treatment (drug, drug with the same MOA, or genetic perturbation) (positive matches) and different treatments (negative matches) at a selected threshold of the list of results. The second row is the same, but for the treatments below the threshold (the rest). The odds ratio is the sum of the first row divided by the sum of the second row. It estimates the likelihood of observing the generated cell morphology is top similar to the ground-truth cell morphology with the same perturbation.</p></sec><sec id="Sec34"><title>Coefficient of determination (<italic toggle="yes">R</italic><sup>2</sup> score)</title><p id="Par82">The coefficient of determination (<italic toggle="yes">R</italic><sup>2</sup> score)<sup><xref ref-type="bibr" rid="CR60">60</xref></sup> was created to evaluate prediction of various models and testing of hypotheses. It can evaluate how well the generated results fit the ground truth. Consider a ground truth set of <italic toggle="yes">n</italic> values marked <italic toggle="yes">y</italic><sub>1</sub>,&#160;<italic toggle="yes">y</italic><sub>2</sub>,&#160;&#8230;,&#160;<italic toggle="yes">y</italic><sub><italic toggle="yes">n</italic></sub>, each associated with a predicted (or generated) value <italic toggle="yes">g</italic><sub>1</sub>,&#160;<italic toggle="yes">g</italic><sub>2</sub>,&#160;&#8230;,&#160;<italic toggle="yes">g</italic><sub><italic toggle="yes">n</italic></sub>. Define residuals as <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub>&#8201;=&#8201;<italic toggle="yes">y</italic><sub><italic toggle="yes">i</italic></sub>&#160;&#8722;&#160;<italic toggle="yes">g</italic><sub><italic toggle="yes">i</italic></sub> and <inline-formula id="IEq47"><alternatives><tex-math id="d33e5141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{y}$$\end{document}</tex-math><mml:math id="d33e5146"><mml:mi>&#563;</mml:mi></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq47.gif"/></alternatives></inline-formula> as the mean of ground-truth set:<disp-formula id="Equ17"><label>17</label><alternatives><tex-math id="d33e5150">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{y}=\frac{1}{N}{\sum }_{i=1}^{N}{y}_{i}$$\end{document}</tex-math><mml:math id="d33e5156"><mml:mi>&#563;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ17.gif"/></alternatives></disp-formula>Then we can measure the variability of the data with two sums of squares formulas. The sum of square of residuals can be calculated as:<disp-formula id="Equ18"><label>18</label><alternatives><tex-math id="d33e5181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${S}_{{{\rm{res}}}}={\sum}_{i}{({y}_{i}-{g}_{i})}^{2}={\sum}_{i}{r}_{i}^{2}$$\end{document}</tex-math><mml:math id="d33e5187"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">res</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ18.gif"/></alternatives></disp-formula>The total sum of squares is:<disp-formula id="Equ19"><label>19</label><alternatives><tex-math id="d33e5236">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${S}_{{{\rm{tot}}}}={\sum}_{i}{({y}_{i}-\bar{y})}^{2}$$\end{document}</tex-math><mml:math id="d33e5242"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">tot</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:mi>&#563;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ19.gif"/></alternatives></disp-formula>The general definition of <italic toggle="yes">R</italic><sub>2</sub> score is:<disp-formula id="Equ20"><label>20</label><alternatives><tex-math id="d33e5278">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${R}^{2}=1-\frac{{S}_{{{\rm{res}}}}}{{S}_{{{\rm{tot}}}}}$$\end{document}</tex-math><mml:math id="d33e5284"><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">res</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">tot</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ20.gif"/></alternatives></disp-formula>In the best case, the <inline-formula id="IEq48"><alternatives><tex-math id="d33e5310">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${S}_{{{\rm{res}}}}=0$$\end{document}</tex-math><mml:math id="d33e5315"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">res</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><inline-graphic xlink:href="41467_2025_63478_Article_IEq48.gif"/></alternatives></inline-formula> and <italic toggle="yes">R</italic><sup>2</sup>&#8201;=&#8201;1. Generally, the <italic toggle="yes">R</italic><sup>2</sup> located in the interval [0,&#160;1] means the degree of fitting, and the closer the value is to 1, the better the performance of the model. Values of <italic toggle="yes">R</italic><sup>2</sup> being negative occur when the predicted data doesn&#8217;t fit the ground truth at all.</p></sec><sec id="Sec35"><title>Wasserstein distance</title><p id="Par83">Wasserstein distance<sup><xref ref-type="bibr" rid="CR61">61</xref></sup> can measure the distance between different distributions. Intuitively, the origin of the Wasserstein distance lies in the optimal transport problem, which can be imagined as moving a pile of stones represented by probability distributions to form another target shape, while minimizing the cumulative distance of the movements. This is the central concern of the optimal transport problem. Let <italic toggle="yes">&#956;</italic> and <italic toggle="yes">&#957;</italic> be two distributions, and let <italic toggle="yes">d</italic> be a way of calculating the distance, then the Wasserstein distance can be defined as:<disp-formula id="Equ21"><label>21</label><alternatives><tex-math id="d33e5356">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{p}(\mu,\nu )={\inf }_{\gamma \in \Gamma (\mu,\nu )}{({{\mathbb{E}}}_{({{\bf{x}}},{{\bf{y}}}) \sim \gamma }d{({{\bf{x}}},{{\bf{y}}})}^{p})}^{\frac{1}{p}}$$\end{document}</tex-math><mml:math id="d33e5362"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#956;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#957;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>inf</mml:mi></mml:mrow><mml:mrow><mml:mi>&#947;</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi mathvariant="normal">&#915;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#956;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#957;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>~</mml:mo><mml:mi>&#947;</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ21.gif"/></alternatives></disp-formula>where &#915;(<italic toggle="yes">&#956;</italic>,&#160;<italic toggle="yes">&#957;</italic>) is the set of all couplings of <italic toggle="yes">&#956;</italic> and <italic toggle="yes">&#957;</italic>.</p></sec><sec id="Sec36"><title>Pearson correlation</title><p id="Par84">Pearson correlation measures the linear relationship between two vectors. Concretely, given two vectors <bold>X</bold> and <bold>Y</bold>, Pearson correlation <italic toggle="yes">&#961;</italic> can be computed as<disp-formula id="Equ22"><label>22</label><alternatives><tex-math id="d33e5461">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rho }_{{{\bf{X}}},{{\bf{Y}}}}=\frac{{{\rm{cov}}}({{\bf{X}}},{{\bf{Y}}})}{{\sigma }_{{{\bf{X}}}}{\sigma }_{{{\bf{Y}}}}}$$\end{document}</tex-math><mml:math id="d33e5467"><mml:msub><mml:mrow><mml:mi>&#961;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">cov</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ22.gif"/></alternatives></disp-formula>where <italic toggle="yes">c</italic><italic toggle="yes">o</italic><italic toggle="yes">v</italic> (<bold>X</bold>,&#160;<bold>Y</bold>) is the covariance between <bold>X</bold> and <bold>Y</bold> and <italic toggle="yes">&#963;</italic><sub><bold>X</bold></sub> denotes the standard deviation of <bold>X</bold>.</p></sec><sec id="Sec37"><title>F1 score</title><p id="Par85">In this study, we adopt balanced F-score (F1 score). After the chi-square test on CellProfiler features extracted from ground truth morphology, we term the features with <italic toggle="yes">p</italic>&#160;values &lt;&#8201;0.05 as positive samples (regarded as significantly changed features), and term other features as negative samples. For generated morphology, we conduct the same test on generated CellProfiler features, then we acquire predicted positive samples and negative samples generated by each method. In this way, we can calculate true positive (TP), false positive (FP), and false negative (FN) for each method. The F1 score can be calculated as:<disp-formula id="Equ23"><label>23</label><alternatives><tex-math id="d33e5544">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{1}=\frac{2{{\rm{TP}}}}{2{{\rm{TP}}}+{{\rm{FP}}}+{{\rm{FN}}}}$$\end{document}</tex-math><mml:math id="d33e5550"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">TP</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">FN</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic position="anchor" orientation="portrait" xlink:href="41467_2025_63478_Article_Equ23.gif"/></alternatives></disp-formula></p></sec></sec><sec id="Sec38"><title>Reporting summary</title><p id="Par86">Further information on research design is available in the&#160;<xref rid="MOESM2" ref-type="media">Nature Portfolio Reporting Summary</xref> linked to this article.</p></sec></sec><sec id="Sec39" sec-type="supplementary-material"><title>Supplementary information</title><p>
<supplementary-material content-type="local-data" id="MOESM1" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM1_ESM.pdf" position="float" orientation="portrait"><caption><p>supplementary_information</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM2" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM2_ESM.pdf" position="float" orientation="portrait"><caption><p>Reporting Summary</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM3" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM3_ESM.pdf" position="float" orientation="portrait"><caption><p>Description of Additional Supplementary Files</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM4" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM4_ESM.xlsx" position="float" orientation="portrait"><caption><p>supplementary_data1</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM5" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM5_ESM.xlsx" position="float" orientation="portrait"><caption><p>supplementary_data2</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM6" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM6_ESM.xlsx" position="float" orientation="portrait"><caption><p>supplementary_data3</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM7" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM7_ESM.xlsx" position="float" orientation="portrait"><caption><p>supplementary_data4</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM8" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM8_ESM.xlsx" position="float" orientation="portrait"><caption><p>supplementary_data5</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM9" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM9_ESM.xlsx" position="float" orientation="portrait"><caption><p>supplementary_data6</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM10" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM10_ESM.xlsx" position="float" orientation="portrait"><caption><p>supplementary_data7</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM11" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM11_ESM.pdf" position="float" orientation="portrait"><caption><p>Transparent Peer Review file</p></caption></media></supplementary-material>
</p></sec><sec id="Sec40" sec-type="supplementary-material"><title>Source data</title><p>
<supplementary-material content-type="local-data" id="MOESM12" position="float" orientation="portrait"><media xlink:href="41467_2025_63478_MOESM12_ESM.zip" position="float" orientation="portrait"><caption><p>Source Data</p></caption></media></supplementary-material>
</p></sec></body><back><fn-group><fn><p><bold>Publisher&#8217;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p>The online version contains supplementary material available at 10.1038/s41467-025-63478-z.</p></sec><ack><title>Acknowledgements</title><p>This study was supported by the Chinese University of Hong Kong (CUHK; award numbers 4937025, 4937026, 5501517, 5501329 and SHIAE BME-p1-24 to Y.L.) and the IdeaBooster Fund (IDBF23ENG05 and IDBF24ENG06 to Y.L.) and partially supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region (Hong Kong SAR), China (project no. CUHK 24204023 and 14208525 to Y.L.) and a grant from the Innovation and Technology Commission of the Hong Kong SAR, China (project no. GHP/065/21SZ and ITS/247/23FP to Y.L.). This research was also funded by the Research Matching Grant Scheme at CUHK (award numbers 8601603 and 8601663 to Y.L.) from the Research Grants Council, Hong Kong SAR, China. We thank Ouyang Jian from BioMap for helping to draw small molecule structures with ChemDraw.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>X.W., Y.F., Y.G., Y.L., and L.S. conceived the study. X.W., Y.F. designed the methodology. X.W., Y.F., and C.F. implemented the models. X.W., Y.F., C.F., K.L., K.D., and YX.L. ran the baseline experiments. X.W. and Y.F. interpreted the results. X.W., Y.F. performed analysis on the data. X.W., Y.F., and Y.G. organized and processed the publicly available data. X.W. and Y.F. visualized the experimental results. L.S., Y.L. supervised the research. X.W., Y.F. wrote the manuscript. Y.G. and Q.Y. help review the paper. All authors read and approved the final manuscript.</p></notes><notes notes-type="peer-review"><title>Peer review</title><sec id="FPar3"><title>Peer review information</title><p id="Par87"><italic toggle="yes">Nature Communications</italic> thanks William Speier and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. A peer review file is available.</p></sec></notes><notes notes-type="data-availability"><title>Data availability</title><p>All the data used in this work is publicly available. The morphology images of CDRP dataset are from<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> and can be downloaded with the scripts from <ext-link ext-link-type="uri" xlink:href="https://github.com/gigascience/paper-bray2017/blob/master/download_cil_images.sh">https://github.com/gigascience/paper-bray2017/blob/master/download_cil_images.sh</ext-link>. The corresponding L1000 gene expression data is collected from <ext-link ext-link-type="uri" xlink:href="https://broad.io/rosetta/">https://broad.io/rosetta/</ext-link>. The morphology images of JUMP dataset are collected from<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> and can be downloaded with the script from <ext-link ext-link-type="uri" xlink:href="https://github.com/jump-cellpainting/datasets/">https://github.com/jump-cellpainting/datasets/</ext-link>. The corresponding L1000 gene expression data is collected from<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>. For LINCS, the bulk morphology images are collected from<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> and the corresponding gene expression data is downloaded from <ext-link ext-link-type="uri" xlink:href="https://broad.io/rosetta/">https://broad.io/rosetta/</ext-link>. For all the genes and related pathways involved in the aforementioned genetic perturbations, as well as the drug names, SMILES (Simplified Molecular Input Line Entry System), targets (if applicable), and MOAs (if applicable) related to drug perturbations, we have provided detailed information, which is included in the Supplementary Data&#160;<xref rid="MOESM4" ref-type="media">1</xref>&#8211;<xref rid="MOESM10" ref-type="media">7</xref>. Source data is provided with this paper.&#160;<xref ref-type="sec" rid="Sec40">Source data</xref> are provided with this paper.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>Code is available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/biomap-research/MorphDiff">https://github.com/biomap-research/MorphDiff</ext-link>. Notebooks for parts of analysis can be found at Code Ocean (10.24433/CO.4389762.v1).</p></notes><notes id="FPar4" notes-type="COI-statement"><title>Competing interests</title><p id="Par88">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Moshkov</surname><given-names>N</given-names></name><etal/></person-group><article-title>Predicting compound activity from phenotypic profiles and chemical structures</article-title><source>Nat. Commun.</source><year>2023</year><volume>14</volume><fpage>1967</fpage><pub-id pub-id-type="pmid">37031208</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41467-023-37570-1</pub-id><pub-id pub-id-type="pmcid">PMC10082762</pub-id></element-citation><mixed-citation id="mc-CR1" publication-type="journal">Moshkov, N. et al. Predicting compound activity from phenotypic profiles and chemical structures. <italic toggle="yes">Nat. Commun.</italic><bold>14</bold>, 1967 (2023).<pub-id pub-id-type="pmid">37031208</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41467-023-37570-1</pub-id><pub-id pub-id-type="pmcid">PMC10082762</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chandrasekaran</surname><given-names>SN</given-names></name><name name-style="western"><surname>Ceulemans</surname><given-names>H</given-names></name><name name-style="western"><surname>Boyd</surname><given-names>JD</given-names></name><name name-style="western"><surname>Carpenter</surname><given-names>AE</given-names></name></person-group><article-title>Image-based profiling for drug discovery: due for a machine-learning upgrade?</article-title><source>Nat. Rev. Drug Discov.</source><year>2021</year><volume>20</volume><fpage>145</fpage><lpage>159</lpage><pub-id pub-id-type="pmid">33353986</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41573-020-00117-w</pub-id><pub-id pub-id-type="pmcid">PMC7754181</pub-id></element-citation><mixed-citation id="mc-CR2" publication-type="journal">Chandrasekaran, S. N., Ceulemans, H., Boyd, J. D. &amp; Carpenter, A. E. Image-based profiling for drug discovery: due for a machine-learning upgrade? <italic toggle="yes">Nat. Rev. Drug Discov.</italic><bold>20</bold>, 145&#8211;159 (2021).<pub-id pub-id-type="pmid">33353986</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41573-020-00117-w</pub-id><pub-id pub-id-type="pmcid">PMC7754181</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Palma</surname><given-names>A</given-names></name><name name-style="western"><surname>Theis</surname><given-names>FJ</given-names></name><name name-style="western"><surname>Lotfollahi</surname><given-names>M</given-names></name></person-group><article-title>Predicting cell morphological responses to perturbations using generative modeling</article-title><source>Nat. Commun.</source><year>2025</year><volume>16</volume><fpage>505</fpage><pub-id pub-id-type="pmid">39779675</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41467-024-55707-8</pub-id><pub-id pub-id-type="pmcid">PMC11711326</pub-id></element-citation><mixed-citation id="mc-CR3" publication-type="journal">Palma, A., Theis, F. J. &amp; Lotfollahi, M. Predicting cell morphological responses to perturbations using generative modeling. <italic toggle="yes">Nat. Commun.</italic><bold>16</bold>, 505 (2025).<pub-id pub-id-type="pmid">39779675</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41467-024-55707-8</pub-id><pub-id pub-id-type="pmcid">PMC11711326</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="other">Lee, H. &amp; Welch, J. D. Morphnet predicts cell morphology from single-cell gene expression. <italic toggle="yes">bioRxiv</italic> 2022&#8211;10 (2022).</mixed-citation></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Swinney</surname><given-names>DC</given-names></name><name name-style="western"><surname>Anthony</surname><given-names>J</given-names></name></person-group><article-title>How were new medicines discovered?</article-title><source>Nat. Rev. Drug Discov.</source><year>2011</year><volume>10</volume><fpage>507</fpage><lpage>519</lpage><pub-id pub-id-type="pmid">21701501</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/nrd3480</pub-id></element-citation><mixed-citation id="mc-CR5" publication-type="journal">Swinney, D. C. &amp; Anthony, J. How were new medicines discovered? <italic toggle="yes">Nat. Rev. Drug Discov.</italic><bold>10</bold>, 507&#8211;519 (2011).<pub-id pub-id-type="pmid">21701501</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/nrd3480</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Chandrasekaran, S. N. et al. Three million images and morphological profiles of cells treated with matched chemical and genetic perturbations. <italic toggle="yes">Nat. Methods</italic><bold>21</bold>, 1114&#8211;1121 (2024).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41592-024-02241-6</pub-id><pub-id pub-id-type="pmcid">PMC11166567</pub-id><pub-id pub-id-type="pmid">38594452</pub-id></mixed-citation></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rosen</surname><given-names>ED</given-names></name><name name-style="western"><surname>Walkey</surname><given-names>CJ</given-names></name><name name-style="western"><surname>Puigserver</surname><given-names>P</given-names></name><name name-style="western"><surname>Spiegelman</surname><given-names>BM</given-names></name></person-group><article-title>Transcriptional regulation of adipogenesis</article-title><source>Genes Dev.</source><year>2000</year><volume>14</volume><fpage>1293</fpage><lpage>1307</lpage><pub-id pub-id-type="pmid">10837022</pub-id></element-citation><mixed-citation id="mc-CR7" publication-type="journal">Rosen, E. D., Walkey, C. J., Puigserver, P. &amp; Spiegelman, B. M. Transcriptional regulation of adipogenesis. <italic toggle="yes">Genes Dev.</italic><bold>14</bold>, 1293&#8211;1307 (2000).<pub-id pub-id-type="pmid">10837022</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Drareni, K., Gautier, J.-F., Venteclef, N. &amp; Alzaid, F. Transcriptional control of macrophage polarisation in type 2 diabetes. <italic toggle="yes">Semin. Immunopathol.</italic><bold>41</bold>, 515&#8211;529 (2019).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s00281-019-00748-1</pub-id><pub-id pub-id-type="pmid">31049647</pub-id></mixed-citation></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Haghighi</surname><given-names>M</given-names></name><name name-style="western"><surname>Caicedo</surname><given-names>JC</given-names></name><name name-style="western"><surname>Cimini</surname><given-names>BA</given-names></name><name name-style="western"><surname>Carpenter</surname><given-names>AE</given-names></name><name name-style="western"><surname>Singh</surname><given-names>S</given-names></name></person-group><article-title>High-dimensional gene expression and morphology profiles of cells across 28,000 genetic and chemical perturbations</article-title><source>Nat. Methods</source><year>2022</year><volume>19</volume><fpage>1550</fpage><lpage>1557</lpage><pub-id pub-id-type="pmid">36344834</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41592-022-01667-0</pub-id><pub-id pub-id-type="pmcid">PMC10012424</pub-id></element-citation><mixed-citation id="mc-CR9" publication-type="journal">Haghighi, M., Caicedo, J. C., Cimini, B. A., Carpenter, A. E. &amp; Singh, S. High-dimensional gene expression and morphology profiles of cells across 28,000 genetic and chemical perturbations. <italic toggle="yes">Nat. Methods</italic><bold>19</bold>, 1550&#8211;1557 (2022).<pub-id pub-id-type="pmid">36344834</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41592-022-01667-0</pub-id><pub-id pub-id-type="pmcid">PMC10012424</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Way</surname><given-names>GP</given-names></name><etal/></person-group><article-title>Morphology and gene expression profiling provide complementary information for mapping cell state</article-title><source>Cell Syst.</source><year>2022</year><volume>13</volume><fpage>911</fpage><lpage>923</lpage><pub-id pub-id-type="pmid">36395727</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.cels.2022.10.001</pub-id><pub-id pub-id-type="pmcid">PMC10246468</pub-id></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Way, G. P. et al. Morphology and gene expression profiling provide complementary information for mapping cell state. <italic toggle="yes">Cell Syst.</italic><bold>13</bold>, 911&#8211;923 (2022).<pub-id pub-id-type="pmid">36395727</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.cels.2022.10.001</pub-id><pub-id pub-id-type="pmcid">PMC10246468</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nassiri</surname><given-names>I</given-names></name><name name-style="western"><surname>McCall</surname><given-names>MN</given-names></name></person-group><article-title>Systematic exploration of cell morphological phenotypes associated with a transcriptomic query</article-title><source>Nucleic Acids Res.</source><year>2018</year><volume>46</volume><fpage>e116</fpage><lpage>e116</lpage><pub-id pub-id-type="pmid">30011038</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/nar/gky626</pub-id><pub-id pub-id-type="pmcid">PMC6212779</pub-id></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Nassiri, I. &amp; McCall, M. N. Systematic exploration of cell morphological phenotypes associated with a transcriptomic query. <italic toggle="yes">Nucleic Acids Res.</italic><bold>46</bold>, e116&#8211;e116 (2018).<pub-id pub-id-type="pmid">30011038</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/nar/gky626</pub-id><pub-id pub-id-type="pmcid">PMC6212779</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wakui</surname><given-names>T</given-names></name><etal/></person-group><article-title>Predicting reprogramming-related gene expression from cell morphology in human induced pluripotent stem cells</article-title><source>Mol. Biol. Cell</source><year>2023</year><volume>34</volume><fpage>ar45</fpage><pub-id pub-id-type="pmid">36947171</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1091/mbc.E22-06-0215</pub-id><pub-id pub-id-type="pmcid">PMC10162412</pub-id></element-citation><mixed-citation id="mc-CR12" publication-type="journal">Wakui, T. et al. Predicting reprogramming-related gene expression from cell morphology in human induced pluripotent stem cells. <italic toggle="yes">Mol. Biol. Cell</italic><bold>34</bold>, ar45 (2023).<pub-id pub-id-type="pmid">36947171</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1091/mbc.E22-06-0215</pub-id><pub-id pub-id-type="pmcid">PMC10162412</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Du</surname><given-names>J</given-names></name><etal/></person-group><article-title>Gene2vec: distributed representation of genes based on co-expression</article-title><source>BMC Genom.</source><year>2019</year><volume>20</volume><fpage>7</fpage><lpage>15</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1186/s12864-018-5370-x</pub-id><pub-id pub-id-type="pmcid">PMC6360648</pub-id><pub-id pub-id-type="pmid">30712510</pub-id></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Du, J. et al. Gene2vec: distributed representation of genes based on co-expression. <italic toggle="yes">BMC Genom.</italic><bold>20</bold>, 7&#8211;15 (2019).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1186/s12864-018-5370-x</pub-id><pub-id pub-id-type="pmcid">PMC6360648</pub-id><pub-id pub-id-type="pmid">30712510</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Rombach, R., Blattmann, A., Lorenz, D., Esser, P. &amp; Ommer, B. High-resolution image synthesis with latent diffusion models. In <italic toggle="yes">Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>, 10684&#8211;10695 (IEEE, 2022).</mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Goodfellow, I. et al. Generative adversarial nets. <italic toggle="yes">Adv. Neural Inform. Process. Syst.</italic><bold>27</bold>, 1&#8211;9 (2014).</mixed-citation></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dhariwal</surname><given-names>P</given-names></name><name name-style="western"><surname>Nichol</surname><given-names>A</given-names></name></person-group><article-title>Diffusion models beat GANs on image synthesis</article-title><source>Adv. Neural Inf. Process. Syst.</source><year>2021</year><volume>34</volume><fpage>8780</fpage><lpage>8794</lpage></element-citation><mixed-citation id="mc-CR16" publication-type="journal">Dhariwal, P. &amp; Nichol, A. Diffusion models beat GANs on image synthesis. <italic toggle="yes">Adv. Neural Inf. Process. Syst.</italic><bold>34</bold>, 8780&#8211;8794 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Carpenter</surname><given-names>AE</given-names></name><etal/></person-group><article-title>Cellprofiler: image analysis software for identifying and quantifying cell phenotypes</article-title><source>Genome Biol.</source><year>2006</year><volume>7</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1186/gb-2006-7-10-r100</pub-id><pub-id pub-id-type="pmcid">PMC1794559</pub-id><pub-id pub-id-type="pmid">17076895</pub-id></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Carpenter, A. E. et al. Cellprofiler: image analysis software for identifying and quantifying cell phenotypes. <italic toggle="yes">Genome Biol.</italic><bold>7</bold>, 1&#8211;11 (2006).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1186/gb-2006-7-10-r100</pub-id><pub-id pub-id-type="pmcid">PMC1794559</pub-id><pub-id pub-id-type="pmid">17076895</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Moshkov</surname><given-names>N</given-names></name><etal/></person-group><article-title>Learning representations for image-based profiling of perturbations</article-title><source>Nat. Commun.</source><year>2024</year><volume>15</volume><fpage>1594</fpage><pub-id pub-id-type="pmid">38383513</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41467-024-45999-1</pub-id><pub-id pub-id-type="pmcid">PMC10881515</pub-id></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Moshkov, N. et al. Learning representations for image-based profiling of perturbations. <italic toggle="yes">Nat. Commun.</italic><bold>15</bold>, 1594 (2024).<pub-id pub-id-type="pmid">38383513</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41467-024-45999-1</pub-id><pub-id pub-id-type="pmcid">PMC10881515</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Batool</surname><given-names>M</given-names></name><name name-style="western"><surname>Ahmad</surname><given-names>B</given-names></name><name name-style="western"><surname>Choi</surname><given-names>S</given-names></name></person-group><article-title>A structure-based drug discovery paradigm</article-title><source>Int. J. Mol. Sci.</source><year>2019</year><volume>20</volume><fpage>2783</fpage><pub-id pub-id-type="pmid">31174387</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/ijms20112783</pub-id><pub-id pub-id-type="pmcid">PMC6601033</pub-id></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Batool, M., Ahmad, B. &amp; Choi, S. A structure-based drug discovery paradigm. <italic toggle="yes">Int. J. Mol. Sci.</italic><bold>20</bold>, 2783 (2019).<pub-id pub-id-type="pmid">31174387</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/ijms20112783</pub-id><pub-id pub-id-type="pmcid">PMC6601033</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lotfollahi</surname><given-names>M</given-names></name><etal/></person-group><article-title>Predicting cellular responses to complex perturbations in high-throughput screens</article-title><source>Mol. Syst. Biol.</source><year>2023</year><volume>19</volume><fpage>e11517</fpage><pub-id pub-id-type="pmid">37154091</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.15252/msb.202211517</pub-id><pub-id pub-id-type="pmcid">PMC10258562</pub-id></element-citation><mixed-citation id="mc-CR20" publication-type="journal">Lotfollahi, M. et al. Predicting cellular responses to complex perturbations in high-throughput screens. <italic toggle="yes">Mol. Syst. Biol.</italic><bold>19</bold>, e11517 (2023).<pub-id pub-id-type="pmid">37154091</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.15252/msb.202211517</pub-id><pub-id pub-id-type="pmcid">PMC10258562</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bray</surname><given-names>M-A</given-names></name><etal/></person-group><article-title>Cell painting, a high-content image-based assay for morphological profiling using multiplexed fluorescent dyes</article-title><source>Nat. Protoc.</source><year>2016</year><volume>11</volume><fpage>1757</fpage><lpage>1774</lpage><pub-id pub-id-type="pmid">27560178</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/nprot.2016.105</pub-id><pub-id pub-id-type="pmcid">PMC5223290</pub-id></element-citation><mixed-citation id="mc-CR21" publication-type="journal">Bray, M.-A. et al. Cell painting, a high-content image-based assay for morphological profiling using multiplexed fluorescent dyes. <italic toggle="yes">Nat. Protoc.</italic><bold>11</bold>, 1757&#8211;1774 (2016).<pub-id pub-id-type="pmid">27560178</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/nprot.2016.105</pub-id><pub-id pub-id-type="pmcid">PMC5223290</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Vaswani, A. et al. Attention is all you need. <italic toggle="yes">Adv. Neural Inform. Process. Syst.</italic><bold>30</bold>, 1&#8211;11 (2017).</mixed-citation></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bray</surname><given-names>M-A</given-names></name><etal/></person-group><article-title>A dataset of images and morphological profiles of 30,000 small-molecule treatments using the cell painting assay</article-title><source>Gigascience</source><year>2017</year><volume>6</volume><fpage>giw014</fpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/gigascience/giw014</pub-id><pub-id pub-id-type="pmcid">PMC5721342</pub-id><pub-id pub-id-type="pmid">28327978</pub-id></element-citation><mixed-citation id="mc-CR23" publication-type="journal">Bray, M.-A. et al. A dataset of images and morphological profiles of 30,000 small-molecule treatments using the cell painting assay. <italic toggle="yes">Gigascience</italic><bold>6</bold>, giw014 (2017).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/gigascience/giw014</pub-id><pub-id pub-id-type="pmcid">PMC5721342</pub-id><pub-id pub-id-type="pmid">28327978</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Chandrasekaran, S. N. et al. Jump cell painting dataset: morphological impact of 136,000 chemical and genetic perturbations. Preprint at <italic toggle="yes">bioRxiv</italic>10.1101/2023.03.23.534023 (2023).</mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Natoli, T. et al. broadinstitute/lincs-cell-painting: full release of lincs cell painting dataset (2021).</mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">Landrum, G. et al. Rdkit: open-source cheminformatics software, 2016. <ext-link ext-link-type="uri" xlink:href="https://www.rdkit.org/">https://www.rdkit.org/</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/rdkit/rdkit">https://github.com/rdkit/rdkit</ext-link><bold>149</bold>, 650 (2016).</mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Yu, X., Chen, Y., Liu, S., Li, T. &amp; Li, G. Multi-mapping image-to-image translation via learning disentanglement. <italic toggle="yes">Adv. Neural Inform. Process. Syst.</italic><bold>32</bold>, 2&#8211;11(2019).</mixed-citation></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>H-Y</given-names></name><etal/></person-group><article-title>Drit++: diverse image-to-image translation via disentangled representations</article-title><source>Int. J. Comput. Vis.</source><year>2020</year><volume>128</volume><fpage>2402</fpage><lpage>2417</lpage></element-citation><mixed-citation id="mc-CR28" publication-type="journal">Lee, H.-Y. et al. Drit++: diverse image-to-image translation via disentangled representations. <italic toggle="yes">Int. J. Comput. Vis.</italic><bold>128</bold>, 2402&#8211;2417 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other">Choi, Y. et al. Stargan: unified generative adversarial networks for multi-domain image-to-image translation. In <italic toggle="yes">Proce. IEEE Conference on Computer Vision And Pattern Recognition</italic>, 8789&#8211;8797 (IEEE, 2018).</mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">Esser, P., Rombach, R. &amp; Ommer, B. Taming transformers for high-resolution image synthesis. In <italic toggle="yes">Proc. IEEE/CVF Conference on Computer Vision And Pattern Recognition</italic>, 12873&#8211;12883 (IEEE, 2021).</mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="other">Gao, S., Zhou, P., Cheng, M.-M. &amp; Yan, S. Masked diffusion transformer is a strong image synthesizer. In <italic toggle="yes">Proc. IEEE/CVF International Conference on Computer Vision</italic>, 23164&#8211;23173 (IEEE, 2023).</mixed-citation></ref><ref id="CR32"><label>32.</label><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lopez</surname><given-names>R</given-names></name><name name-style="western"><surname>Regier</surname><given-names>J</given-names></name><name name-style="western"><surname>Cole</surname><given-names>MB</given-names></name><name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name><name name-style="western"><surname>Yosef</surname><given-names>N</given-names></name></person-group><article-title>Deep generative modeling for single-cell transcriptomics</article-title><source>Nat. Methods</source><year>2018</year><volume>15</volume><fpage>1053</fpage><lpage>1058</lpage><pub-id pub-id-type="pmid">30504886</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41592-018-0229-2</pub-id><pub-id pub-id-type="pmcid">PMC6289068</pub-id></element-citation><mixed-citation id="mc-CR32" publication-type="journal">Lopez, R., Regier, J., Cole, M. B., Jordan, M. I. &amp; Yosef, N. Deep generative modeling for single-cell transcriptomics. <italic toggle="yes">Nat. Methods</italic><bold>15</bold>, 1053&#8211;1058 (2018).<pub-id pub-id-type="pmid">30504886</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41592-018-0229-2</pub-id><pub-id pub-id-type="pmcid">PMC6289068</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B. &amp; Hochreiter, S. Gans trained by a two-time-scale update rule converge to a local Nash equilibrium. <italic toggle="yes">Adv. Neural Inform. Process. Syst.</italic><bold>30</bold>, 1&#8211;12 (2017).</mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">Salimans, T. et al. Improved techniques for training GANs. <italic toggle="yes">Adv. Neural Inform. Process. Syst.</italic><bold>29</bold>, 2234&#8211; 2242 (2016).</mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="other">Jayasumana, S. et al. Rethinking fid: Towards a better evaluation metric for image generation. In <italic toggle="yes">Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>, 9307&#8211;9315 (IEEE, 2024).</mixed-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="other">Naeem, M. F., Oh, S. J., Uh, Y., Choi, Y. &amp; Yoo, J. Reliable fidelity and diversity metrics for generative models. In <italic toggle="yes">Proc. International Conference on Machine Learning</italic>, 7176&#8211;7185 (PMLR, 2020).</mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Deng, J. et al. Imagenet: a large-scale hierarchical image database. In <italic toggle="yes">Proc.</italic><italic toggle="yes">IEEE Conference on Computer Vision And Pattern Recognition</italic>, 248&#8211;255 (IEEE, 2009).</mixed-citation></ref><ref id="CR38"><label>38.</label><citation-alternatives><element-citation id="ec-CR38" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cortes</surname><given-names>C</given-names></name><name name-style="western"><surname>Vapnik</surname><given-names>V</given-names></name></person-group><article-title>Support-vector networks</article-title><source>Mach. Learn.</source><year>1995</year><volume>20</volume><fpage>273</fpage><lpage>297</lpage></element-citation><mixed-citation id="mc-CR38" publication-type="journal">Cortes, C. &amp; Vapnik, V. Support-vector networks. <italic toggle="yes">Mach. Learn.</italic><bold>20</bold>, 273&#8211;297 (1995).</mixed-citation></citation-alternatives></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Zanders, E. D. &amp; Zanders, E. D. Introduction to drugs and drug targets. <italic toggle="yes">Sci. Business Discovery</italic><bold>21</bold>, 11&#8211;30 (2020).</mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">D&#8217;mello, D., Shivasharanappa, K., Hanchinalmath, J. V. &amp; Patil, S. J. In silico approaches in drug discovery for SARS-CoV-2. <italic toggle="yes">Coronavirus Drug Discovery</italic> 235&#8211;251 (Elsevier, 2022).</mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="other">McInnes, L., Healy, J. &amp; Melville, J. Umap: uniform manifold approximation and projection for dimension reduction. Preprint at. <italic toggle="yes">arXiv</italic>10.48550/arXiv.1802.03426 (2018).</mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="other">Kalinin, A. A. et al. A versatile information retrieval framework for evaluating profile strength and similarity. <italic toggle="yes">Nat Commun</italic><bold>16</bold>, 5181 (2025).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41467-025-60306-2</pub-id><pub-id pub-id-type="pmcid">PMC12137819</pub-id><pub-id pub-id-type="pmid">40467541</pub-id></mixed-citation></ref><ref id="CR43"><label>43.</label><citation-alternatives><element-citation id="ec-CR43" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Trapotsi</surname><given-names>M-A</given-names></name><name name-style="western"><surname>Hosseini-Gerami</surname><given-names>L</given-names></name><name name-style="western"><surname>Bender</surname><given-names>A</given-names></name></person-group><article-title>Computational analyses of mechanism of action (moa): data, methods and integration</article-title><source>RSC Chem. Biol.</source><year>2022</year><volume>3</volume><fpage>170</fpage><lpage>200</lpage><pub-id pub-id-type="pmid">35360890</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1039/d1cb00069a</pub-id><pub-id pub-id-type="pmcid">PMC8827085</pub-id></element-citation><mixed-citation id="mc-CR43" publication-type="journal">Trapotsi, M.-A., Hosseini-Gerami, L. &amp; Bender, A. Computational analyses of mechanism of action (moa): data, methods and integration. <italic toggle="yes">RSC Chem. Biol.</italic><bold>3</bold>, 170&#8211;200 (2022).<pub-id pub-id-type="pmid">35360890</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1039/d1cb00069a</pub-id><pub-id pub-id-type="pmcid">PMC8827085</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR44"><label>44.</label><citation-alternatives><element-citation id="ec-CR44" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hu</surname><given-names>Y</given-names></name><name name-style="western"><surname>Bajorath</surname><given-names>J</given-names></name></person-group><article-title>Many structurally related drugs bind different targets, whereas distinct drugs display significant target overlap</article-title><source>RSC Adv.</source><year>2012</year><volume>2</volume><fpage>3481</fpage><lpage>3489</lpage></element-citation><mixed-citation id="mc-CR44" publication-type="journal">Hu, Y. &amp; Bajorath, J. Many structurally related drugs bind different targets, whereas distinct drugs display significant target overlap. <italic toggle="yes">RSC Adv.</italic><bold>2</bold>, 3481&#8211;3489 (2012).</mixed-citation></citation-alternatives></ref><ref id="CR45"><label>45.</label><citation-alternatives><element-citation id="ec-CR45" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hu</surname><given-names>Y</given-names></name><name name-style="western"><surname>Lounkine</surname><given-names>E</given-names></name><name name-style="western"><surname>Bajorath</surname><given-names>J</given-names></name></person-group><article-title>Many approved drugs have bioactive analogs with different target annotations</article-title><source>AAPS J.</source><year>2014</year><volume>16</volume><fpage>847</fpage><lpage>859</lpage><pub-id pub-id-type="pmid">24871342</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1208/s12248-014-9621-8</pub-id><pub-id pub-id-type="pmcid">PMC4070249</pub-id></element-citation><mixed-citation id="mc-CR45" publication-type="journal">Hu, Y., Lounkine, E. &amp; Bajorath, J. Many approved drugs have bioactive analogs with different target annotations. <italic toggle="yes">AAPS J.</italic><bold>16</bold>, 847&#8211;859 (2014).<pub-id pub-id-type="pmid">24871342</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1208/s12248-014-9621-8</pub-id><pub-id pub-id-type="pmcid">PMC4070249</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR46"><label>46.</label><citation-alternatives><element-citation id="ec-CR46" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Subramanian</surname><given-names>A</given-names></name><etal/></person-group><article-title>A next generation connectivity map: L1000 platform and the first 1,000,000 profiles</article-title><source>Cell</source><year>2017</year><volume>171</volume><fpage>1437</fpage><lpage>1452</lpage><pub-id pub-id-type="pmid">29195078</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.cell.2017.10.049</pub-id><pub-id pub-id-type="pmcid">PMC5990023</pub-id></element-citation><mixed-citation id="mc-CR46" publication-type="journal">Subramanian, A. et al. A next generation connectivity map: L1000 platform and the first 1,000,000 profiles. <italic toggle="yes">Cell</italic><bold>171</bold>, 1437&#8211;1452 (2017).<pub-id pub-id-type="pmid">29195078</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.cell.2017.10.049</pub-id><pub-id pub-id-type="pmcid">PMC5990023</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="other">Roohani, Y., Huang, K. &amp; Leskovec, J. Predicting transcriptional outcomes of novel multigene perturbations with gears. <italic toggle="yes">Nat. Biotechnol.</italic><bold>42</bold>, 927&#8211;935 (2023).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41587-023-01905-6</pub-id><pub-id pub-id-type="pmcid">PMC11180609</pub-id><pub-id pub-id-type="pmid">37592036</pub-id></mixed-citation></ref><ref id="CR48"><label>48.</label><citation-alternatives><element-citation id="ec-CR48" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bunne</surname><given-names>C</given-names></name><etal/></person-group><article-title>Learning single-cell perturbation responses using neural optimal transport</article-title><source>Nat. Methods</source><year>2023</year><volume>20</volume><fpage>1759</fpage><lpage>1768</lpage><pub-id pub-id-type="pmid">37770709</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41592-023-01969-x</pub-id><pub-id pub-id-type="pmcid">PMC10630137</pub-id></element-citation><mixed-citation id="mc-CR48" publication-type="journal">Bunne, C. et al. Learning single-cell perturbation responses using neural optimal transport. <italic toggle="yes">Nat. Methods</italic><bold>20</bold>, 1759&#8211;1768 (2023).<pub-id pub-id-type="pmid">37770709</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41592-023-01969-x</pub-id><pub-id pub-id-type="pmcid">PMC10630137</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="other">Singer, U. et al. Make-a-video: text-to-video generation without text-video data. In <italic toggle="yes">Proc. Eleventh International Conference on Learning Representations</italic> (ICLR, 2023).</mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="other">Ramesh, A., Dhariwal, P., Nichol, A., Chu, C. &amp; Chen, M. Hierarchical text-conditional image generation with clip latents. Preprint at arXiv 10.48550/arXiv.2204.06125 (2022).</mixed-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="other">Zhang, R., Isola, P., Efros, A. A., Shechtman, E. &amp; Wang, O. The unreasonable effectiveness of deep features as a perceptual metric. In <italic toggle="yes">Proc.IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic><italic toggle="yes">CVPR</italic> (IEEE, 2018).</mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="other">Simonyan, K. &amp; Zisserman, A. Very deep convolutional networks for large-scale image recognition. Preprint at <italic toggle="yes">arXiv</italic>10.48550/arXiv.1409.1556 (2014).</mixed-citation></ref><ref id="CR53"><label>53.</label><citation-alternatives><element-citation id="ec-CR53" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ho</surname><given-names>J</given-names></name><name name-style="western"><surname>Jain</surname><given-names>A</given-names></name><name name-style="western"><surname>Abbeel</surname><given-names>P</given-names></name></person-group><article-title>Denoising diffusion probabilistic models</article-title><source>Adv. Neural Inf. Process. Syst.</source><year>2020</year><volume>33</volume><fpage>6840</fpage><lpage>6851</lpage></element-citation><mixed-citation id="mc-CR53" publication-type="journal">Ho, J., Jain, A. &amp; Abbeel, P. Denoising diffusion probabilistic models. <italic toggle="yes">Adv. Neural Inf. Process. Syst.</italic><bold>33</bold>, 6840&#8211;6851 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR54"><label>54.</label><mixed-citation publication-type="other">Ronneberger, O., Fischer, P. &amp; Brox, T. U-net: Convolutional networks for biomedical image segmentation. In <italic toggle="yes">Proc.</italic><italic toggle="yes">MICCAI 2015: Munich, Germany, October 5-9, 2015, Proceedings, Part III 18</italic>, 234&#8211;241 (Springer, 2015).</mixed-citation></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="other">Sz&#233;kely, G. J., Rizzo, M. L. &amp; Bakirov, N. K. Measuring and testing dependence by correlation of distances. Preprint at 10.1214/009053607000000505 (2007).</mixed-citation></ref><ref id="CR56"><label>56.</label><citation-alternatives><element-citation id="ec-CR56" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gretton</surname><given-names>A</given-names></name><name name-style="western"><surname>Borgwardt</surname><given-names>KM</given-names></name><name name-style="western"><surname>Rasch</surname><given-names>MJ</given-names></name><name name-style="western"><surname>Sch&#246;lkopf</surname><given-names>B</given-names></name><name name-style="western"><surname>Smola</surname><given-names>A</given-names></name></person-group><article-title>A kernel two-sample test</article-title><source>J. Mach. Learn. Res.</source><year>2012</year><volume>13</volume><fpage>723</fpage><lpage>773</lpage></element-citation><mixed-citation id="mc-CR56" publication-type="journal">Gretton, A., Borgwardt, K. M., Rasch, M. J., Sch&#246;lkopf, B. &amp; Smola, A. A kernel two-sample test. <italic toggle="yes">J. Mach. Learn. Res.</italic><bold>13</bold>, 723&#8211;773 (2012).</mixed-citation></citation-alternatives></ref><ref id="CR57"><label>57.</label><citation-alternatives><element-citation id="ec-CR57" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Seal</surname><given-names>S</given-names></name><etal/></person-group><article-title>From pixels to phenotypes: Integrating image-based profiling with cell health data as biomorph features improves interpretability</article-title><source>Mol. Biol. Cell</source><year>2024</year><volume>35</volume><fpage>mr2</fpage><pub-id pub-id-type="pmid">38170589</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1091/mbc.E23-08-0298</pub-id><pub-id pub-id-type="pmcid">PMC10916876</pub-id></element-citation><mixed-citation id="mc-CR57" publication-type="journal">Seal, S. et al. From pixels to phenotypes: Integrating image-based profiling with cell health data as biomorph features improves interpretability. <italic toggle="yes">Mol. Biol. Cell</italic><bold>35</bold>, mr2 (2024).<pub-id pub-id-type="pmid">38170589</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1091/mbc.E23-08-0298</pub-id><pub-id pub-id-type="pmcid">PMC10916876</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR58"><label>58.</label><mixed-citation publication-type="other">Serrano, E. et al. Reproducible image-based profiling with Pycytominer. <italic toggle="yes">Nat Methods</italic><bold>22</bold>, 677&#8211;680 (2025).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41592-025-02611-8</pub-id><pub-id pub-id-type="pmcid">PMC12121495</pub-id><pub-id pub-id-type="pmid">40032995</pub-id></mixed-citation></ref><ref id="CR59"><label>59.</label><mixed-citation publication-type="other">Radford, A. et al. Learning transferable visual models from natural language supervision. In <italic toggle="yes">Proc. International Conference on Machine Learning</italic>, 8748&#8211;8763 (PMLR, 2021).</mixed-citation></ref><ref id="CR60"><label>60.</label><citation-alternatives><element-citation id="ec-CR60" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wright</surname><given-names>S</given-names></name></person-group><article-title>Correlation and causation</article-title><source>J. Agric. Res.</source><year>1921</year><volume>20</volume><fpage>557</fpage></element-citation><mixed-citation id="mc-CR60" publication-type="journal">Wright, S. Correlation and causation. <italic toggle="yes">J. Agric. Res.</italic><bold>20</bold>, 557 (1921).</mixed-citation></citation-alternatives></ref><ref id="CR61"><label>61.</label><citation-alternatives><element-citation id="ec-CR61" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vaserstein</surname><given-names>LN</given-names></name></person-group><article-title>Markov processes over denumerable products of spaces, describing large systems of automata</article-title><source>Probl. Peredachi Informatsii</source><year>1969</year><volume>5</volume><fpage>64</fpage><lpage>72</lpage></element-citation><mixed-citation id="mc-CR61" publication-type="journal">Vaserstein, L. N. Markov processes over denumerable products of spaces, describing large systems of automata. <italic toggle="yes">Probl. Peredachi Informatsii</italic><bold>5</bold>, 64&#8211;72 (1969).</mixed-citation></citation-alternatives></ref><ref id="CR62"><label>62.</label><mixed-citation publication-type="other">Meng, C. et al. Sdedit: guided image synthesis and editing with stochastic differential equations. In <italic toggle="yes">Proc. International Conference on Learning Representations</italic> (ICLR, 2022).</mixed-citation></ref></ref-list></back></article>
        
    </metadata>
</record>
    </GetRecord>

</OAI-PMH>