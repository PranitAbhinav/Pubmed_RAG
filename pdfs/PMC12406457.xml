


<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
    <responseDate>2025-09-09T14:04:35Z</responseDate>
    <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:12406457" metadataPrefix="pmc">https://pmc.ncbi.nlm.nih.gov/api/oai/v1/mh/</request>
    
    <GetRecord>
        <record>
    <header>
    <identifier>oai:pubmedcentral.nih.gov:12406457</identifier>
    <datestamp>2025-09-04</datestamp>
    
        
        <setSpec>tdtmv</setSpec>
        
    
        
        <setSpec>pmc-open</setSpec>
        
    
</header>
    <metadata>
        
        <article xmlns="https://jats.nlm.nih.gov/ns/archiving/1.4/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.4/ https://jats.nlm.nih.gov/archiving/1.4/xsd/JATS-archivearticle1-4.xsd" article-type="research-article" xml:lang="en" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Trop Dis Travel Med Vaccines</journal-id><journal-id journal-id-type="iso-abbrev">Trop Dis Travel Med Vaccines</journal-id><journal-id journal-id-type="pmc-domain-id">3243</journal-id><journal-id journal-id-type="pmc-domain">tdtmv</journal-id><journal-title-group><journal-title>Tropical Diseases, Travel Medicine and Vaccines</journal-title></journal-title-group><issn pub-type="epub">2055-0936</issn><publisher><publisher-name>BMC</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12406457</article-id><article-id pub-id-type="pmcid-ver">PMC12406457.1</article-id><article-id pub-id-type="pmcaid">12406457</article-id><article-id pub-id-type="pmcaiid">12406457</article-id><article-id pub-id-type="pmid">40898274</article-id><article-id pub-id-type="doi">10.1186/s40794-025-00267-y</article-id><article-id pub-id-type="publisher-id">267</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>GenoDense-Net: unraveling the genomic puzzle of the global pathogen</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name name-style="western"><surname>Dubey</surname><given-names initials="S">Shivendra</given-names></name><address><email>shivendra.dubey@jaipur.manipal.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Dubey</surname><given-names initials="S">Sakshi</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><name name-style="western"><surname>Raghuwanshi</surname><given-names initials="K">Kapil</given-names></name><address><email>kapil29021988@gmail.com</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" corresp="yes"><name name-style="western"><surname>Pranjal</surname><given-names initials="P">Pranshu</given-names></name><address><email>pranshu.pranjal@jaipur.manipal.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Kumar</surname><given-names initials="S">Sudheer</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/040h76494</institution-id><institution-id institution-id-type="ISNI">0000 0004 4661 2475</institution-id><institution>Department of Artificial Intelligence &amp; Machine Learning, </institution><institution>Manipal University Jaipur, </institution></institution-wrap>Jaipur, India </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01rfr0p20</institution-id><institution-id institution-id-type="GRID">grid.472355.2</institution-id><institution-id institution-id-type="ISNI">0000 0004 1775 3391</institution-id><institution>Department of Electronics and Communications, </institution><institution>RKDF University, </institution></institution-wrap>Bhopal, MP India </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03vr3gq96</institution-id><institution-id institution-id-type="GRID">grid.504249.e</institution-id><institution-id institution-id-type="ISNI">0000 0004 1785 2680</institution-id><institution>IcfaiTech (Faculty of Science and Technology), The ICFAI University, Jaipur, Rajasthan, </institution></institution-wrap>Jaipur, India </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/040h76494</institution-id><institution-id institution-id-type="ISNI">0000 0004 4661 2475</institution-id><institution>Department of Artificial Intelligance &amp; Machine Learning, </institution><institution>Manipal University Jaipur, </institution></institution-wrap>Jaipur, Rajasthan India </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05p2t3578</institution-id><institution>Department of Computer Science and Engineering, </institution><institution>University of Engineering and Management, </institution></institution-wrap>Jaipur, Rajasthan India </aff></contrib-group><pub-date pub-type="epub"><day>2</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>11</volume><issue-id pub-id-type="pmc-issue-id">478162</issue-id><elocation-id>32</elocation-id><history><date date-type="received"><day>11</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>15</day><month>7</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>02</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>04</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-04 10:25:45.023"><day>04</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><self-uri content-type="pmc-pdf" xlink:href="40794_2025_Article_267.pdf"/><abstract id="Abs1"><p id="Par1">The respiratory system of humans is impacted by infectious and deadly illnesses like COVID-19. Early identification and diagnosis of this type of illness is essential to stop the infection from spreading further. In the present research, we presented a technique for determining the condition using COVID-19's current genome sequences employing the DenseNet-16 framework. We operated a network of already trained neurons before using a transfer learning method to prepare it according to our dataset. Additionally, we preprocessed the collected information using the NearKbest interpolation approach; then, we utilized Adam Optimizer to optimize our findings. Compared with special deep learning models like ResNet-50, VGG-19, AlexNet, and VGG-16, our approach produced an accuracy of 99.18%. The model was deployed on a platform with GPU support, which greatly decreased training time. Dataset size and the requirement for further validation are two of the study's limitations, despite the encouraging results. The current research showed how a deep learning approach may be useful to categorize the genome sequence of infectious disease like COVID-19 using the suggested GenoDense-Net architecture. The next step in this research project is conducting investigations in the clinic.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>DenseNet-16</kwd><kwd>NearKbest</kwd><kwd>Adam optimizer</kwd><kwd>VGG-16</kwd><kwd>Genome sequence</kwd></kwd-group><funding-group><award-group><funding-source><institution>Manipal University Jaipur</institution></funding-source></award-group><open-access><p>Open access funding provided by Manipal University Jaipur.</p></open-access></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#169; BioMed Central Ltd., part of Springer Nature 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">A crucial task in comprehending the complex genomic makeup of infectious disease like COVID-19 is unraveling the worldwide pathogen's genomic puzzle. An extraordinary global effort by researchers and scientists is underway to interpret the viruses'genetic coding, reconstruct their genomic design, and trace their history of evolution. This unrelenting search intends to reveal critical insights about the transmission dynamics, mutation patterns, and the virus's origin through thorough genome analysis and sequencing. By solving the genomic riddle, we can learn crucial details about the potential variants and behavior of the virus, which will help us design specialized diagnostic equipment, therapies, and preventative measures. In addition to being a scientific accomplishment, this quest holds the potential to inform public health policies and direct our group's reaction to the global epidemic. The corona virus is an infectious disease, also called COVID-19, was discovered for the first time in the final few days of 2019. That expressed how critically alarming the circumstance globally referred to an international epidemic. This illness impacts the respiratory system of humans [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>].</p><p id="Par3">Given the numerous sufferers, these available kits for diagnosis of infectious disease were insufficient because they failed to recognize every instance. Therefore, the researchers found other ways of diagnosing the viral infection using the patient's CT scan (Computerized Tomography scan) images from their lungs. Most people cannot afford the astronomical cost of CT scans. Therefore, we use genomic sequence analysis of infectious disease as the foundation of our technique [<xref ref-type="bibr" rid="CR3">3</xref>].</p><sec id="Sec2"><title>Role of genome sequence</title><p id="Par4">By revealing vital information about the biological makeup of the microorganisms accountable for the diseases, the sequencing of genomes serves a critical role in diagnosing infectious diseases. The following represent a few crucial functions of the sequencing of genomes in the detection of infectious diseases:</p><sec id="Sec3"><title>Pathogen identification</title><p id="Par5">DNA sequencing enables researchers to ascertain a pathogen's unique genetic signature, allowing for precise identification. The bacterium causing the sickness is identified by matching a pathogenic microbe's genetic makeup to a repository containing known sequences [<xref ref-type="bibr" rid="CR4">4</xref>].</p></sec><sec id="Sec4"><title>Transmission dynamics understanding</title><p id="Par6">Genome sequencing aids in tracing the paths of infectious disease transmission, which is essential for understanding transmission dynamics. Scientists can track the clusters of related cases and information on the disease by comparing genomes of viruses isolated from various people or geographic areas. For conducting specific measures and managing epidemics, this information is essential [<xref ref-type="bibr" rid="CR5">5</xref>].</p></sec><sec id="Sec5"><title>Drug resistance detection</title><p id="Par7">Drug resistance detection is made easier with the help of genome sequencing for infections. Researchers can pinpoint genetic variations linked to antimicrobial medication resistance by analyzing the genomic sequence. This information helps decide on the best course of action for treating patients and creating plans for preventing the spread of strains that are resistant to medicines [<xref ref-type="bibr" rid="CR6">6</xref>].</p></sec><sec id="Sec6"><title>Development of vaccine</title><p id="Par8">Genome sequencing is essential for the creation of vaccinations against diseases that are infectious. A pathogen's genetic structure is examined to discover important antigens and create vaccines specifically designed to elicit a response from the immune system. This method has proven to be especially helpful in quickly creating vaccinations for contagious diseases like COVID-19 [<xref ref-type="bibr" rid="CR2">2</xref>].</p></sec><sec id="Sec7"><title>Epidemiological research</title><p id="Par9">The sequencing of genomes aids epidemiological study by supplying necessary information on the molecular evolution and modes of transmission of infections. To develop control and efficient preventative measures, researchers can learn more about the source, propagation, and development of infectious illnesses by examining gene variations in the pathogen population [<xref ref-type="bibr" rid="CR7">7</xref>].</p></sec></sec><sec id="Sec8"><title>Genome classification techniques based on AI</title><p id="Par10">Transformer-based frameworks like DeepSequence, GenomeBERT, and BERT for DNA have been investigated in recent developments in AI-driven genomic classification. These models perform better in predicting mutation effects and classifying regulatory sequences by using attention processes to capture contextual linkages and long-range interactions within genomic sequences. Future research should investigate the incorporation of this type of transformer-based genome frameworks for more accurate and multimodal COVID-19 diagnosis, even if our present study has focused on CNN-based feature selection and extraction&#160;with chest scans.</p><p id="Par11">GenomeBERT&#8212;Better results on tasks involving the annotation of genomes and the prediction of mutation effects are made possible by a customized version of BERT that was previously trained on individual DNA sequences.</p><p id="Par12">BERT for DNA&#8212;The BERT architecture is modified to sequences of DNA using a contextual embedding approach to capture functional and regulatory patterns.</p><p id="Par13">DeepSequence&#8212;A computational model that infers variation consequences of substantial biological significance by using unsupervised learning from numerous sequence matches.</p></sec><sec id="Sec9"><title>Objectives of the research</title><p id="Par14">Every research has some objectives to develop innovative ideas. This study work on the proposed model with having some objectives these are:<list list-type="bullet"><list-item><p id="Par15">&#8226;&#160;To understands the vital necessity of promptly identifying in preventing the transmission of infectious virus, a severe and extremely transmissible respiratory disorder.</p></list-item><list-item><p id="Par16">&#8226;&#160;To creates an approach for identifying infectious disease like&#160;COVID-19 in individuals'X-ray images of the chest. We can see this approach with the DenseNet-16&#160;framework to be the foundation.</p></list-item><list-item><p id="Par17">&#8226;&#160;To use a&#160;neural network those was trained and hone it on the particular dataset to utilize techniques for transfer learning. To use the Nearest-Neighbor approximation approach to process the chest X-ray pictures in order to make them more analytically suitable.</p></list-item><list-item><p id="Par18">&#8226;&#160;To use the Adam Optimizer for improve the framework's diagnostic accuracy by optimizing its parameters.</p></list-item><list-item><p id="Par19">&#8226;&#160;To compare the proposed framework with various deep learning frameworks like ResNet-50, AlexNet, VGG-19, and VGG-16 the level of precision gained is better. That demonstrate the suggested DenseNet-16 based technique works better than various competing models.</p></list-item></list></p></sec></sec><sec id="Sec10"><title>Literature review</title><p id="Par20">By thousands of researchers worldwide have been collected information and creating strategies to reveal the epidemiological, pathogenetic, and medical characteristics of SARS-CoV-2. Artificial intelligence has been used to expedite treatment development, forecast the spread of the virus, and diagnose patients. A preliminary diagnostic model and RT-PCR (Reverse Transcription-Real Time Polymerase Chain Reaction) and employing deep learning approaches with lung CT scans (computed tomography scans) has been compare in an investigation aimed at identifying COVID-19 infection [<xref ref-type="bibr" rid="CR8">8</xref>]. From lung computed tomography (CT scans) sets, a 3-D deep learning algorithm was created, employing 618 CT observations. Implemented a location-attention classification approach, the machine trained to distinguish between pictures and classify them into non-infectious, viral pneumonia, COVID-19, and Influenza-A [<xref ref-type="bibr" rid="CR9">9</xref>]. Considering a median success rate of 86.7 per cent based on the CT scans utilized, the deep learning models successfully identified COVID-19 patients. It has been employed of Transcription-Real Time Polymerase Chain Reaction (RT-PCR) tests as the norm for infectious disease recognition [<xref ref-type="bibr" rid="CR3">3</xref>]; causes significant delays in identifying suspicious people, creating several unique obstacles to the prevention of the disease. The COVID-19 detection investigation included an initial collection of 540 samples from patients (COVID-negative and COVID-positive) [<xref ref-type="bibr" rid="CR10">10</xref>]. Of the total, 229 and 313 patients using the samples had negative and positive results.</p><p id="Par21">For identifying COVID-19 using CT scans, a three-dimensional DeCoVNet (Deep Convolutional Neural Network) has been developed. Each step comprises the network stem (the DeCoVNet), two 3-dimensional residual blocks, including as a ProClf (Progressive Classifier). The Progressive Classifier is where the forecast findings, come on or after. After extracting the data from the CT images, it directly generates the probability of becoming COVID-negative and COVID-positive. The analysis confirmed that the method was a shallow learning system with inadequate supervision. It did, however, achieve a high COVID-19 detection effectiveness. In numerous computational biology, computer vision, bioinformatics, and investigations, deep learning frameworks has been used to predict and categorize RNA and DNA-binding specificity, among other tasks [<xref ref-type="bibr" rid="CR11">11</xref>]. To develop a signal detection system that recapitulates referred to motifs, a DeepBind; for example, used just one level of convolution to operate in a CNN (Convolutional Neural Network) design, while looked into additional variables in structures [<xref ref-type="bibr" rid="CR12">12</xref>], which included the variety of layers and activities like the pooling process. Other research has employed more intricate designs incorporating all the RNN (Recurrent Neural Network) and CNN layer models, like DanQ [<xref ref-type="bibr" rid="CR13">13</xref>] and iDeepS [<xref ref-type="bibr" rid="CR14">14</xref>]. In an additional investigation, a bi-GRUs (bidirectional Gated Recurrent Units) layer was used as part of the KERGU technique [<xref ref-type="bibr" rid="CR15">15</xref>] (an utterly RNN-based design. To give the network a state within it that enables it to recognize long-distance dependence, this pair an embedded model of the sequence of inputs using the KERGU algorithm [<xref ref-type="bibr" rid="CR8">8</xref>].</p><p id="Par22">In recent years, hybrid AI approaches that combine deep learning with evolutionary and metaheuristic optimization techniques have been studied. To illustrate their possible relevance to genomic categorization and mutation detection, hybrid models have been used to improve results in tasks for feature selection [<xref ref-type="bibr" rid="CR16">16</xref>&#8211;<xref ref-type="bibr" rid="CR18">18</xref>] and&#160;imaging for medicine [<xref ref-type="bibr" rid="CR19">19</xref>]. Furthermore, for better disease diagnostics using genomic sequences, deep neural networks can be combined with computational evolutionary principles [<xref ref-type="bibr" rid="CR20">20</xref>] to provide strong optimization techniques (Table&#160;<xref rid="Tab1" ref-type="table">1</xref>).
<table-wrap id="Tab1" position="float" orientation="portrait"><label>Table&#160;1</label><caption><p>An overview of hybrid and current AI-based models&#160;for healthcare imaging and genome issues</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Pertinence to the Classification of Genomes</th><th align="left" colspan="1" rowspan="1">Major Contribution</th><th align="left" colspan="1" rowspan="1">Application Area</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1"><bold>Differential automatic encoder </bold>[<xref ref-type="bibr" rid="CR21">21</xref>]</td><td align="left" colspan="1" rowspan="1"><bold>Very important for diagnosing diseases based on mutations</bold></td><td align="left" colspan="1" rowspan="1"><bold>Sequence distributions for learning unsupervised models</bold></td><td align="left" colspan="1" rowspan="1"><bold>Prediction of mutation effects</bold></td></tr><tr><td align="left" colspan="1" rowspan="1"><bold>Frameworks for cybersecurity powered by AI </bold>[<xref ref-type="bibr" rid="CR18">18</xref>]</td><td align="left" colspan="1" rowspan="1"><bold>Adaptable to safe pipelines for genomic data</bold></td><td align="left" colspan="1" rowspan="1"><bold>established foundations for intelligent edge AI to make decisions quickly and securely</bold></td><td align="left" colspan="1" rowspan="1"><bold>Security of medical data and edge computing</bold></td></tr><tr><td align="left" colspan="1" rowspan="1"><bold>Transformer-based model </bold>[<xref ref-type="bibr" rid="CR22">22</xref>]</td><td align="left" colspan="1" rowspan="1"><bold>The latest advancements in contextual genomic feature learning</bold></td><td align="left" colspan="1" rowspan="1"><bold>BERT model pre-trained for DNA data</bold></td><td align="left" colspan="1" rowspan="1"><bold>Classification of genomic sequences</bold></td></tr><tr><td align="left" colspan="1" rowspan="1"><bold>Evolutionary metaheuristics </bold>[<xref ref-type="bibr" rid="CR19">19</xref>]</td><td align="left" colspan="1" rowspan="1"><bold>Beneficial for deep genomic model parameter tweaking</bold></td><td align="left" colspan="1" rowspan="1"><bold>A thorough analysis of metaheuristic algorithms</bold></td><td align="left" colspan="1" rowspan="1"><bold>Genetics and engineering optimization</bold></td></tr><tr><td align="left" colspan="1" rowspan="1"><bold>Paradigms for evolutionary computing </bold>[<xref ref-type="bibr" rid="CR23">23</xref>]</td><td align="left" colspan="1" rowspan="1"><bold>Provides a foundation for using PSO/GA&#160;in analysis of sequences</bold></td><td align="left" colspan="1" rowspan="1"><bold>Examining evolutionary tactics in practical issues</bold></td><td align="left" colspan="1" rowspan="1"><bold>General tasks for AI optimization</bold></td></tr><tr><td align="left" colspan="1" rowspan="1"><bold>Hybrid metaheuristics combined with feature selection </bold>[<xref ref-type="bibr" rid="CR24">24</xref>]</td><td align="left" colspan="1" rowspan="1"><bold>Useful for lowering the dimensionality of genetic data</bold></td><td align="left" colspan="1" rowspan="1"><bold>Enhanced categorization by the selection of feature subsets</bold></td><td align="left" colspan="1" rowspan="1"><bold>Genomic analysis and machine learning</bold></td></tr><tr><td align="left" colspan="1" rowspan="1"><bold>Optimization of hybrid deep learning </bold>[<xref ref-type="bibr" rid="CR20">20</xref>]</td><td align="left" colspan="1" rowspan="1"><bold>Gives instructions on how to use hybrid optimization for genome-based DL projects</bold></td><td align="left" colspan="1" rowspan="1"><bold>Suggested a new hybrid model that enhances DL performance</bold></td><td align="left" colspan="1" rowspan="1"><bold>Imaging techniques for medicine (such as X-rays and CT)</bold></td></tr><tr><td align="left" colspan="1" rowspan="1"><bold>Genomic variation analysis combined with deep learning </bold>[<xref ref-type="bibr" rid="CR25">25</xref>]</td><td align="left" colspan="1" rowspan="1"><bold>Extremely pertinent to detecting and classification of viral mutations based on genomes</bold></td><td align="left" colspan="1" rowspan="1"><bold>Model for detecting COVID-19 variants that is specific to mutations</bold></td><td align="left" colspan="1" rowspan="1"><bold>Classification of variants of SARS-CoV-2</bold></td></tr><tr><td align="left" colspan="1" rowspan="1"><bold>Transformers of vision and transfer learning </bold>[<xref ref-type="bibr" rid="CR26">26</xref>]</td><td align="left" colspan="1" rowspan="1"><bold>Demonstrates the promise of transformer-based techniques for imaging problems related to DNA and genomics</bold></td><td align="left" colspan="1" rowspan="1"><bold>Adaptation of Vision Transformer for Medical Diagnostics</bold></td><td align="left" colspan="1" rowspan="1"><bold>X-rays for the identification of disease</bold></td></tr><tr><td align="left" colspan="1" rowspan="1"><bold>Attention-focused LSTM-CNN </bold>[<xref ref-type="bibr" rid="CR27">27</xref>]</td><td align="left" colspan="1" rowspan="1"><bold>High applicability for contextually aware modelling of sequential genomic data</bold></td><td align="left" colspan="1" rowspan="1"><bold>Improved sequence classification performance with a hybrid model</bold></td><td align="left" colspan="1" rowspan="1"><bold>Classification of DNA sequences</bold></td></tr></tbody></table></table-wrap></p><sec id="Sec11"><title>Significance of review</title><p id="Par23">While this study shows the promise of artificial intelligence in infectious disease&#160;diagnosis like COVID-19, there is still a need for more thorough medical verification that is essential for putting these algorithms to use in actual clinical settings.</p><sec id="Sec12"><title>External verification</title><p id="Par24">The study makes absence of outside verification that involves evaluating the hypothesis using information gathered from different medical facilities or geographic areas. To evaluate the frameworks the ability to generalize this is crucial.</p></sec><sec id="Sec13"><title>Small-scale dataset</title><p id="Par25">The utilization of a comparatively modest dataset represents a possible study need. The precision found in this dataset is encouraging, but the validation process frequently calls for accessibility to a larger, diversified dataset that is typical for an entire population.</p></sec><sec id="Sec14"><title>Therapeutic significance</title><p id="Par26">Although the research's aim is accurate diagnosis, validation in clinical settings should consider the effects of the test's findings on actual patients. This entails assessing the simulation's specificity, sensitivity,&#160;negative and positive&#160;prognostic standards, as well as its capacity to support medical experts to generate wise judgments.</p></sec><sec id="Sec15"><title>Ethics</title><p id="Par27">The study might not have addressed issues like confidentiality of patients, consent that is informed, and transparency in decision-making that are connected to utilizing artificial intelligence (AI) models in healthcare settings.</p></sec><sec id="Sec16"><title>Reliability and robustness</title><p id="Par28">A high degree of precision is important, but medical testing should also take into account the system's dependability and durability&#160;under various settings, changes in picture quality, and outside influences.</p></sec></sec></sec><sec id="Sec17"><title>Densenet-16 architecture</title><p id="Par29">"DenseNet-16"refers to a specific design called DenseNet with 16 layers. Densely Connected Convolutional Networks (DenseNet), referred to known as deep neural network architecture [<xref ref-type="bibr" rid="CR28">28</xref>].</p><p id="Par30">Each layer in DenseNet connects to each subsequent level according to a feed-forward fashion, creating a network of dense relationships among groups. This connection architecture offers more immediate data flow and improved gradient propagation to address the disappearing gradient issue and encourage feature reuse.</p><p id="Par31">The number after"DenseNet"indicates the network's layers total counts that includes fully connected layers, pooling, and convolutional layer. The instance of DenseNet-16 shows there are sixteen distinct layers in a network [<xref ref-type="bibr" rid="CR29">29</xref>]. A top classification layer, transition layers, and dense blocks are standard components of the DenseNet design. Multiple layers make up dense blocks, and each layer inside a block has linked with each subsequent layer through that block. Reduced channel counts within dense blocks are achieved by using transition layers to regulate the dimensions of space. A fully linked layer comprising the resultant prediction common comes after a layer that pools worldwide averages as the final classification layer. Various tasks related to computer vision include picture classification, object identification, and semantic segmentation. DenseNet has demonstrated good performance. Depending on the precise needs of the work, the level of detail of the dataset, and the available computer resources, DenseNet-16 (see Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref>) or any additional format may be used.<fig id="Fig1" position="float" orientation="portrait"><label>Fig. 1</label><caption><p>DenseNet16</p></caption><graphic id="MO1" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig1_HTML.jpg"/></fig></p></sec><sec id="Sec18"><title>Proposed methodology</title><p id="Par32">In this work, we have used two genome sequencing data sets are employed, including from China and the USA. We generate a frame to read every line from the provided dataset, including the line number and sequence. Beginning has been from the algorithm's search for a matched sequence. The technique for uncovering genetic code patterns is used to identify matching sequences. To calculate the overall time complexity of the GenoDese-Net model (see Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>); we have identify the beginning and finishing time of the running algorithm. However, we are also use an algorithm to identify the missing sequencing and the fraction of altered genome sequences in the provided sequences.<fig id="Fig2" position="float" orientation="portrait"><label>Fig. 2</label><caption><p>GenoDense &#8211; Net model</p></caption><graphic id="MO2" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig2_HTML.jpg"/></fig></p><p id="Par33">Dense(16) indicates that there will be 16 neurons in the layer. Every single neuron within an extremely dense layer is completely associated with every neuron in the layer before it; meaning that every neuron in the layer getting information from every neuron which is in the layer before. In this model, we are using dense layers with the sigmoid activation function. This layer may describe irregularities within the data since the sigmoid function is a function that converts each neuron's output to a number that ranges from zero to one.&#160;Hyperparameter tweaking and experimentation are frequently required to determine a dense layer's ideal number of neurons. The trade-off between generalize performance and model capacity relies on the particular issue, the complexity and amount of the dataset, and other factors. Determining the optimum amount of neurons to get the required performance of the model may be done using methods like model validation and cross-validation.</p><p id="Par34">The complexity and capacity of a neural network are influenced by the total amount of neurons within its dense (completely interconnected) layer. The total number of neurons represents a crucial hyperparameter that could impact the network's functioning and capacity for learning. The mathematical expense of inference and training rises as the density of a layer of neurons also increases. Resource contexts constrain the model deployment, and the need for additional neurons may impact training duration since they demand more processing capacity. The num_words of number of neurons will be present in the output layer. The num_words variable represents the classification problem's variety of categories or classes. Each neuron in the output layer denotes a certain class, as well as the chance or probability that what is input falls under that group of neurons. The softmax function as used as activation for the output layer. The outputs of the neurons in the output layer are normalised by the softmax function to ensure that they add to 1. Generating probabilities for each class in multi-class classification tasks is standard practice.<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="d33e634">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uptheta \hspace{0.17em}=\hspace{0.17em}\uptheta -\text{learning}\_\text{rate }*\text{ m }/ (\text{sqrt}(\text{v})\hspace{0.17em}+\hspace{0.17em}\text{epsilon})$$\end{document}</tex-math><mml:math id="d33e640" display="block"><mml:mrow><mml:mi mathvariant="normal">&#952;</mml:mi><mml:mspace width="1.69998pt"/><mml:mo>=</mml:mo><mml:mspace width="1.69998pt"/><mml:mi mathvariant="normal">&#952;</mml:mi><mml:mo>-</mml:mo><mml:mtext>learning</mml:mtext><mml:mi>_</mml:mi><mml:mtext>rate</mml:mtext><mml:mspace width="0.333333em"/><mml:mrow/><mml:mo>&#8727;</mml:mo><mml:mspace width="0.333333em"/><mml:mtext>m</mml:mtext><mml:mspace width="0.333333em"/><mml:mo stretchy="false">/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>sqrt</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>v</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mspace width="1.69998pt"/><mml:mo>+</mml:mo><mml:mspace width="1.69998pt"/><mml:mtext>epsilon</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ1.gif"/></alternatives></disp-formula></p><p id="Par35">Here, &#952; stands for the neural network's parameters (biases and weights), the parameter updates'magnitude is controlled by learning_rate, often known as learning rate or step size, the gradients'first moment estimate (mean), denoted by the letter m, and the gradients'uncentered variance is represented by v, the second moment estimate. To maintain numerical stability and prevent division by zero, a minor constant called epsilon was included. We used adom optimizer method with weight decay (L2 regularisation) and a learning rate of 0.001 value of 1e-5 is used as the loss function. To minimize the loss function, the optimizer must change the weights of the model during training. That is the thing whose loss function is categorical cross-entropy. When the objectives are one-hot encoded in multi-class classification settings, categorical cross-entropy is typically used.</p><p id="Par36">To set up TensorFlow and Keras, optimization on the tool must be used during training for the compilation stage of a model of neural networks. Using tf.kera optimizers, the optimizer entity it was previously generated has been referred to via opt variable Adam.<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="d33e682">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uptheta \hspace{0.17em}=\hspace{0.17em}\uptheta -\text{learning}\_\text{rate }* \nabla \text{f}(\uptheta )$$\end{document}</tex-math><mml:math id="d33e688" display="block"><mml:mrow><mml:mi mathvariant="normal">&#952;</mml:mi><mml:mspace width="1.69998pt"/><mml:mo>=</mml:mo><mml:mspace width="1.69998pt"/><mml:mi mathvariant="normal">&#952;</mml:mi><mml:mo>-</mml:mo><mml:mtext>learning</mml:mtext><mml:mi>_</mml:mi><mml:mtext>rate</mml:mtext><mml:mspace width="0.333333em"/><mml:mrow/><mml:mo>&#8727;</mml:mo><mml:mi mathvariant="normal">&#8711;</mml:mi><mml:mtext>f</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">&#952;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ2.gif"/></alternatives></disp-formula></p><p id="Par37">The SGD (stochastic gradient descent) update rule for a neural network's parameters (&#952;), learning rate (learning_rate), and (&#8711;f(&#952;))&#160;gradient of its loss function (f) with regard to those variables. In order to minimise the loss function, the optimizer must modify the model weights depending upon the calculated gradients. The measurement parameter is set to"accuracy,"which gauges how many outputs of all samples were properly predicted. It indicates how accurately the model is functioning in terms of categorization. The package would determine the implementation and function of the class or DNA module. It is challenging to describe the function of the DNA module or class precisely without further details about the particular package and its contents. However, the class or module may be connected to the analysis of DNA sequences or modification just on the term"DNA,"based on the name alone. It might include features for managing DNA sequences, running procedures on performing DNA or DNA data, and analysis-specific algorithms. It would be essential to consult the package's documentation or source code or request more details from its creators or maintainers to better comprehend the DNA class or module and its functionality.</p><p id="Par38">
<fig position="anchor" id="Figa" orientation="portrait"><caption><p>Algorithm 1 Feature selection, protein identification, transcription and model improvement</p></caption><graphic position="anchor" id="MO3" orientation="portrait" xlink:href="40794_2025_267_Figa_HTML.jpg"/></fig>
</p><p id="Par39">Feature selection selects the most relevant features from a wider set to enhance the model's accuracy and comprehension in Algorithm 2. Protein identification, essential for comprehending systems of biology and researching diseases, involves identifying the existence or authenticity of protein in a specimen from the body. Protein synthesis and gene expression depend heavily on transcription, which creates RNA from DNA. Model enhancement seeks to enhance the accuracy of forecasting algorithms by modifying their design, adjusting hyperparameters, or adding new data, ultimately producing more precise and insightful results forecasts.</p><p id="Par40">A well-liked library for Python's bioinformatics and computational biology is the Bio package, occasionally referred to as Biopython. These offer several features for interacting with biological data, such as protein sequences, RNA, and DNA. The Biopython SeqUtils package includes utility and class methods for analyzing sequences. This instance imports the ProtParam module with SeqUtils. The ProtParam module offers methods and characteristics for computing different protein sequence features. It has characteristics to determine the molecular weight, physicochemical protein characteristics, isoelectric point, and content of amino acids. For the characterization and analysis of protein sequences, these characteristics are helpful. Functionalities about feature selection methods are included in the scikit-learn feature selection module, intending to optimize, promote interpretability, lower overfitting, and model performance. A feature selection technique centred on univariate tests of statistical significance is implemented by the SelectKBest module in the sci-kit-learn library. According to a predetermined scoring mechanism, the most outstanding K features containing the greatest score are chosen.<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="d33e730">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{F}=\frac{\frac{\sum_{l-1}^{n}\left(\frac{{TG}_{l}^{2}}{{N}_{l}}\right)- \left(\frac{{T}^{2}}{N}\right)}{n-1}}{\frac{\sum_{l-1}^{n}\sum_{m-1}^{{N}_{l}}{(O}_{lm}^{2})- \sum_{l-1}^{n}\left(\frac{{TG}_{l}^{2}}{{N}_{l}}\right)}{N-n}}$$\end{document}</tex-math><mml:math id="d33e736" display="block"><mml:mrow><mml:mtext>F</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mfrac><mml:msubsup><mml:mrow><mml:mi mathvariant="italic">TG</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>N</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mfrac></mml:mfenced><mml:mo>-</mml:mo><mml:mfenced close=")" open="("><mml:mfrac><mml:msup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi>N</mml:mi></mml:mfrac></mml:mfenced></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>l</mml:mi></mml:msubsup><mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">lm</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>-</mml:mo></mml:mrow><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mfrac><mml:msubsup><mml:mrow><mml:mi mathvariant="italic">TG</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>N</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mfrac></mml:mfenced></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:mfrac></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ3.gif"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="d33e829">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{MSE}=\frac{\sum_{l-1}^{n}\sum_{m-1}^{{N}_{l}}{(O}_{lm}^{2})- \sum_{l-1}^{n}\left(\frac{{TG}_{l}^{2}}{{N}_{l}}\right)}{N-n}$$\end{document}</tex-math><mml:math id="d33e835" display="block"><mml:mrow><mml:mtext>MSE</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>l</mml:mi></mml:msubsup><mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">lm</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>-</mml:mo></mml:mrow><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mfrac><mml:msubsup><mml:mrow><mml:mi mathvariant="italic">TG</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>N</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mfrac></mml:mfenced></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ4.gif"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="d33e894">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{MSE}=\frac{\sum_{l-1}^{n}\left(\frac{{TG}_{l}^{2}}{{N}_{l}}\right)- \left(\frac{{T}^{2}}{N}\right)}{n-1}$$\end{document}</tex-math><mml:math id="d33e900" display="block"><mml:mrow><mml:mtext>MSE</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mfrac><mml:msubsup><mml:mrow><mml:mi mathvariant="italic">TG</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>N</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mfrac></mml:mfenced><mml:mo>-</mml:mo><mml:mfenced close=")" open="("><mml:mfrac><mml:msup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi>N</mml:mi></mml:mfrac></mml:mfenced></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ5.gif"/></alternatives></disp-formula></p><p id="Par41">where F represents the proportion of variance across the whole test, the mean square error represent by MSE, which is calculated due to error (within residual mean square, groups), the mean square owing to groups or treatments (among all groups) represent by MST, Olm represents an observation, T is the sum of the totals of every one of observations, TGi is the group's total, N is the total amount of observation, and Nl is the sample size in group l.</p><p id="Par42">The F-value of the ANOVA is among the intended classification task of target variable and each feature. It provides the <italic toggle="yes">p</italic>-value and F-value for assesses and each feature how linearly dependent each characteristic is on the target variable.</p><p id="Par43">The LSTM (Long Short-Term Memory) is a sort of the RNN layer that belongs to the recurrent neural network family. When the input information sequence is crucial, LSTM layers are frequently used to handle sequential data, especially text or time series. Long-term dependencies are captured by LSTM layers, which also deal with the classic RNN's vanishing gradient issue. In a neural network, dense denotes a completely linked layer. Each of the neurons in the present coat is associated with every other neuron in the layer that follows below via dense layers. They are employed in learning non-linear mapping amongst data from both input and output. We used dropout, a regularisation method, to stop overfitting in neural networks. The network must acquire more resilient and generic representations because dropout layers arbitrarily remove an input unit's percentage through training. This help to reduce the interdependencies between neurons.</p><p id="Par44">
<fig position="anchor" id="Figb" orientation="portrait"><caption><p>Algorithm 2 Unknown territory and uncovering new insights: unveiling genetic code patterns</p></caption><graphic position="anchor" id="MO4" orientation="portrait" xlink:href="40794_2025_267_Figb_HTML.jpg"/></fig>
</p><p id="Par45">The second algorithm shows how to derive new insights and investigate genetic data. It is a streamlined framework, which can develop and change according to the type of biological information we're using and our unique needs. By applying nearest-neighbor interpolation, a straightforward but efficient method that chooses the pixel count that represents the closest neighbor while scaling, the chest X-ray pictures have been expanded to 224&#8201;&#215;&#8201;224&#8201;&#215;&#8201;3. Because it can preserve the edge properties of healthcare pictures and has a cheap processing cost&#8212;two factors that are essential for accurate classification&#8212;this method was chosen. This interpolation technique achieves the required multidimensional integrity for DenseNet-16 without producing interpolated objects of value, which is important because our work concentrates on graphical COVID-19 detection.</p><sec id="Sec21"><title>Dense blocks: feature transformation</title><p id="Par46">Through feature map concatenation, each layer in DenseNet takes input from all preceding layers, not just the one immediately before it. If y represents the l<sup>th</sup> layer's output, then one transformation is as follows:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="d33e965">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{y}}_{\text{m}}\hspace{0.17em}=\hspace{0.17em}{\text{H}}_{\text{m}}([{\text{y}}_{0}, {\text{y}}_{1}, {\text{y}}_{2}, \dots .{\text{y}}_{\text{m}-1}])$$\end{document}</tex-math><mml:math id="d33e971" display="block"><mml:mrow><mml:msub><mml:mtext>y</mml:mtext><mml:mtext>m</mml:mtext></mml:msub><mml:mspace width="1.69998pt"/><mml:mo>=</mml:mo><mml:mspace width="1.69998pt"/><mml:msub><mml:mtext>H</mml:mtext><mml:mtext>m</mml:mtext></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mtext>y</mml:mtext><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>y</mml:mtext><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>y</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8943;</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mtext>y</mml:mtext><mml:mrow><mml:mtext>m</mml:mtext><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ6.gif"/></alternatives></disp-formula></p><p id="Par47">H<sub>m</sub>(.)&#8201;=&#8201;Composite function which includes; ReLU activation, BN (Batch Normalization), Convolution operation.<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="d33e1017">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{H}}_{\text{m}}\left(\text{y}\right)\hspace{0.17em}=\hspace{0.17em}{\text{V}}_{\text{m}}*(\text{ReLU}(\text{BN})(\text{y})$$\end{document}</tex-math><mml:math id="d33e1023" display="block"><mml:mrow><mml:msub><mml:mtext>H</mml:mtext><mml:mtext>m</mml:mtext></mml:msub><mml:mfenced close=")" open="("><mml:mtext>y</mml:mtext></mml:mfenced><mml:mspace width="1.69998pt"/><mml:mo>=</mml:mo><mml:mspace width="1.69998pt"/><mml:msub><mml:mtext>V</mml:mtext><mml:mtext>m</mml:mtext></mml:msub><mml:mrow><mml:mrow/><mml:mo>&#8727;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>ReLU</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>BN</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>y</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ7.gif"/></alternatives></disp-formula>where&#8201;&#8727;&#8201;indicates the convolution operation and V are the convolution layer weights.</p></sec><sec id="Sec22"><title>Backpropagation in dense connections: weight propagation</title><p id="Par48">Consider the loss function to be H. The loss gradient in relation to an earlier layer's output y<sub>i</sub> (i&#8201;&lt;&#8201;m), where y<sub>i</sub> must take into account any later layers that employ:<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="d33e1064">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{\delta H}{\delta yi}=\sum\nolimits_{k=i+1}^{M}\frac{\delta H}{\delta yi}. \frac{\delta yk}{\delta yi}$$\end{document}</tex-math><mml:math id="d33e1070" display="block"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>&#948;</mml:mi><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>&#948;</mml:mi><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mfrac><mml:mrow><mml:mi>&#948;</mml:mi><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>&#948;</mml:mi><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#948;</mml:mi><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>&#948;</mml:mi><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ8.gif"/></alternatives></disp-formula></p><p id="Par49">By doing so, training stability is increased and disappearing gradients are decreased by allowing continuous flow of gradients to layers prior to them.</p></sec><sec id="Sec23"><title>Utilizing adam optimizer for optimization</title><p id="Par50">For our trials, we first set the Adam optimizer's usual decay of weights (L2 regularization) to 0.0001, the batch size to 32, and the learning rate to 0.001. These values were chosen using previous research and practical best practices. We used a grid search strategy across a constrained, small parameter space to fine-tune these hyperparameters. In particular, the batch size was assessed at values (64, 32, 16), and the learning rate was adjusted between (0.01, 0.001, 0.0001). To guarantee convergence and generalization, each configuration was evaluated using validation loss and accuracy&#160;trends. We made sure that the chosen combination produced steady training and optimal performance; however, we did not use genetic algorithms or&#160;Bayesian optimization&#160;due to computational resource limitations. The Adam optimizer, which uses estimations of the initial and subsequent moments of gradients to update parameters, is used to optimize the DenseNet-16&#160;model.<list list-type="bullet"><list-item><p id="Par51">&#920;<sub>t</sub>&#8201;=&#8201;Model parameters.</p></list-item><list-item><p id="Par52">h<sub>t</sub>&#8201;=&#8201;&#948; <sub>&#920;t</sub>M(&#920;<sub>t</sub>) gredient.</p></list-item><list-item><p id="Par53">v&#8201;=&#8201;variance.</p></list-item><list-item><p id="Par54">m&#8201;=&#8201;mean.</p></list-item></list></p><p id="Par55">
<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="d33e1138">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{v}t\hspace{0.17em}=\hspace{0.17em}{\upalpha}_{2}.{\text{v}}_{\text{t}}-1\hspace{0.17em}+\hspace{0.17em}(1- {\upalpha}_{2}).{h}_{t}^{2}$$\end{document}</tex-math><mml:math id="d33e1144" display="block"><mml:mrow><mml:mtext>v</mml:mtext><mml:mi>t</mml:mi><mml:mspace width="1.69998pt"/><mml:mo>=</mml:mo><mml:mspace width="1.69998pt"/><mml:msub><mml:mi mathvariant="normal">&#945;</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mtext>v</mml:mtext><mml:mtext>t</mml:mtext></mml:msub><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mspace width="1.69998pt"/><mml:mo>+</mml:mo><mml:mspace width="1.69998pt"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="normal">&#945;</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ9.gif"/></alternatives></disp-formula>
<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="d33e1184">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{m}}_{\text{t}}\hspace{0.17em}=\hspace{0.17em}{\upalpha}_{1}.{\text{m}}_{\text{t}-1}\hspace{0.17em}+\hspace{0.17em}(1- {\upalpha}_{1}).{\text{h}}_{\text{t}}$$\end{document}</tex-math><mml:math id="d33e1190" display="block"><mml:mrow><mml:msub><mml:mtext>m</mml:mtext><mml:mtext>t</mml:mtext></mml:msub><mml:mspace width="1.69998pt"/><mml:mo>=</mml:mo><mml:mspace width="1.69998pt"/><mml:msub><mml:mi mathvariant="normal">&#945;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mtext>m</mml:mtext><mml:mrow><mml:mtext>t</mml:mtext><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mspace width="1.69998pt"/><mml:mo>+</mml:mo><mml:mspace width="1.69998pt"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="normal">&#945;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo><mml:msub><mml:mtext>h</mml:mtext><mml:mtext>t</mml:mtext></mml:msub></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ10.gif"/></alternatives></disp-formula>
<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="d33e1230">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{t}^{\prime}=\frac{\text{vt}}{1- {\upalpha}_{2}^{t}}$$\end{document}</tex-math><mml:math id="d33e1236" display="block"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>&#8242;</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mtext>vt</mml:mtext><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#945;</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ11.gif"/></alternatives></disp-formula>
<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="d33e1257">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${m}_{t}^{\prime}=\frac{\text{mt}}{1- {\upalpha}_{1}^{t}}$$\end{document}</tex-math><mml:math id="d33e1263" display="block"><mml:mrow><mml:msubsup><mml:mi>m</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>&#8242;</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mtext>mt</mml:mtext><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#945;</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ12.gif"/></alternatives></disp-formula>
<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="d33e1284">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\Theta }_{\text{t}+1}={\Theta }_{\text{t}}-\upalpha .\frac{{m}_{t}^{\prime}}{\sqrt{{v}_{t}^{\prime}}+ \varepsilon }$$\end{document}</tex-math><mml:math id="d33e1290" display="block"><mml:mrow><mml:msub><mml:mi mathvariant="normal">&#920;</mml:mi><mml:mrow><mml:mtext>t</mml:mtext><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">&#920;</mml:mi><mml:mtext>t</mml:mtext></mml:msub><mml:mo>-</mml:mo><mml:mi mathvariant="normal">&#945;</mml:mi><mml:mo>.</mml:mo><mml:mfrac><mml:msubsup><mml:mi>m</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>&#8242;</mml:mo></mml:msubsup><mml:mrow><mml:msqrt><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>&#8242;</mml:mo></mml:msubsup></mml:msqrt><mml:mo>+</mml:mo><mml:mi>&#949;</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic position="anchor" orientation="portrait" xlink:href="40794_2025_267_Article_Equ13.gif"/></alternatives></disp-formula>
</p><p id="Par56">Here, A little constant &#949; keeps division by zero from happening, the decay rates for moment estimations are denoted by <inline-formula id="IEq1"><alternatives><tex-math id="d33e1327">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\upalpha$$\end{document}</tex-math><mml:math id="d33e1332"><mml:mi mathvariant="normal">&#945;</mml:mi></mml:math><inline-graphic xlink:href="40794_2025_267_Article_IEq1.gif"/></alternatives></inline-formula>
<sub>1</sub> and <inline-formula id="IEq2"><alternatives><tex-math id="d33e1339">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\upalpha$$\end{document}</tex-math><mml:math id="d33e1344"><mml:mi mathvariant="normal">&#945;</mml:mi></mml:math><inline-graphic xlink:href="40794_2025_267_Article_IEq1.gif"/></alternatives></inline-formula>
<sub>2</sub>, which are typically 0.9 and 0.999. The nucleotide sequences (which are made up of the letters A, T, C, and G) need to be first quantitatively coded in order to convert the entire sequence into a logical representation. This is usually done by learning embeddings or k-mer embedding and the one-hot encoding method. This is necessary in order to customize DenseNet for genome-wide data. In order to allow DenseNet's two-dimensional layer of convolution to identify motifs (specific patterns) within the sequence, these decoded patterns are subsequently transformed into a two-dimensional matrix that resembles a picture. A 1,000-base sequence, for instance, could be rearranged to form an array like 225&#8201;&#215;&#8201;225&#8201;&#215;&#8201;3, where 3 stands for the number of nucleotide channels. Then, by altering the layers that provide input and output in accordance with the biological function&#8212;such as regulatory area identification, variation classification, or mutation effect prediction&#8212;DenseNet could be used directly from through or scratch transfer learning.</p><p id="Par57">ImageNet pretrained weights were used to initialize the DenseNet-16 model. We preserved mid-level and low-level data on images by freezing the first three dense blocks and the primary layers in order to maximize the transfer learning process. Our chest X-ray dataset was used to unfreeze and fine-tune the last classifier and dense block layers. The technique of particular fine-tuning decreased overfitting and training time while enabling the trained model to adjust to COVID-19-specific imagery sequences. For final classification, a new dense and flattened layer (using softmax and dropout) and a median pooling layer were added.</p></sec></sec><sec id="Sec24"><title>Result and discussion</title><p id="Par58">The study used two datasets, the first of which had 2,100 chest X-ray pictures to serve as training purpose&#160;and 910 as testing purpose.&#160;Employing the NearKbest interpolation method, the photos were resized to a standard size of 225*225*3. DenseNet-16, a model framework with 20,311,999 parameters, was selected. We required 40 epochs were required for the model's training under the Anaconda Python environment. We use Batch Normalization following few layers to improve the performance of deep learning system. We used another NSBI dataset from Genbank for the purpose of this study, which contains genomic data for COVID 19 in FASTA format from different nations. We used the COVID 19 genome dataset from two separate countries. This keeps everything steady as you practice. The Adam optimizer, that is effective at determining the optimal parameters for simulation, that instructed to be used while configuring the&#160;model. This model learns more quickly and performs better because to this combination.</p><p id="Par59">We calculated the genome sequences'overall computation time in 1.83&#160;s and calculated the proportion of altered genome sequences at 1.31% (see Tables&#160;<xref rid="Tab2" ref-type="table">2</xref> and <xref rid="Tab3" ref-type="table">3</xref>). Out of all genome sequences, COVID-19 was accurately categorized by computation time. The changing percentage represents the percentage of modified genomic sequences during COVID-19.
<table-wrap id="Tab2" position="float" orientation="portrait"><label>Table&#160;2</label><caption><p>Calculate computation time of genome sequence</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="2" rowspan="1">Genome Sequence Analysis</th></tr><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Computation Time in Sec</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">GenoDense-Net</td><td align="left" colspan="1" rowspan="1">1.83</td></tr><tr><td align="left" colspan="1" rowspan="1">SPM Approach</td><td align="left" colspan="1" rowspan="1">2.13</td></tr></tbody></table></table-wrap><table-wrap id="Tab3" position="float" orientation="portrait"><label>Table&#160;3</label><caption><p>Percentage of genome sequence</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="2" rowspan="1">Changing Percentage of Genome Sequence</th></tr><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Percentage</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">GenoDense-Net</td><td align="left" colspan="1" rowspan="1">1.31</td></tr><tr><td align="left" colspan="1" rowspan="1">SPM Approach</td><td align="left" colspan="1" rowspan="1">-</td></tr></tbody></table></table-wrap></p><p id="Par60">The information from the DataFrame sequence''sequence ratios'column will be used to generate a bar graph. Sequence Ratio is written on the plot's y-axis as its label and"Index/Sequence numbering where genomes are missing"is representing by the x-axis label of the plot as shown in Fig.&#160;<xref rid="Fig3" ref-type="fig">3</xref>. The bar design can pinpoint certain indices or sequence numbers where genomes are absent. There may be clusters, voids, or patterns in the missing data that may be seen by visually examining the plot. This knowledge might be very helpful in comprehending the causes of missing genomes and perhaps direct additional research. The distribution pattern of sequencing proportions smaller than one may be shown and examined using the code, which is helpful overall. In addition, it facilitates data comparison, pattern identification, and communication. These details might be helpful in various sectors, including genetics, data analysis, research, and bioinformatics, wherever it's crucial to comprehend the sequence ratio's distribution.<fig id="Fig3" position="float" orientation="portrait"><label>Fig. 3</label><caption><p>Missing index of genome sequence</p></caption><graphic id="MO5" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig3_HTML.jpg"/></fig></p><p id="Par61">The nucleotide percentages in the genome sequence (A, G, T, and C) are calculated using the code. The genome's makeup may be understood using this information, which is also useful for understanding the structural and functional characteristics of the genome. This programme also determines the GC content, representing 37.86% of the genome sequence's Guanine (G) followed by Cytosine (C) bases. GC concentration is a crucial metric in genomics because it can affect evolutionary trends, protein-coding competence, and DNA steadiness. That is utilized in a gene forecast, variety of genomic research, phylogenetic learning, and primer design.</p><p id="Par62">The provided algorithm compares sequences of genes from the USA versus China to analyze them. A set of the names of genes is iterated over and over as several procedures are carried out for each gene. The genetic sequence is translated from DNA into RNA, transformed into a numpy array, and then plotted. The next step involves:<list list-type="bullet"><list-item><p id="Par63">&#8226;&#160;Comparing the gene sequences from the USA and then China.</p></list-item><list-item><p id="Par64">&#8226;&#160;Finding mutations.</p></list-item><list-item><p id="Par65">&#8226;&#160;Storing the information about those mutations in a lexicon.</p></list-item></list></p><p id="Par66">The function outputs the finished protein sequence once the mRNA sequence is translated. Overall, it makes gene mutation analysis easier and sheds light on the genetic variances from the USA to China.</p><p id="Par67">The proposed technique emphasizes the translation of&#160;protein and&#160;mRNA&#160;analyses. It uses a specific translation table to translate an mRNA to an amino acid sequence. The length and the outcome of the amino acid sequence are printed. The model also prints the original mRNA sequence's length. Finally, it offers details on the typical RNA codon table. This code may be used to investigate protein production, comprehend how the genetic code is translated and examine sequences of proteins as shown in Fig.&#160;<xref rid="Fig4" ref-type="fig">4</xref>.<fig id="Fig4" position="float" orientation="portrait"><label>Fig. 4</label><caption><p>Mutation of genome sequence</p></caption><graphic id="MO6" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig4_HTML.jpg"/></fig></p><p id="Par68">The number of distinct amino acids found in the sequence of proteins, some of which are present on more occasions than others, has been shown by counting everyone. The proportion of every amino acid in the protein's sequence provides a normalized representation, illuminating the similarities and differences between amino acids. Understanding the general amino acid distribution of the protein and spotting any biases or trends may be done using this information.</p><p id="Par69">The protein's molecular weight indicates its dimensions and level of complexity. When comparing proteins or forecasting their physical characteristics, it indicates the total separate weight of every amino acid in the sequence. The aromaticity value (see Table <xref rid="Tab4" ref-type="table">4</xref>) indicates the amount of aromatic amino acids in the protein sequence, including tryptophan, tyrosine, and phenylalanine. The presence of certain aromatic amino acids may have an impact on the protein's interactions, function, or structure if the aromaticity score is higher.
<table-wrap id="Tab4" position="float" orientation="portrait"><label>Table&#160;4</label><caption><p>Aromaticity and molecular mass of genome sequence</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2" colspan="1">Variable</th><th align="left" colspan="2" rowspan="1">Value</th></tr><tr><th align="left" colspan="1" rowspan="1">GenoDense-Net</th><th align="left" colspan="1" rowspan="1">SPM Approach</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">Aromaticity (the degree to which molecules are aromatic)</td><td align="left" colspan="1" rowspan="1">0.107384441939120639</td><td align="left" colspan="1" rowspan="1">-</td></tr><tr><td align="left" colspan="1" rowspan="1">Molecular mass (weight within base pair)</td><td align="left" colspan="1" rowspan="1">794,048.92579999659</td><td align="left" colspan="1" rowspan="1">-</td></tr></tbody></table></table-wrap></p><p id="Par70">The GenoDense model creates a visualization showing the distribution or composition of a certain information collection in Fig.&#160;<xref rid="Fig5" ref-type="fig">5</xref>. In this instance, the proposed model precisely depicts the protein amino acid structure of the POI (Protein of Interest). The corresponding presence or quantity of each amino acid in the POI has been intuitively and easily visualized using a graph to illustrating the data. These may be helpful in different biochemical and biological investigations and can aid in understanding the qualities and traits of the protein.<fig id="Fig5" position="float" orientation="portrait"><label>Fig. 5</label><caption><p>Interest of proteins of genome sequence</p></caption><graphic id="MO7" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig5_HTML.jpg"/></fig></p><p id="Par71">The provided data also creates a graph which is showing the protein length variation. Our understanding of the distribution and frequency of various protein lengths in the data set is made possible through the proposed method's ability to visualize protein lengths. This Fig.&#160;<xref rid="Fig6" ref-type="fig">6</xref> is a graph that visually depicts the protein length's distribution by displaying the protein's number concentrated and a range of lengths in each length bin. This information might be helpful for analysis and evaluation of the acquired understanding of the protein data under review and the spot patterns.<fig id="Fig6" position="float" orientation="portrait"><label>Fig. 6</label><caption><p>Length of proteins of genome sequence</p></caption><graphic id="MO8" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig6_HTML.jpg"/></fig></p><p id="Par72">To visualize, the residual length of range using a Fig.&#160;<xref rid="Fig7" ref-type="fig">7</xref>, the accompanying figure excludes the highest and lowest values or outliers from the protein's length data. The"functional_proteins"dataset is filtered by the algorithm, which only chooses proteins with lengths under 60. A new data frame contains these filtered proteins.<fig id="Fig7" position="float" orientation="portrait"><label>Fig. 7</label><caption><p>Length of proteins of genome sequence where threshold value&#8201;&lt;&#8201;60</p></caption><graphic id="MO9" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig7_HTML.jpg"/></fig></p><p id="Par73">The protein length's distribution less than 60&#160;kDa has displayed by plotting the graph employing the filtering protein's lengths. The visualization aids in understanding the protein's frequency or concentration together with shortened lengths and the overall distribution of protein lengths within a certain range. Insights into the lengths of common or normal proteins of the dataset may be gained by performing a targeted analysis of the protein length distribution free from the impact of extreme values.</p><p id="Par74">The"functional_proteins"dataset is filtered using the provided code to only include proteins with a length larger than 1000&#160;kDa. A new data frame contains the proteins that have been filtered. The method then creates a histogram displaying the distribution of proteins with lengths larger than 1000, employing the processed proteins'total lengths. The distribution of greater lengths of protein throughout the data set is shown visually by the Fig.&#160;<xref rid="Fig8" ref-type="fig">8</xref>.<fig id="Fig8" position="float" orientation="portrait"><label>Fig. 8</label><caption><p>Length of proteins where threshold value&#8201;&gt;&#8201;1000</p></caption><graphic id="MO10" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig8_HTML.jpg"/></fig></p><p id="Par75">By examining the visualization, one can gain understanding about the concentration and frequency of proteins of longer chains, which can help one comprehend the structure of the huge proteins inside the data set. The visualization aids in the discovery of any patterns or traits connected to proteins with lengths greater than the predetermined threshold of 1000.</p><p id="Par76">Pairwise sequencing of the connections between various DNA sequences is done using the suggested technique. It determines the alignment scores between the sequences. It divides each by the total length of the sequence used as a reference to get similarities scoring between the sequences and turns those into percentages.</p><p id="Par77">Then, three comparisons&#8212; MERS/SARS, MERS/COV2, and SARS/COV2 &#8212;has been presented with the computed similarity percentages. The pattern of similarities between various viruses, has presented in the Fig.&#160;<xref rid="Fig9" ref-type="fig">9</xref>, is shed light on by these comparisons. In contrast to the Y-axis which shows the proportion of sequence identity, the X-axis displays various sequence comparisons. Figure&#160;<xref rid="Fig9" ref-type="fig">9</xref> makes it easy to compare the sequence resemblances of the various DNA sequences. To analyse DNA sequences, the technique combines pairwise sequence position, visualizing DNA sequences, and computing relevance scores.<fig id="Fig9" position="float" orientation="portrait"><label>Fig. 9</label><caption><p>Sequence identity in percentage of genome sequence</p></caption><graphic id="MO11" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig9_HTML.jpg"/></fig></p><p id="Par78">A multi-layered neural network structure is depicted in the Fig.&#160;<xref rid="Fig10" ref-type="fig">10</xref>. The Dense layer, a Dropout layer, and the LSTM layer are all parts of the model architecture. According to the LSTM layer's output structure (None, 61, 16), it accepts sequences of inputs of length 61 and generates sequences of output of length 16. There are 5632 parameters in the LSTM layer.<fig id="Fig10" position="float" orientation="portrait"><label>Fig. 10</label><caption><p>Multi-layered neural network structures</p></caption><graphic id="MO12" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig10_HTML.jpg"/></fig></p><p id="Par79">The output shape is unaffected by the Dropout layer, which operates for regularisation and to avoid overfitting. Since it doesn't add additional weights to the structure, it has no parameters. The output shape of the Dense layer, which comes after the Dropout layer, is (None, 61, 16). The supplied data is transformed using the 272 parameters that are introduced. A second Dropout layer is added without altering the output form. The model is finished using a Dense layer with the output form (None, 61, 6). The 102 parameters have been used for this layer. The model comprises 6,006 distinct parameters in total, every one of that is trainable. The parameters that can be trained are modified to enhance the performance of the model (see Table <xref rid="Tab5" ref-type="table">5</xref>). These non-trainable parameters of model are set to 0. The design of the model, the variable&#8217;s count for every layer, along with the form of the result at each level are all described in this overview. It aids in comprehending the neural network model's intricacy and capabilities. Adam, the optimizer, is configured by the code with particular weight decay and learning rate. During training, the optimize is in charge of adjusting the neural network's weights. Categorical cross-entropy, a popular loss function for multi-class classification issues, was selected as the loss function.
<table-wrap id="Tab5" position="float" orientation="portrait"><label>Table&#160;5</label><caption><p>The CNN model&#8217;s performance comparison</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Accuracy</th><th align="left" colspan="1" rowspan="1">Total Parameter (million)</th><th align="left" colspan="1" rowspan="1">Trainable Parameter (million)</th><th align="left" colspan="1" rowspan="1">Traning Time</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">ReseNet and AlexNet</td><td align="left" colspan="1" rowspan="1">49</td><td align="left" colspan="1" rowspan="1">61.23</td><td align="left" colspan="1" rowspan="1">2.46</td><td align="left" colspan="1" rowspan="1">51</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG19</td><td align="left" colspan="1" rowspan="1">92</td><td align="left" colspan="1" rowspan="1">143.21</td><td align="left" colspan="1" rowspan="1">20.01</td><td align="left" colspan="1" rowspan="1">59</td></tr><tr><td align="left" colspan="1" rowspan="1">DenseNet169</td><td align="left" colspan="1" rowspan="1">96.37</td><td align="left" colspan="1" rowspan="1">25.13</td><td align="left" colspan="1" rowspan="1">23.40</td><td align="left" colspan="1" rowspan="1">65</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG16</td><td align="left" colspan="1" rowspan="1">50.55</td><td align="left" colspan="1" rowspan="1">138.37</td><td align="left" colspan="1" rowspan="1">14.69</td><td align="left" colspan="1" rowspan="1">55</td></tr><tr><td align="left" colspan="1" rowspan="1">GenoDense-Net</td><td align="left" colspan="1" rowspan="1">99.18</td><td align="left" colspan="1" rowspan="1">20.32</td><td align="left" colspan="1" rowspan="1">7.66</td><td align="left" colspan="1" rowspan="1">63</td></tr></tbody></table></table-wrap></p><p id="Par80">Every training development of each epoch in the training and validation of model is valuable. The information is broken out as follows; Epoch: When training for this particular epoch, the loss function's value is called the loss. It displays the model's performance and shows how closely the predictions match the actual numbers, and Accuracy: The model's accuracy for the training data set represents up to this present epoch. It displays the percentage of accurately predicted samples. Several of the test models (VGG-19, ResNet-50,&#160;AlexNet, and VGG-16) were developed applying transfer learning techniques with previously trained ImageNet parameters in order to guarantee an even evaluation. Binary classification was used for the last fully connected layers. The training setup (batch size&#8201;=&#8201;32, learning rate&#8201;=&#8201;0.001), number of epochs (40), and data preparation were identical for every model. The Google Colaboratory with GPU support (identical hardware environment) was used for the training. A comparison of training efficiency, model complexity, and performance is shown in Table&#160;<xref rid="Tab5" ref-type="table">5</xref>. In particular, we used pairwise t-tests (with Bonferroni correction) after a one-way ANOVA test to assess the significance of the performance differences between the previous models and GenoDense-Net. Accuracy scores gathered from five separate runs of each model utilizing identical train-test splits have been used for the tests. The ANOVA findings verified that the mean accuracy of the models varied statistically significantly (p&#8201;&lt;&#8201;0.01). Furthermore, GenoDense-Net's improvements over all other models are statistically significant, according to the t-tests (p&#8201;&lt;&#8201;0.05 after correction) (see Table&#160;<xref rid="Tab6" ref-type="table">6</xref>).
<table-wrap id="Tab6" position="float" orientation="portrait"><label>Table&#160;6</label><caption><p>The CNN model&#8217;s statistical comparison</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1"><italic toggle="yes">p</italic>-value vs t-test</th><th align="left" colspan="1" rowspan="1">Standard Deviation</th><th align="left" colspan="1" rowspan="1">Statistical Significant</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">ReseNet and AlexNet</td><td align="left" colspan="1" rowspan="1">&#8201;&lt;&#8201;0.001</td><td align="left" colspan="1" rowspan="1">1.13</td><td align="left" colspan="1" rowspan="1">Significant</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG19</td><td align="left" colspan="1" rowspan="1">0.002</td><td align="left" colspan="1" rowspan="1">0.96</td><td align="left" colspan="1" rowspan="1">Significant</td></tr><tr><td align="left" colspan="1" rowspan="1">DenseNet169</td><td align="left" colspan="1" rowspan="1">0.003</td><td align="left" colspan="1" rowspan="1">1.05</td><td align="left" colspan="1" rowspan="1">Significant</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG16</td><td align="left" colspan="1" rowspan="1">&#8201;&lt;&#8201;0.001</td><td align="left" colspan="1" rowspan="1">1.10</td><td align="left" colspan="1" rowspan="1">Significant</td></tr><tr><td align="left" colspan="1" rowspan="1">GenoDense-Net</td><td align="left" colspan="1" rowspan="1">-</td><td align="left" colspan="1" rowspan="1">0.33</td><td align="left" colspan="1" rowspan="1">-</td></tr></tbody></table></table-wrap></p><p id="Par81">Additionally, we have emphasized the special contribution of GenoDense-Net, a hybrid model that combines an image-inspired DenseNet structure with genome-wide coding to enable high accuracy (99.18%) with the classification of infectious diseases from DNA sequences while preserving computational clarity. This comparison makes our work's positioning stronger (see Table&#160;<xref rid="Tab7" ref-type="table">7</xref>) and makes clear how original it is compared to probabilistic and transformer-based&#160;sequence models. The model&#8217;s complexity comparison is presented in Table&#160;<xref rid="Tab8" ref-type="table">8</xref>.
<table-wrap id="Tab7" position="float" orientation="portrait"><label>Table&#160;7</label><caption><p>GenoDense-Net compared to the most advanced genomic models of AI</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Task</th><th align="left" colspan="1" rowspan="1">Architecture</th><th align="left" colspan="1" rowspan="1">Performance</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">GenomeBERT</td><td align="left" colspan="1" rowspan="1">Annotation of the genome and prediction of variation effects</td><td align="left" colspan="1" rowspan="1">BERT (Transformer)</td><td align="left" colspan="1" rowspan="1">F1-score &#8776; 93%&#8211;97%</td></tr><tr><td align="left" colspan="1" rowspan="1">DeepSEA</td><td align="left" colspan="1" rowspan="1">Chromatin characteristics and the prediction of regulatory regions</td><td align="left" colspan="1" rowspan="1">CNN</td><td align="left" colspan="1" rowspan="1">AUC &#8776; 95%</td></tr><tr><td align="left" colspan="1" rowspan="1">DeepVariant</td><td align="left" colspan="1" rowspan="1">Calling SNPs and indel variants</td><td align="left" colspan="1" rowspan="1">Multi-task learning on CNN</td><td align="left" colspan="1" rowspan="1">Precision &#8776; 99.49%</td></tr><tr><td align="left" colspan="1" rowspan="1">DanQ</td><td align="left" colspan="1" rowspan="1">Prediction of functional regions</td><td align="left" colspan="1" rowspan="1">BiLSTM&#8201;+&#8201;CNN</td><td align="left" colspan="1" rowspan="1">AUC &#8776; 94%</td></tr><tr><td align="left" colspan="1" rowspan="1">GenoDense-Net</td><td align="left" colspan="1" rowspan="1">Classification of infectious diseases (e.g., COVID-19)</td><td align="left" colspan="1" rowspan="1">DenseNet-16 (Transfer Learning&#8201;+&#8201;CNN)</td><td align="left" colspan="1" rowspan="1"><p>Accuracy&#8201;=&#8201;99.18%</p><p>F1-score: 99.11%</p><p>Precision: 98.96%</p><p>Recall: 98.32%</p><p>MCC: 0.979</p><p>AUC-ROC: 0.989</p></td></tr></tbody></table></table-wrap><table-wrap id="Tab8" position="float" orientation="portrait"><label>Table&#160;8</label><caption><p>The CNN Model&#8217;s complexity comparison</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Inference time per sample in ms</th><th align="left" colspan="1" rowspan="1">Training time per epoch in s</th><th align="left" colspan="1" rowspan="1">Memory usage in GB</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">ReseNet and AlexNet</td><td align="left" colspan="1" rowspan="1">5.3</td><td align="left" colspan="1" rowspan="1">36</td><td align="left" colspan="1" rowspan="1">2.6</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG19</td><td align="left" colspan="1" rowspan="1">5.5</td><td align="left" colspan="1" rowspan="1">66</td><td align="left" colspan="1" rowspan="1">10.2</td></tr><tr><td align="left" colspan="1" rowspan="1">DenseNet169</td><td align="left" colspan="1" rowspan="1">4.7</td><td align="left" colspan="1" rowspan="1">57</td><td align="left" colspan="1" rowspan="1">8.2</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG16</td><td align="left" colspan="1" rowspan="1">9.6</td><td align="left" colspan="1" rowspan="1">64</td><td align="left" colspan="1" rowspan="1">5.2</td></tr><tr><td align="left" colspan="1" rowspan="1">GenoDense-Net</td><td align="left" colspan="1" rowspan="1">3.2</td><td align="left" colspan="1" rowspan="1">43</td><td align="left" colspan="1" rowspan="1">6.7</td></tr></tbody></table></table-wrap></p><p id="Par82">A standard bar plot is depicted in Fig.&#160;<xref rid="Fig11" ref-type="fig">11</xref>, where each bar's length indicates how important a particular feature is. The'Features'axis in this&#160;figure&#160;would stand for image features (such as certain patterns or areas&#160;in the X-ray pictures), and the'significance'axis represents the relative contribution of each feature to the prediction of the model.<fig id="Fig11" position="float" orientation="portrait"><label>Fig. 11</label><caption><p>Feature&#8217;s significance</p></caption><graphic id="MO13" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig11_HTML.jpg"/></fig></p><p id="Par83">Figure&#160;<xref rid="Fig12" ref-type="fig">12</xref> shows the genetic differences between different strains of COVID-19. These many strains are listed on a vertical axis in the picture, while particular genes or areas of the viral genome are indicated on a horizontal axis. Each strain is given a unique hue in the depiction, making it simple to compare their genetic variations and giving a clear picture of the strains'genomic diversity.<fig id="Fig12" position="float" orientation="portrait"><label>Fig. 12</label><caption><p>Genetic variations among strains</p></caption><graphic id="MO14" position="float" orientation="portrait" xlink:href="40794_2025_267_Fig12_HTML.jpg"/></fig></p></sec><sec id="Sec25"><title>Conclusion</title><p id="Par84">In this study, we devised a method for determining a patient's level of infectiousness from their genome sequence using the DenseNet-16 model. We employed a transfer learning strategy after using a pre-trained DenseNet-16 network. Data preprocessing was done using the NearKbest interpolation approach, and optimization was done using Adam Optimizer. Our accuracy was 99.18%. Additionally, we discussed incomplete proteins, sequence identity as a proportion of the genome's sequence, protein length, aromaticity and molecular mass, mutations in the genome's sequence, and a missing index of the genome's sequence. We outperformed ResNet-50, AlexNet,&#160;VGG-19 models, and VGG-16&#160;in terms of accuracy. Future studies should work to close this gap in order to guarantee the model's efficacy and moral application in medical facilities. We have focus on performing an additional thorough validation of clinical research with a bigger, more varied dataset sourced from various medical facilities. We can work on assessing the effectiveness of the model over a range of segments of the population, genders, comprising multiple age brackets, and racial/ethnic groupings, to guarantee that it can be generalized. Also evaluating how the framework affects medical choices, outcomes for patients, and the use of medical resources. Also, we can work on resolving transparency and moral issues in the application of artificial intelligence in medical. Although the suggested methodology is highly accurate at identifying COVID-19 using chest X-ray pictures, there are difficulties when implementing it in actual clinical situations. Careful consideration must be given to variations in patient demographics, imaging conditions, and interaction with medical facilities. To guarantee responsible AI use, ethical issues including model bias, data privacy,and decision openness also need to be addressed. Crucially, our findings are based on a small dataset, and before using the system in standard medical practice, external validation utilizing a variety of multi-center medical data is essential.</p></sec></body><back><fn-group><fn><p><bold>Publisher&#8217;s Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>For their constant encouragement, tolerance, and support during our journey, we are incredibly appreciative of our families and friends.</p></ack><notes notes-type="author-contribution"><title>Authors&#8217; contributions</title><p>All author have equal contribution.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>Open access funding provided by Manipal University Jaipur.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>No datasets were generated or analysed during the current study.</p></notes><notes><title>Declarations</title><notes id="FPar1"><title>Ethics approval and consent to participate</title><p id="Par85">Not applicable.</p></notes><notes id="FPar2"><title>Consent for publication</title><p id="Par86">All participants received and signed a written informed consent before entering a study.</p></notes><notes id="FPar3" notes-type="COI-statement"><title>Competing interests</title><p id="Par87">The authors declare no competing interests.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nawaz</surname><given-names>MS</given-names></name><name name-style="western"><surname>Fournier-Viger</surname><given-names>P</given-names></name><name name-style="western"><surname>Shojaee</surname><given-names>A</given-names></name><name name-style="western"><surname>Fujita</surname><given-names>H</given-names></name></person-group><article-title>Using artificial intelligence techniques for COVID-19 genome analysis</article-title><source>Appl Intell</source><year>2021</year><volume>51</volume><fpage>3086</fpage><lpage>3103</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s10489-021-02193-w</pub-id><pub-id pub-id-type="pmcid">PMC7888282</pub-id><pub-id pub-id-type="pmid">34764587</pub-id></element-citation><mixed-citation id="mc-CR1" publication-type="journal">Nawaz MS, Fournier-Viger P, Shojaee A, Fujita H. Using artificial intelligence techniques for COVID-19 genome analysis. Appl Intell. 2021;51:3086&#8211;103.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s10489-021-02193-w</pub-id><pub-id pub-id-type="pmcid">PMC7888282</pub-id><pub-id pub-id-type="pmid">34764587</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other">M&#225;rquez S, Prado-Vivar B, Guadalupe JJ, Gutierrez B, Becerra-Wong M, Jibaja M, Tobar M, Barrag&#225;n V, Rojas-Silva P, Coloma J, Trueba G. Metagenome of a Bronchoalveolar Lavage Fluid Sample from a Confirmed COVID-19 Case in Quito, Ecuador, Obtained Using Oxford Nanopore MinION Technology. Microbiology Resource Announcements. 2020;9(41):10&#8211;128.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1128/MRA.00996-20</pub-id><pub-id pub-id-type="pmcid">PMC7545292</pub-id><pub-id pub-id-type="pmid">33033138</pub-id></mixed-citation></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dubeya</surname><given-names>S</given-names></name><name name-style="western"><surname>Kumar</surname><given-names>M</given-names></name><name name-style="western"><surname>Verma</surname><given-names>DK</given-names></name></person-group><article-title>Machine learning approaches in deal with the COVID-19: comprehensive study</article-title><source>ECS Trans</source><year>2022</year><volume>107</volume><issue>1</issue><fpage>17815</fpage></element-citation><mixed-citation id="mc-CR3" publication-type="journal">Dubeya S, Kumar M, Verma DK. Machine learning approaches in deal with the COVID-19: comprehensive study. ECS Trans. 2022;107(1):17815.</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dubey</surname><given-names>S</given-names></name><name name-style="western"><surname>Dubey</surname><given-names>S</given-names></name><name name-style="western"><surname>Raghuwanshi</surname><given-names>K</given-names></name></person-group><article-title>Unlocking IoT and machine learning&#8217;s potential for water quality assessment: an extensive analysis and future directions</article-title><source>Water Conserv Sci Eng</source><year>2025</year><volume>10</volume><issue>1</issue><fpage>18</fpage></element-citation><mixed-citation id="mc-CR4" publication-type="journal">Dubey S, Dubey S, Raghuwanshi K. Unlocking IoT and machine learning&#8217;s potential for water quality assessment: an extensive analysis and future directions. Water Conserv Sci Eng. 2025;10(1):18.</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mousavizadeh</surname><given-names>L</given-names></name><name name-style="western"><surname>Ghasemi</surname><given-names>S</given-names></name></person-group><article-title>Genotype and phenotype of COVID-19: their roles in pathogenesis</article-title><source>J Microbiol Immunol Infect</source><year>2021</year><volume>54</volume><issue>2</issue><fpage>159</fpage><lpage>163</lpage><pub-id pub-id-type="pmid">32265180</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jmii.2020.03.022</pub-id><pub-id pub-id-type="pmcid">PMC7138183</pub-id></element-citation><mixed-citation id="mc-CR5" publication-type="journal">Mousavizadeh L, Ghasemi S. Genotype and phenotype of COVID-19: their roles in pathogenesis. J Microbiol Immunol Infect. 2021;54(2):159&#8211;63.<pub-id pub-id-type="pmid">32265180</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jmii.2020.03.022</pub-id><pub-id pub-id-type="pmcid">PMC7138183</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lu</surname><given-names>R</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>X</given-names></name><name name-style="western"><surname>Li</surname><given-names>J</given-names></name><name name-style="western"><surname>Niu</surname><given-names>P</given-names></name><name name-style="western"><surname>Yang</surname><given-names>B</given-names></name><name name-style="western"><surname>Wu</surname><given-names>H</given-names></name><name name-style="western"><surname>Wang</surname><given-names>W</given-names></name><name name-style="western"><surname>Song</surname><given-names>H</given-names></name><name name-style="western"><surname>Huang</surname><given-names>B</given-names></name><name name-style="western"><surname>Zhu</surname><given-names>N</given-names></name><name name-style="western"><surname>Bi</surname><given-names>Y</given-names></name></person-group><article-title>Genomic characterisation and epidemiology of 2019 novel coronavirus: implications for virus origins and receptor binding</article-title><source>Lancet</source><year>2020</year><volume>395</volume><issue>10224</issue><fpage>565</fpage><lpage>574</lpage><pub-id pub-id-type="pmid">32007145</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/S0140-6736(20)30251-8</pub-id><pub-id pub-id-type="pmcid">PMC7159086</pub-id></element-citation><mixed-citation id="mc-CR6" publication-type="journal">Lu R, Zhao X, Li J, Niu P, Yang B, Wu H, Wang W, Song H, Huang B, Zhu N, Bi Y. Genomic characterisation and epidemiology of 2019 novel coronavirus: implications for virus origins and receptor binding. Lancet. 2020;395(10224):565&#8211;74.<pub-id pub-id-type="pmid">32007145</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/S0140-6736(20)30251-8</pub-id><pub-id pub-id-type="pmcid">PMC7159086</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ray</surname><given-names>M</given-names></name><name name-style="western"><surname>Sable</surname><given-names>MN</given-names></name><name name-style="western"><surname>Sarkar</surname><given-names>S</given-names></name><name name-style="western"><surname>Hallur</surname><given-names>V</given-names></name></person-group><article-title>Essential interpretations of bioinformatics in COVID-19 pandemic</article-title><source>Meta Gene</source><year>2021</year><volume>1</volume><issue>27</issue><fpage>100844</fpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.mgene.2020.100844</pub-id><pub-id pub-id-type="pmcid">PMC7744275</pub-id><pub-id pub-id-type="pmid">33349792</pub-id></element-citation><mixed-citation id="mc-CR7" publication-type="journal">Ray M, Sable MN, Sarkar S, Hallur V. Essential interpretations of bioinformatics in COVID-19 pandemic. Meta Gene. 2021;1(27): 100844.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.mgene.2020.100844</pub-id><pub-id pub-id-type="pmcid">PMC7744275</pub-id><pub-id pub-id-type="pmid">33349792</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dubey</surname><given-names>S</given-names></name><name name-style="western"><surname>Verma</surname><given-names>DK</given-names></name><name name-style="western"><surname>Kumar</surname><given-names>M</given-names></name></person-group><article-title>Genome sequence analysis of severe acute respiratory syndrome using GenoAnalytica model</article-title><source>Scalable Comput Pract Exp</source><year>2025</year><volume>26</volume><issue>1</issue><fpage>361</fpage><lpage>370</lpage></element-citation><mixed-citation id="mc-CR8" publication-type="journal">Dubey S, Verma DK, Kumar M. Genome sequence analysis of severe acute respiratory syndrome using GenoAnalytica model. Scalable Comput Pract Exp. 2025;26(1):361&#8211;70.</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ahmed</surname><given-names>I</given-names></name><name name-style="western"><surname>Ahmad</surname><given-names>M</given-names></name><name name-style="western"><surname>Jeon</surname><given-names>G</given-names></name><name name-style="western"><surname>Piccialli</surname><given-names>F</given-names></name></person-group><article-title>A framework for pandemic prediction using big data analytics</article-title><source>Big Data Res</source><year>2021</year><volume>25</volume><fpage>100190</fpage></element-citation><mixed-citation id="mc-CR9" publication-type="journal">Ahmed I, Ahmad M, Jeon G, Piccialli F. A framework for pandemic prediction using big data analytics. Big Data Res. 2021;25:100190.</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="other">Tripathi A, Chourasia U, Dubey S, Arjariya A, Dixit P. A Survey: Optimization Algorithms In Deep Learning. InProceedings of the International Conference on Innovative Computing &amp; Communications (ICICC). 2020.</mixed-citation></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dubey</surname><given-names>S</given-names></name><name name-style="western"><surname>Verma</surname><given-names>DK</given-names></name><name name-style="western"><surname>Kumar</surname><given-names>M</given-names></name></person-group><article-title>Severe acute respiratory syndrome coronavirus 2 GenoAnalyzer and mutagenic anomaly detector using FCMFI and NSCE</article-title><source>Int J Biol Macromol</source><year>2024</year><volume>258</volume><fpage>129051</fpage><pub-id pub-id-type="pmid">38159703</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.ijbiomac.2023.129051</pub-id></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Dubey S, Verma DK, Kumar M. Severe acute respiratory syndrome coronavirus 2 GenoAnalyzer and mutagenic anomaly detector using FCMFI and NSCE. Int J Biol Macromol. 2024;258: 129051.<pub-id pub-id-type="pmid">38159703</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.ijbiomac.2023.129051</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ullah</surname><given-names>K</given-names></name><name name-style="western"><surname>Ahmed</surname><given-names>I</given-names></name><name name-style="western"><surname>Ahmad</surname><given-names>M</given-names></name><name name-style="western"><surname>Rahman</surname><given-names>AU</given-names></name><name name-style="western"><surname>Nawaz</surname><given-names>M</given-names></name><name name-style="western"><surname>Adnan</surname><given-names>A</given-names></name></person-group><article-title>Rotation invariant person tracker using top view</article-title><source>&#160;J Ambient Intell Humaniz Comput</source><year>2019</year><volume>4</volume><fpage>1</fpage><lpage>7</lpage></element-citation><mixed-citation id="mc-CR12" publication-type="journal">Ullah K, Ahmed I, Ahmad M, Rahman AU, Nawaz M, Adnan A. Rotation invariant person tracker using top view. J Ambient Intell Humaniz Comput. 2019;4:1&#8211;7.</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="other">Dubey S, Verma DK, Kumar,M. Identification of Unique Genomic Signatures in Viral Immunogenic Syndrome (VIS) Using FIMAR and FCSM Methods for Development of Effective Diagnostic and Therapeutic Strategies , Economic Computation Economic Cybernetics Studies Research. 2024 58(2).</mixed-citation></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dubey</surname><given-names>S</given-names></name><name name-style="western"><surname>Singh</surname><given-names>S</given-names></name><name name-style="western"><surname>Verma</surname><given-names>DK</given-names></name><name name-style="western"><surname>Lodhi</surname><given-names>SK</given-names></name><name name-style="western"><surname>Dubey</surname><given-names>S</given-names></name></person-group><article-title>Genocare prognosticator model: host genetics predict severity of infectious disease</article-title><source>Scalable Comput Pract Exp</source><year>2025</year><volume>26</volume><issue>2</issue><fpage>924</fpage><lpage>939</lpage></element-citation><mixed-citation id="mc-CR14" publication-type="journal">Dubey S, Singh S, Verma DK, Lodhi SK, Dubey S. Genocare prognosticator model: host genetics predict severity of infectious disease. Scalable Comput Pract Exp. 2025;26(2):924&#8211;39.</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Meraihi</surname><given-names>Y</given-names></name><name name-style="western"><surname>Gabis</surname><given-names>AB</given-names></name><name name-style="western"><surname>Mirjalili</surname><given-names>S</given-names></name><name name-style="western"><surname>Ramdane-Cherif</surname><given-names>A</given-names></name><name name-style="western"><surname>Alsaadi</surname><given-names>FE</given-names></name></person-group><article-title>Machine learning-based research for covid-19 detection, diagnosis, and prediction: a survey</article-title><source>SN Comput Sci</source><year>2022</year><volume>3</volume><issue>4</issue><fpage>286</fpage><pub-id pub-id-type="pmid">35578678</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s42979-022-01184-z</pub-id><pub-id pub-id-type="pmcid">PMC9096341</pub-id></element-citation><mixed-citation id="mc-CR15" publication-type="journal">Meraihi Y, Gabis AB, Mirjalili S, Ramdane-Cherif A, Alsaadi FE. Machine learning-based research for covid-19 detection, diagnosis, and prediction: a survey. SN Comput Sci. 2022;3(4):286.<pub-id pub-id-type="pmid">35578678</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s42979-022-01184-z</pub-id><pub-id pub-id-type="pmcid">PMC9096341</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leal</surname><given-names>VN</given-names></name><name name-style="western"><surname>Paulino</surname><given-names>LM</given-names></name><name name-style="western"><surname>Cambui</surname><given-names>RA</given-names></name><name name-style="western"><surname>Zupelli</surname><given-names>TG</given-names></name><name name-style="western"><surname>Yamada</surname><given-names>SM</given-names></name><name name-style="western"><surname>Oliveira</surname><given-names>LA</given-names></name><name name-style="western"><surname>Pontillo</surname><given-names>A</given-names></name></person-group><article-title>A common variant close to the &#8220;tripwire&#8221; linker region of NLRP1 contributes to severe COVID-19</article-title><source>Inflamm Res</source><year>2022</year><pub-id pub-id-type="doi">10.1007/s00011-022-01670-3</pub-id><pub-id pub-id-type="pmid">36416944</pub-id><pub-id pub-id-type="pmcid">PMC9684769</pub-id></element-citation><mixed-citation id="mc-CR16" publication-type="journal">Leal VN, Paulino LM, Cambui RA, Zupelli TG, Yamada SM, Oliveira LA, Pontillo A. A common variant close to the &#8220;tripwire&#8221; linker region of NLRP1 contributes to severe COVID-19. Inflamm Res. 2022. 10.1007/s00011-022-01670-3.<pub-id pub-id-type="pmid">36416944</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s00011-022-01670-3</pub-id><pub-id pub-id-type="pmcid">PMC9684769</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dubey</surname><given-names>S</given-names></name><name name-style="western"><surname>Verma</surname><given-names>DK</given-names></name><name name-style="western"><surname>Kumar</surname><given-names>M</given-names></name></person-group><article-title>Real-time infectious disease endurance indicator system for scientific decisions using machine learning and rapid data processing</article-title><source>PeerJ Comput Sci</source><year>2024</year><volume>10</volume><fpage>e2062</fpage><pub-id pub-id-type="pmid">39145255</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.7717/peerj-cs.2062</pub-id><pub-id pub-id-type="pmcid">PMC11323025</pub-id></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Dubey S, Verma DK, Kumar M. Real-time infectious disease endurance indicator system for scientific decisions using machine learning and rapid data processing. PeerJ Comput Sci. 2024;10: e2062.<pub-id pub-id-type="pmid">39145255</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.7717/peerj-cs.2062</pub-id><pub-id pub-id-type="pmcid">PMC11323025</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Khaled</surname><given-names>K</given-names></name><name name-style="western"><surname>Singla</surname><given-names>MK</given-names></name></person-group><article-title>Predictive analysis of groundwater resources using random forest regression</article-title><source>J Artif Intell Metaheuristics</source><year>2025</year><volume>9</volume><issue>01</issue><fpage>11</fpage><lpage>9</lpage></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Khaled K, Singla MK. Predictive analysis of groundwater resources using random forest regression. J Artif Intell Metaheuristics. 2025;9(01):11&#8211;9.</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Elshabrawy</surname><given-names>M</given-names></name></person-group><article-title>A review on waste management techniques for sustainable energy production</article-title><source>Metaheuristic Optim Rev</source><year>2025</year><volume>3</volume><fpage>47</fpage><lpage>58</lpage></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Elshabrawy M. A review on waste management techniques for sustainable energy production. Metaheuristic Optim Rev. 2025;3:47&#8211;58.</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alhussan</surname><given-names>AA</given-names></name><name name-style="western"><surname>Khafaga</surname><given-names>DS</given-names></name><name name-style="western"><surname>El-Kenawy</surname><given-names>ES</given-names></name><name name-style="western"><surname>Ibrahim</surname><given-names>A</given-names></name><name name-style="western"><surname>Eid</surname><given-names>MM</given-names></name><name name-style="western"><surname>Abdelhamid</surname><given-names>AA</given-names></name></person-group><article-title>Pothole and plain road classification using adaptive mutation dipper throated optimization and transfer learning for self driving cars</article-title><source>IEEE Access</source><year>2022</year><volume>5</volume><issue>10</issue><fpage>84188</fpage><lpage>84211</lpage></element-citation><mixed-citation id="mc-CR20" publication-type="journal">Alhussan AA, Khafaga DS, El-Kenawy ES, Ibrahim A, Eid MM, Abdelhamid AA. Pothole and plain road classification using adaptive mutation dipper throated optimization and transfer learning for self driving cars. IEEE Access. 2022;5(10):84188&#8211;211.</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Riesselman</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Ingraham</surname><given-names>JB</given-names></name><name name-style="western"><surname>Marks</surname><given-names>DS</given-names></name></person-group><article-title>Deep generative models of genetic variation capture the effects of mutations</article-title><source>Nat Methods</source><year>2018</year><volume>15</volume><issue>10</issue><fpage>816</fpage><lpage>822</lpage><pub-id pub-id-type="pmid">30250057</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41592-018-0138-4</pub-id><pub-id pub-id-type="pmcid">PMC6693876</pub-id></element-citation><mixed-citation id="mc-CR21" publication-type="journal">Riesselman AJ, Ingraham JB, Marks DS. Deep generative models of genetic variation capture the effects of mutations. Nat Methods. 2018;15(10):816&#8211;22.<pub-id pub-id-type="pmid">30250057</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41592-018-0138-4</pub-id><pub-id pub-id-type="pmcid">PMC6693876</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Liu J, Yang M, Yu Y, Xu H, Li K, Zhou X. Large language models in bioinformatics: applications and perspectives. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2401.04155">arXiv:2401.04155</ext-link>. 2024 Jan 8.</mixed-citation></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hassib</surname><given-names>EM</given-names></name><name name-style="western"><surname>El-Desouky</surname><given-names>AI</given-names></name><name name-style="western"><surname>El-Kenawy</surname><given-names>ES</given-names></name><name name-style="western"><surname>El-Ghamrawy</surname><given-names>SM</given-names></name></person-group><article-title>An imbalanced big data mining framework for improving optimization algorithms performance</article-title><source>IEEE Access</source><year>2019</year><volume>26</volume><issue>7</issue><fpage>170774</fpage><lpage>170795</lpage></element-citation><mixed-citation id="mc-CR23" publication-type="journal">Hassib EM, El-Desouky AI, El-Kenawy ES, El-Ghamrawy SM. An imbalanced big data mining framework for improving optimization algorithms performance. IEEE Access. 2019;26(7):170774&#8211;95.</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Salamai AA, El-kenawy ES, Abdelhameed I. Dynamic voting classifier for risk identification in supply chain 4.0. Computers, Materials &amp; Continua. 2021;69(3).</mixed-citation></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alnowaiser</surname><given-names>K</given-names></name><name name-style="western"><surname>Saber</surname><given-names>A</given-names></name><name name-style="western"><surname>Hassan</surname><given-names>E</given-names></name><name name-style="western"><surname>Awad</surname><given-names>WA</given-names></name></person-group><article-title>An optimized model based on adaptive convolutional neural network and grey wolf algorithm for breast cancer diagnosis</article-title><source>PLoS One</source><year>2024</year><volume>19</volume><issue>8</issue><fpage>e0304868</fpage><pub-id pub-id-type="pmid">39159151</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0304868</pub-id><pub-id pub-id-type="pmcid">PMC11332925</pub-id></element-citation><mixed-citation id="mc-CR25" publication-type="journal">Alnowaiser K, Saber A, Hassan E, Awad WA. An optimized model based on adaptive convolutional neural network and grey wolf algorithm for breast cancer diagnosis. PLoS One. 2024;19(8): e0304868.<pub-id pub-id-type="pmid">39159151</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0304868</pub-id><pub-id pub-id-type="pmcid">PMC11332925</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Elbedwehy</surname><given-names>S</given-names></name><name name-style="western"><surname>Hassan</surname><given-names>E</given-names></name><name name-style="western"><surname>Saber</surname><given-names>A</given-names></name><name name-style="western"><surname>Elmonier</surname><given-names>R</given-names></name></person-group><article-title>Integrating neural networks with advanced optimization techniques for accurate kidney disease diagnosis</article-title><source>Sci Rep</source><year>2024</year><volume>14</volume><issue>1</issue><fpage>21740</fpage><pub-id pub-id-type="pmid">39289394</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-024-71410-6</pub-id><pub-id pub-id-type="pmcid">PMC11408592</pub-id></element-citation><mixed-citation id="mc-CR26" publication-type="journal">Elbedwehy S, Hassan E, Saber A, Elmonier R. Integrating neural networks with advanced optimization techniques for accurate kidney disease diagnosis. Sci Rep. 2024;14(1):21740.<pub-id pub-id-type="pmid">39289394</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-024-71410-6</pub-id><pub-id pub-id-type="pmcid">PMC11408592</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hassan</surname><given-names>E</given-names></name><name name-style="western"><surname>Saber</surname><given-names>A</given-names></name><name name-style="western"><surname>Elbedwehy</surname><given-names>S</given-names></name></person-group><article-title>Knowledge distillation model for Acute Lymphoblastic Leukemia Detection: Exploring the impact of nesterov-accelerated adaptive moment estimation optimizer</article-title><source>Biomed Signal Process Control</source><year>2024</year><volume>1</volume><issue>94</issue><fpage>106246</fpage></element-citation><mixed-citation id="mc-CR27" publication-type="journal">Hassan E, Saber A, Elbedwehy S. Knowledge distillation model for Acute Lymphoblastic Leukemia Detection: Exploring the impact of nesterov-accelerated adaptive moment estimation optimizer. Biomed Signal Process Control. 2024;1(94): 106246.</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Biswas</surname><given-names>B</given-names></name><name name-style="western"><surname>Chattopadhyay</surname><given-names>S</given-names></name><name name-style="western"><surname>Hazra</surname><given-names>S</given-names></name><name name-style="western"><surname>Hansda</surname><given-names>AK</given-names></name><name name-style="western"><surname>Goswami</surname><given-names>R</given-names></name></person-group><article-title>COVID-19 pandemic: the delta variant, T-cell responses, and the efficacy of developing vaccines</article-title><source>Inflamm Res</source><year>2022</year><volume>71</volume><issue>4</issue><fpage>377</fpage><lpage>396</lpage><pub-id pub-id-type="pmid">35292834</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s00011-022-01555-5</pub-id><pub-id pub-id-type="pmcid">PMC8923340</pub-id></element-citation><mixed-citation id="mc-CR28" publication-type="journal">Biswas B, Chattopadhyay S, Hazra S, Hansda AK, Goswami R. COVID-19 pandemic: the delta variant, T-cell responses, and the efficacy of developing vaccines. Inflamm Res. 2022;71(4):377&#8211;96.<pub-id pub-id-type="pmid">35292834</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s00011-022-01555-5</pub-id><pub-id pub-id-type="pmcid">PMC8923340</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other">Jia P, Chen L, Lyu D. Fine-grained population mobility data-based community-level COVID-19 prediction model. Cybernet Syst. 2022;(1). 10.1080/01969722.2022.2103614.</mixed-citation></ref></ref-list></back></article>
        
    </metadata>
</record>
    </GetRecord>

</OAI-PMH>