


<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
    <responseDate>2025-09-09T13:47:42Z</responseDate>
    <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:12405504" metadataPrefix="pmc">https://pmc.ncbi.nlm.nih.gov/api/oai/v1/mh/</request>
    
    <GetRecord>
        <record>
    <header>
    <identifier>oai:pubmedcentral.nih.gov:12405504</identifier>
    <datestamp>2025-09-04</datestamp>
    
        
        <setSpec>scirep</setSpec>
        
    
        
        <setSpec>pmc-open</setSpec>
        
    
</header>
    <metadata>
        
        <article xmlns="https://jats.nlm.nih.gov/ns/archiving/1.4/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.4/ https://jats.nlm.nih.gov/archiving/1.4/xsd/JATS-archivearticle1-4.xsd" article-type="research-article" xml:lang="en" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-id journal-id-type="pmc-domain-id">1579</journal-id><journal-id journal-id-type="pmc-domain">scirep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12405504</article-id><article-id pub-id-type="pmcid-ver">PMC12405504.1</article-id><article-id pub-id-type="pmcaid">12405504</article-id><article-id pub-id-type="pmcaiid">12405504</article-id><article-id pub-id-type="pmid">40897752</article-id><article-id pub-id-type="doi">10.1038/s41598-025-17647-1</article-id><article-id pub-id-type="publisher-id">17647</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A novel technique for ransomware detection using image based dynamic features and transfer learning to address dataset limitations</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name name-style="western"><surname>Ferdous</surname><given-names initials="J">Jannatul</given-names></name><address><email>jferdous@csu.edu.au</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Islam</surname><given-names initials="R">Rafiqul</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Mahboubi</surname><given-names initials="A">Arash</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Islam</surname><given-names initials="MZ">Md Zahidul</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00wfvh315</institution-id><institution-id institution-id-type="GRID">grid.1037.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 0368 0777</institution-id><institution>School of Computing, Mathematics and Engineering, </institution><institution>Charles Sturt University, </institution></institution-wrap>Wagga Wagga, NSW 2650 Australia </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00wfvh315</institution-id><institution-id institution-id-type="GRID">grid.1037.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 0368 0777</institution-id><institution>School of Computing, Mathematics and Engineering, </institution><institution>Charles Sturt University, </institution></institution-wrap>Albury, NSW 2640 Australia </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00wfvh315</institution-id><institution-id institution-id-type="GRID">grid.1037.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 0368 0777</institution-id><institution>School of Computing, Mathematics and Engineering, </institution><institution>Charles Sturt University, </institution></institution-wrap>Port Macquarie, NSW 2444 Australia </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00wfvh315</institution-id><institution-id institution-id-type="GRID">grid.1037.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 0368 0777</institution-id><institution>School of Computing, Mathematics and Engineering, </institution><institution>Charles Sturt University, </institution></institution-wrap>Bathurst, NSW 2795 Australia </aff></contrib-group><pub-date pub-type="epub"><day>2</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>15</volume><issue-id pub-id-type="pmc-issue-id">478255</issue-id><elocation-id>32342</elocation-id><history><date date-type="received"><day>7</day><month>3</month><year>2025</year></date><date date-type="accepted"><day>26</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>02</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>04</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-04 00:25:59.930"><day>04</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article&#8217;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#8217;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>.</license-p></license></permissions><self-uri content-type="pmc-pdf" xlink:href="41598_2025_Article_17647.pdf"/><abstract id="Abs1"><p id="Par7">The increasing frequency of ransomware attacks necessitates the development of more effective detection methods. Existing image-based ransomware detection approaches have largely focused on static analysis, overlooking specialized ransomware behaviors such as encryption, privilege escalation, and system recovery disruption. Although dynamic and memory forensics-based visualization methods exist in the broader malware domain, they primarily target generic malware families and often rely on memory dumps or system snapshots without transforming behavioral features into spatially meaningful representations. Moreover, traditional machine learning methods such as Random Forest (RF), Support Vector Machine (SVM), and K-Nearest Neighbors (KNN) typically depend on manual feature engineering and large labelled datasets, limiting scalability and adaptability. To address these limitations, we propose a novel behavior-to-image ransomware detection framework that transforms dynamic behavioral features extracted from sandbox-generated JSON reports into two-dimensional (2D) grayscale and color image representations, optimized for transfer learning (TL), enabling effective classification under small-data conditions. Our approach integrates domain-specific feature filtering and impact analysis to ensure the selection of the most ransomware-relevant attributes. TL subsequently automates feature extraction and classification, eliminating the need for separate feature selection procedures and overcoming the time-consuming process of manual feature engineering. Furthermore, by leveraging prior knowledge from large-scale image datasets, TL significantly mitigates the need for extensive labelled data while maintaining high detection accuracy and strong generalization. Experimental results demonstrate that fine-tuned pretrained models, notably ResNet50, achieve up to 99.96% accuracy with a minimal loss factor of 0.0026, even with a small dataset of 500 ransomware and 500 benign samples. We further validated the model&#8217;s interpretability through t-SNE visualizations and saliency maps, confirming its ability to focus on class-discriminative behavioral patterns. The low misclassification rate, along with the transparency of the model, highlights its potential for practical deployment in ransomware detection systems.</p><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.1038/s41598-025-17647-1.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Ransomware</kwd><kwd>Portable executable (PE)</kwd><kwd>Dynamic analysis</kwd><kwd>Convolutional neural network</kwd><kwd>Pretrained models</kwd><kwd>Transfer learning</kwd><kwd>Image classification</kwd></kwd-group><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Computer science</kwd><kwd>Information technology</kwd></kwd-group><funding-group><award-group><funding-source><institution>This work was supported by Charles Sturt University (CSU) Ph.D. Project Operating Fund</institution></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#169; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par8">The exponential rise in connected devices across sectors such as IoT, industrial IoT (IIoT), healthcare, e-banking, and cyber-physical systems (CPSs) has introduced significant cyber vulnerabilities, particularly for unaware users<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Among these, ransomware stands out as one of the most persistent and damaging threats in the cybersecurity landscape, leveraging this extensive connectivity to exploit vulnerable users and organizations. The most recent report on ransomware activity indicates an alarming 18% increase in activity during the initial five months of 2024<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. Additionally, the SOPHOS 2024 ransomware report shows a dramatic 500% increase in average ransom payments, which reached $2.73&#160;million in 2024&#8212;nearly $1&#160;million more than in the previous year<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. This growing frequency of ransomware attacks and high ransom demands have become significant cybersecurity concerns, necessitating the development of effective detection methods.</p><p id="Par9">Ransomware is a type of malware that encrypts victims&#8217; files, making them inaccessible, and demands a ransom, usually cryptocurrency, for the decryption key. Early ransomware strains were relatively simple but have evolved to become more sophisticated, employing stronger encryption algorithms, targeting specific organizations, and utilizing advanced evasion techniques<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>. Recent high-profile ransomware attacks, such as Lockbit, Conti, Clop, and Blackbasta, have demonstrated the devastating impact of ransomware on individuals, businesses, and critical infrastructure, leading to significant financial losses, operational disruptions, and reputational damage<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR6">6</xref></sup>. Ransomware detection relies on two main analytical approaches, static and dynamic analysis, to identify malicious characteristics or features. Static analysis involves examining the code structure without execution, making it a faster and safer method but limited by its inability to handle obfuscated or encrypted ransomware. Identifying specific patterns or signatures in binaries is ideal for detecting known threats. In contrast, Dynamic analysis observes ransomware behavior in controlled environments, enabling detection of zero-day exploits and APTs that adapt based on the system. Although slower, Dynamic analysis provides deeper insights by capturing real-time interactions like network traffic and file manipulations, making it practical for complex ransomware<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>.</p><p id="Par10">In the current literature, researchers have employed various machine learning (ML) and deep learning (DL) methods to identify and categorize ransomware. As traditional ML methods usually require extensive manual feature engineering, they are labor-intensive and prone to human bias. These models also lack the ability to learn abstract or spatial hierarchies from raw data, thereby limiting their adaptability to evolving ransomware behaviors<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. To address this limitation, recent studies have increasingly used DL techniques for ransomware detection, yielding promising results<sup><xref ref-type="bibr" rid="CR9">9</xref>&#8211;<xref ref-type="bibr" rid="CR11">11</xref></sup>. DL automates feature extraction, thereby bypassing the requirement for manual processing. In recent studies, researchers have employed image-based approaches to improve ransomware detection by converting the complete binary executable into images via various DL techniques, including non-pretrained and pretrained models (transfer learning approaches). Several non-pretrained DL models, such as deep residual networks (DRNs), CNNs, and recurrent networks, have shown promise in image-based ransomware detection with notable approaches<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, IMCFN<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, CNN-LSTM<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, SDIF-NN<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, and malware image processing via the transfer learning (TL) approach<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>.</p><p id="Par11">Transfer learning is a machine learning technique that involves leveraging a pretrained deep learning model on a large dataset to perform a related task on a smaller dataset. TL allows the model to apply previously learned features to new tasks. It has recently achieved significant progress in image-based malware detection and has enabled high accuracy in classifying malware images with less labelled data. This is advantageous for ransomware detection because it addresses the challenges of small training datasets by fine-tuning pretrained models for specific detection tasks. Several studies have used this technique for malware classification, including those<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR15">15</xref>&#8211;<xref ref-type="bibr" rid="CR19">19</xref></sup>.</p><p id="Par12">While studying existing ransomware detection research, we identified several critical challenges and research gaps. Most existing studies have focused on static analysis for image-based ransomware detection, which faces difficulties in effectively identifying advanced ransomware variants using obfuscation techniques. These sophisticated forms of ransomware necessitate the exploration of runtime behavioral features to enhance their detection capabilities<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. However, visual representations of runtime behavioral features have not yet been explored in the existing image-based ransomware detection systems. Further investigations have identified two significant challenges in ransomware detection using dynamic features. First, these methods often face limitations owing to outdated datasets. Second, there is limited availability of active ransomware samples in public repositories, the rapid evolution of ransomware, and ethical and legal constraints<sup><xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR22">22</xref></sup>. These challenges result in substantially smaller datasets for dynamic analyses. Limited data increases the overfitting risk, reduces diverse behavior identification, and undermines reliability in detecting new threats, resulting in poor performance. Several previous studies<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR23">23</xref>,<xref ref-type="bibr" rid="CR24">24</xref></sup> have utilized various ML and DL models to train CSV-formatted data obtained from JSON reports through dynamic analysis. However, the results are unsatisfactory. They obtained 95.9%, 97.28% and 96.34% accuracies. We found that this data format showed lower accuracy for small datasets.</p><p id="Par13">To address these limitations, this study introduces an innovative behavior-to-image ransomware detection pipeline. This pipeline transforms structured dynamic features extracted from sandbox-executed JSON reports into semantically meaningful two-dimensional images utilizing transfer learning, as depicted in Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref>. The process begins with dynamic analysis, which extracts the behavioral traits of ransomware in JSON format, offering rich but complex hierarchically structured insights. The JSON data were converted into structured CSV features to simplify the dataset preparation and feature engineering processes. Although this representation is suitable for numerical analysis, it inherently lacks the spatial relationships that modern deep learning models such as CNNs rely on. To address this gap, we converted CSV data into image representations by adding a new dimension for feature interpretation. For this conversion, we developed two Python scripts: one to automate feature extraction from JSON to CSV formats and the other to transform CSV data into images. This allows the use of pretrained deep learning models, which are extensively trained on large image datasets, to leverage prior knowledge and extract meaningful spatial patterns from these image-based features. To evaluate the effectiveness of the proposed approach, we employed baseline non-pretrained models, including convolutional neural networks (CNNs), artificial neural networks (ANNs), a hybrid model that combines a CNN with long short-term memory (LSTM), and another hybrid model that integrates a CNN with gated recurrent units (GRUs) to train image-based representations. These models struggled to achieve satisfactory results, indicating their limited ability to be generalized to small training datasets. This reinforces the necessity of using pretrained models via the TL approach. The key contributions of this study are as follows:</p><p id="Par14">
<list list-type="order"><list-item><p id="Par15">A Novel behavior-to-image ransomware detection pipeline: We present an innovative end-to-end framework that converts structured dynamic behavioral features derived from sandbox JSON reports into image formats. This framework is specifically tailored for TL-based classification when dealing with small datasets. Unlike prior visual methods that rely on static binary representations (e.g., raw executable bytes, PE headers), sequences of system calls, or memory dumps, our pipeline captures semantically rich runtime behaviors and enhances the ability of the model to detect polymorphic and evolving ransomware variants (e.g., Conti, Ryuk, and Lockbit) in real time.</p></list-item><list-item><p id="Par16">Domain-guided feature engineering with automated extraction: We implement a domain-specific filtering strategy to select 100 behaviorally discriminative features, such as privilege escalation, dropped files, encryption patterns, and anti-analysis techniques. A custom Python-based extractor automates this process across large JSON datasets, thereby ensuring reproducibility and consistency. Each selected feature is numerically encoded and spatially arranged to preserve interpretability in the resulting image representation.</p></list-item><list-item><p id="Par17">Balanced and threat-informed dataset: We curate a balanced dataset of 500 ransomware and 500 benign samples, selected from 25 active and impactful ransomware families from 2019 to 2024 (Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>). Unlike many prior studies that relied on outdated or generic datasets, our dataset reflects the current threat landscapes guided by domain-specific intelligence and prevalence criteria. This addresses critical gaps in prior research, particularly the lack of behavioral diversity and the use of obsolete malware samples.</p></list-item><list-item><p id="Par18">Empirical validation of small-data effectiveness and computational efficiency via TL: We demonstrate that fine-tuned pretrained models (especially ResNet50), combined with behavior-to-image transformation, achieve high detection accuracy even with limited datasets. Additionally, by leveraging pretrained CNN models through TL, we significantly reduced the computational burden compared with training deep learning models from scratch. This enables faster convergence, lower resource consumption, and practical applicability, even under small-data conditions.</p></list-item><list-item><p id="Par19">Model interpretability and reliability: We enhance trust in the proposed detection pipeline by integrating t-SNE and saliency map visualizations, which provide insights into feature space separability and decision focus. These visual tools also supported our misclassification analysis, confirming that the model&#8217;s rare false negatives occurred near class boundaries and could explain the model&#8217;s robustness and interpretability.</p></list-item></list>
</p><p id="Par20">Given the limitations of static and manual or rule-driven behavioral methods against modern polymorphic ransomware, this study introduces a behavior-driven, image-based detection framework. Leveraging real-time dynamic analysis, recent ransomware families, and pretrained CNNs, the approach addresses the lack of up-to-date, behaviorally rich datasets, overcomes the reliance on manual feature engineering, and enables effective detection even in small-data scenarios.</p><p id="Par21">The remainder of this paper is organized as follows. We begin with a review of related works, summarize the key findings, and identify the gaps that our research aims to address. This is followed by a detailed explanation of the proposed methodology, including the processes of dataset creation, image conversion, and detection strategy. We then present our experimental results, illustrate them in detailed Tables and Figures, and compare our results with those of related studies. The discussion section offers a critical analysis of the factors contributing to our model&#8217;s performance and the limitations of our approach. The paper concludes by summarizing the key contributions and their implications for ransomware detection along with suggestions for future research.</p></sec><sec id="Sec34245"><title>Related work</title><p id="Par22">In this section, we review and compare existing research relevant to ransomware detection with a focus on methodologies involving static analysis, dynamic analysis, image-based techniques, and transfer learning. Currently, very few related studies based on TL approaches for ransomware classification exist in the literature. Hence, we describe associated studies on ransomware and more general malware-oriented papers.</p><p id="Par23">Table&#160;<xref rid="Tab1" ref-type="table">1</xref> provides a comparative overview of recent ransomware and malware detection studies, summarizing their dataset sources, feature categories (e.g., static, dynamic, or visual), size of the dataset, model types, and their performance in terms of detection accuracy and key limitations. This summary highlights the lack of approaches that utilize dynamic behavior-to-image transformations, particularly for ransomware classification tasks.</p><p id="Par24">Traditional approaches primarily focus on static analysis, in which features are extracted from the binary code of malicious files to detect potential threats. Manavi and Hamzeh proposed two static analysis methods for detecting ransomwares. The first approach<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> uses PE headers to form a graph, which is then mapped to an eigenspace and transformed into a feature vector to train a random forest (RF) classifier. This method achieved an accuracy of 93.30%. The second approach<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> extracted the header from executable files, built a grayscale image using a zigzag pattern, and trained a custom CNN model with an accuracy of 93.33%. The advantage of these methods is that they do not require a robust understanding of the PE header structure. One limitation is that they did not evaluate the detection of new ransomware families. The study by<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> focused on ransomware detection using deep reinforcement learning (DRL). This study achieved 97.9% accuracy and a 2.1% false detection rate, highlighting the importance of using advanced machine learning techniques to improve the accuracy of ransomware detection. However, the proposed method may not work for new and unknown ransomware variants, limiting static analysis adaptability to evolving threats.</p><p id="Par25">By contrast, dynamic analysis monitor runtime behavior of suspected files and capture critical changes in the system, such as file operations, registry modifications, and network communications. For example<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, proposed a dynamic analysis-based ransomware detection method called EldeRan, which uses regularized logistic regression (RLR). Their approach uses dynamic features like Windows API calls, registry key, file system, and directory operations. They also shared a dataset with 582 ransomware samples from 11 families. They achieved an average accuracy of 96.34%. However, this study did not evaluate the ability of the method to detect new previously unseen ransomware families. The authors in<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> developed a two-stage ransomware detection model using the Markov model and random forest. They first analyzed the API call patterns of ransomware and then combined them with other data such as registry keys and file extensions to enhance detection. They achieved an overall accuracy of 97.3% with 4.8% FPR. Additionally<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, proposed an improved TextCNN model using API call sequences for ransomware detection, achieving an accuracy of 0.959. In<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, the authors proposed XRan, an explainable deep learning-based ransomware detection system using dynamic analysis. Their method integrates features such as API call sequences, DLLs, and mutex operations to enhance the feature space.</p><p id="Par26">XRan utilized a CNN architecture along with XAI techniques such as LIME and SHAP for interpretable detection. The model achieved a true positive rate (TPR) of 99.4%, outperforming state-of-the-art methods. However, this approach is computationally expensive and time consuming. The study<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> proposed SwiftR, a cross-platform ransomware fingerprinting method that uses hierarchical neural networks (HNNs) on hybrid features to achieve high accuracy.</p><p id="Par27">In recent years, Image-based detection techniques have emerged as novel approaches for ransomware detection. This method converts malicious binary files into visual representations, such as grayscale or color images, and applies deep learning to classify malware from benign samples.</p><p id="Par28">
<table-wrap id="Tab1" position="float" orientation="portrait"><label>Table 1</label><caption><p>Comparative summary of state-of-the-art ransomware and malware detection studies, detailing dataset sources, feature types (static, dynamic, or visual), model architectures used, and observed limitations in accuracy or scalability.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Paper</th><th align="left" colspan="1" rowspan="1">Dataset source</th><th align="left" colspan="1" rowspan="1">Feature type (Static, dynamic or visual)</th><th align="left" colspan="1" rowspan="1">Feature name</th><th align="left" colspan="1" rowspan="1">Dataset size (<italic toggle="yes">R</italic>&#8201;=&#8201;Ransomware, M&#8201;=&#8201;Malware, B&#8201;=&#8201;Benign)</th><th align="left" colspan="1" rowspan="1">Name of the models used</th><th align="left" colspan="1" rowspan="1">Accuracy (%)</th><th align="left" colspan="1" rowspan="1">Limitation</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>
</td><td align="left" colspan="1" rowspan="1">VirusTotal and VirusShare</td><td align="left" colspan="1" rowspan="1">Static</td><td align="left" colspan="1" rowspan="1">PE headers</td><td align="left" colspan="1" rowspan="1"><italic toggle="yes">R</italic>&#8201;=&#8201;6000, B&#8201;=&#8201;6000</td><td align="left" colspan="1" rowspan="1">RF</td><td align="left" colspan="1" rowspan="1">93.30</td><td align="left" colspan="1" rowspan="1">Did not evaluate detection of new ransomware families.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>
</td><td align="left" colspan="1" rowspan="1">VirusTotal and VirusShare</td><td align="left" colspan="1" rowspan="1">Visual static features</td><td align="left" colspan="1" rowspan="1">PE headers bytes-based images</td><td align="left" colspan="1" rowspan="1"><italic toggle="yes">R</italic>&#8201;=&#8201;1000, B&#8201;=&#8201;1000</td><td align="left" colspan="1" rowspan="1">CNN</td><td align="left" colspan="1" rowspan="1">93.30</td><td align="left" colspan="1" rowspan="1">Did not evaluate detection of new ransomware families</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>
</td><td align="left" colspan="1" rowspan="1">VirusShare</td><td align="left" colspan="1" rowspan="1">Static</td><td align="left" colspan="1" rowspan="1">PE headers</td><td align="left" colspan="1" rowspan="1"><p><italic toggle="yes">R</italic>&#8201;=&#8201;35,367,</p><p>B&#8201;=&#8201;27,118</p></td><td align="left" colspan="1" rowspan="1">DRL</td><td align="left" colspan="1" rowspan="1">97.9</td><td align="left" colspan="1" rowspan="1">May not be effective against new and unknown ransomware variants.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>
</td><td align="left" colspan="1" rowspan="1"><p>VirusShare</p><p>Software.Informer</p></td><td align="left" colspan="1" rowspan="1">Dynamic</td><td align="left" colspan="1" rowspan="1">API calls, file system, registry keys, directory operations etc.</td><td align="left" colspan="1" rowspan="1"><p><italic toggle="yes">R</italic>&#8201;=&#8201;582,</p><p>B&#8201;=&#8201;942</p></td><td align="left" colspan="1" rowspan="1">Regularized logistic regression (RLR)</td><td align="left" colspan="1" rowspan="1">96.34</td><td align="left" colspan="1" rowspan="1">Did not assess detection of new ransomware families.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>
</td><td align="left" colspan="1" rowspan="1">VirusShare, Softonic.Com</td><td align="left" colspan="1" rowspan="1">Dynamic</td><td align="left" colspan="1" rowspan="1">API calls, file system, Registry key, etc.</td><td align="left" colspan="1" rowspan="1"><p><italic toggle="yes">R</italic>&#8201;=&#8201;1176,</p><p>B&#8201;=&#8201;1160</p></td><td align="left" colspan="1" rowspan="1">Markov model and random forest</td><td align="left" colspan="1" rowspan="1">97.28</td><td align="left" colspan="1" rowspan="1">May struggle to adapt with modern sophisticated ransomware.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>
</td><td align="left" colspan="1" rowspan="1">Sangfor technologies</td><td align="left" colspan="1" rowspan="1">Dynamic</td><td align="left" colspan="1" rowspan="1">API call sequences</td><td align="left" colspan="1" rowspan="1"><p><italic toggle="yes">R</italic>&#8201;=&#8201;1000,</p><p>B&#8201;=&#8201;1000</p></td><td align="left" colspan="1" rowspan="1">TextCNN</td><td align="left" colspan="1" rowspan="1">95.9</td><td align="left" colspan="1" rowspan="1">Convolutional layers not fully optimized and generalizability to unseen ransomware is unclear.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>
</td><td align="left" colspan="1" rowspan="1">ISOT, VirusShare, Software.Informer</td><td align="left" colspan="1" rowspan="1">Dynamic</td><td align="left" colspan="1" rowspan="1">API call sequences, DLLs, and mutex operations</td><td align="left" colspan="1" rowspan="1"><p><italic toggle="yes">R</italic>&#8201;=&#8201;668</p><p>B&#8201;=&#8201;668</p></td><td align="left" colspan="1" rowspan="1">2-layered CNN</td><td align="left" colspan="1" rowspan="1">98.2</td><td align="left" colspan="1" rowspan="1">This method demands substantial computational power and is notably time-consuming.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>
</td><td align="left" colspan="1" rowspan="1"><p>vipre.com</p><p>ninite.com</p></td><td align="left" colspan="1" rowspan="1">Static and dynamic</td><td align="left" colspan="1" rowspan="1">API Sequence, VEX sequence, Byte entropy, Behavioral analysis report</td><td align="left" colspan="1" rowspan="1"><p><italic toggle="yes">R</italic>&#8201;=&#8201;10.3&#160;K</p><p>B&#8201;=&#8201;10&#160;K</p></td><td align="left" colspan="1" rowspan="1">CNN, LSTM, MLP</td><td align="left" colspan="1" rowspan="1">98.75</td><td align="left" colspan="1" rowspan="1">High computational resource demand.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>
</td><td align="left" colspan="1" rowspan="1">VirusShare</td><td align="left" colspan="1" rowspan="1">Visual static features</td><td align="left" colspan="1" rowspan="1">PE header bytes-based images</td><td align="left" colspan="1" rowspan="1"><p><italic toggle="yes">R</italic>&#8201;=&#8201;2023,</p><p>B&#8201;=&#8201;2134</p></td><td align="left" colspan="1" rowspan="1">Xception</td><td align="left" colspan="1" rowspan="1">98.20</td><td align="left" colspan="1" rowspan="1">Relies on static features, limiting generalizability by missing dynamic ransomware behaviors.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>
</td><td align="left" colspan="1" rowspan="1">VirusShare and VirusTotal</td><td align="left" colspan="1" rowspan="1">Static visual</td><td align="left" colspan="1" rowspan="1">PE files into images</td><td align="left" colspan="1" rowspan="1"><p>M&#8201;=&#8201;974,957</p><p>B&#8201;=&#8201;89,004</p></td><td align="left" colspan="1" rowspan="1">CNN-LSTM</td><td align="left" colspan="1" rowspan="1">99.91</td><td align="left" colspan="1" rowspan="1">The study did not examine the system&#8217;s scalability for larger datasets.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>
</td><td align="left" colspan="1" rowspan="1">Kaggle by Microsoft 2015</td><td align="left" colspan="1" rowspan="1">Static visual</td><td align="left" colspan="1" rowspan="1">Hashes as grayscale images</td><td align="left" colspan="1" rowspan="1"><p>M&#8201;=&#8201;5000</p><p>B&#8201;=&#8201;5000</p></td><td align="left" colspan="1" rowspan="1">CNN</td><td align="left" colspan="1" rowspan="1">98.862</td><td align="left" colspan="1" rowspan="1">Ineffective against packed or encrypted malware and need more hardware resources for faster detection.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>
</td><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Static visual</td><td align="left" colspan="1" rowspan="1">APK files images</td><td align="left" colspan="1" rowspan="1"><p><italic toggle="yes">R</italic>&#8201;=&#8201;500</p><p>B&#8201;=&#8201;500</p></td><td align="left" colspan="1" rowspan="1">ResNet50, AlexNet, InceptionV3, ResNet101, etc.</td><td align="left" colspan="1" rowspan="1">99.5</td><td align="left" colspan="1" rowspan="1">May struggle to combat with modern complex and evolving ransomware.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>
</td><td align="left" colspan="1" rowspan="1"><p>Virus-share</p><p>Malimg dataset</p></td><td align="left" colspan="1" rowspan="1">Static visual</td><td align="left" colspan="1" rowspan="1">PE files or malware binaries into images</td><td align="left" colspan="1" rowspan="1">M&#8201;=&#8201;9339</td><td align="left" colspan="1" rowspan="1"><p>VGG16,</p><p>ResNet50, IMCFN</p></td><td align="left" colspan="1" rowspan="1">98.82</td><td align="left" colspan="1" rowspan="1">The authors overlooked the effects of image size and data imbalance on their method. Small and old dataset.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>
</td><td align="left" colspan="1" rowspan="1">Malimg dataset</td><td align="left" colspan="1" rowspan="1">Static visual</td><td align="left" colspan="1" rowspan="1">PE files or malware binaries into images</td><td align="left" colspan="1" rowspan="1">M&#8201;=&#8201;9339</td><td align="left" colspan="1" rowspan="1">VGG16, VGG19, ResNet50, and InceptionV3, MLP</td><td align="left" colspan="1" rowspan="1">98.55</td><td align="left" colspan="1" rowspan="1">This method did not assess scalability or performance on larger datasets.</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>
</td><td align="left" colspan="1" rowspan="1">virussign.com</td><td align="left" colspan="1" rowspan="1">Hybrid (static and dynamic)</td><td align="left" colspan="1" rowspan="1">Visual static and hybrid (static&#8201;+&#8201;dynamic)</td><td align="left" colspan="1" rowspan="1"><p>M&#8201;=&#8201;512</p><p>B&#8201;=&#8201;888</p></td><td align="left" colspan="1" rowspan="1">VGG16 network.</td><td align="left" colspan="1" rowspan="1">94.70 for hybrid and 91.41 for static image</td><td align="left" colspan="1" rowspan="1">The study did not assess the method&#8217;s scalability or resource efficiency.</td></tr></tbody></table></table-wrap>
</p><p id="Par29">For example, Moreira et al.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> applied static analysis to detect ransomware by converting PE header files into color images in a sequential vector pattern and classifying them via Xception convolutional neural networks without transfer learning. They obtained 98.20% accuracy and emphasized the importance of using features extracted during execution to better understand sophisticated ransomware. Bensaoud and Kalita<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> proposed a malware classification system using a hybrid CNN-LSTM model that transforms API calls and opcode sequences into N-gram features, achieving 99.91% accuracy on a dataset of 9,749,57 samples. While the study also explored recent deep learning architectures such as ConvNeXt-T, Swin-T, and ViT-G/14, the CNN-LSTM approach outperformed them. However, this study did not investigate the scalability of the system for larger datasets or its performance in real-world scenarios. Ni et al.<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> proposed a CNN model that utilized the SimHash technique, employing locally sensitive hashing to represent hashes as grayscale images, which were then fed into the CNN model for training. However, the authors noted the need to validate their approach for packed and sophisticated real-world malware, as mentioned in their future research scope. Although this method has shown promise in leveraging visual features for detection, its reliance on static characteristics limits its ability to detect dynamic behavioral patterns, which are crucial for identifying modern ransomware variants.</p><p id="Par30">The use of transfer learning and pretrained deep learning models has significantly advanced malware detection to address the limitations of traditional and image-based methods. TL leverages pretrained models on large datasets, allowing the transfer of learned knowledge to new tasks with minimal retraining. In cybersecurity, pretrained CNNs such as ResNet and AlexNet are used to detect malware by analyzing visualized malicious file features. For example, Vasan et al.<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> leveraged pretrained VGG16 and ResNet50 CNN models for feature extractors and combined their feature maps to achieve excellent classification accuracy using an SVM. However, the authors did not address the impact of the image size and data imbalance on their approach. Kumar and Panda<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> proposed SDIF-CNN, a malware detection framework that uses fine-tuned CNN models and stacked feature maps. Their method leverages fine-tuned VGG16 as a feature extractor, combined with features from VGG19, ResNet50, and InceptionV3, to create a stacked feature map. The optimized feature vector was used to train six classifiers, with MLP achieving the highest accuracy of 98.55% on the MalImg dataset and 94.78% on real-world malware datasets. The framework demonstrated resilience to obfuscation techniques without relying on resource-intensive dynamic analysis. However, this study did not evaluate the scalability or performance of larger datasets. Almomani et al.<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> proposed E2E-RDS, a ransomware detection system that combines static ML and vision-based DL approaches. The vision-based approach converted binary executable files into 2D images and employed 19 fine-tuned and transfer-learned CNN models, with the fine-tuned ResNet50 model attaining 99.5% accuracy, surpassing alternative techniques. Additionally, Rezende et al.<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> proposed a malware classification method using TL with ResNet-50 on grayscale byte plot images, achieving 98.62% accuracy on 9,339 samples from 25 families. The study highlights the effectiveness of TL but lacks a discussion on handling imbalanced datasets or emerging malware variants. Huang et al.<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> proposed a deep-learning-based malware detection method using malware visualization techniques. Static images were generated from file features and dynamic images from behavior reports via the cuckoo sandbox and merged into hybrid images. They employed a pretrained CNN model, VGG16, to train both datasets, achieving an accuracy of 94.70% on the hybrid dataset and 91.41% on the static dataset. The results showed that the hybrid approach outperformed the static approach in terms of malware detection. However, this study did not evaluate the scalability of the method for large deployments or the resource efficiency.</p><sec id="Sec2"><title>Summary</title><p> According to Table&#160;<xref rid="Tab1" ref-type="table">1</xref>, while previous research has achieved promising results via advanced machine learning techniques such as deep learning and transfer learning, significant gaps remain in ransomware detection. Notably, existing studies have relied primarily on static numeric or static-visual features (e.g., PE headers or byte-based images). Dynamic analysis has been used in several studies, including EldeRan<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, XRan<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, and<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>, these approaches primarily target general malware detection and are not tailored to the behavioral aspects which is critical for addressing evolving ransomware threats. Many methods struggle with scalability because of the obfuscation techniques of small datasets, such as packing and encryption. Although some studies have explored dynamic features, they often require significant computational resources and lack real-time adaptability. Furthermore, there is a notable scarcity of research utilizing TL with pretrained models specifically for ransomware detection.</p><p id="Par32">The proposed method introduces image-based dynamic features and transfer learning for ransomware detection, using our balanced dataset of the 25 most relevant ransomware families identified by cyber-threat reports. These addresses critical gaps in literature, including static feature reliance, small dataset generalization, and obfuscation resilience. Image-based dynamic features enhance resilience against obfuscation techniques like packing and encryption. Transfer learning with pretrained models ensures robust performance on small datasets. Lightweight architectures of pretrained models improve computational efficiency and scalability, increasing accuracy and generalizability beyond current methods.</p></sec></sec><sec id="Sec3425425"><title>The proposed ransomware detection approach</title><p id="Par33">In this section, we describe the proposed ransomware detection method. Figure&#160;<xref rid="Fig1" ref-type="fig">1</xref> illustrates the high-level workflow of the behavior-to-image based ransomware detection pipeline. The workflow presents an end-to-end framework for ransomware detection that is designed in three primary phases: (1) dataset creation, (2) visualization, and (3) detection. This structured approach transforms the dynamic behavioral data of ransomware into visual formats, allowing for deep learning-based analysis via both nontrained and pretrained models. Each phase uniquely contributes to the development of a reliable and efficient detection system, which is particularly valuable for managing small and diverse datasets of active ransomware samples. The following subsections describe each phase and the workflow component.</p><sec id="Sec4"><title>Phase 1: dataset creation phase</title><p id="Par34">In Phase 1, the workflow encompasses the collection, detonation, and analysis of ransomware and benign samples to construct a feature-rich dataset for machine learning.</p><sec id="Sec5"><title>Sample collection, distribution, and balancing strategy</title><p id="Par35">We created a balanced dataset by collecting 1000 binary executable samples, including 500 legitimate software applications and 500 ransomware instances, which were selected from 25 distinct ransomware families based on threat intelligence classification. All ransomware samples were collected from MalwareBazaar<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> and VirusShare<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>, whereas benign samples were obtained from SnapFiles<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>, PortableApps.com<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>, and GitHub<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>. This diverse collection ensured a comprehensive and representative dataset for real-world scenarios.</p><p id="Par36">
<fig id="Fig1" position="float" orientation="portrait"><label>Fig. 1</label><caption><p>Proposed ransomware detection workflow.</p></caption><graphic id="d33e929" position="float" orientation="portrait" xlink:href="41598_2025_17647_Fig1_HTML.jpg"/></fig>
</p><p id="Par37">We applied two criteria for selecting ransomware families to ensure relevance and impact in our dataset: (1) a high prevalence of attacks and a significant impact on organizations globally, as reported by various renowned cybersecurity sources from 2019 to 2024, and (2) the appearance of at least two independent reports from reputable cybersecurity firms.</p><p id="Par38">This selection method identifies the most relevant and widespread ransomware families, ensuring that a dataset accurately represents major ransomware threats. Figure&#160;<xref rid="Fig2" ref-type="fig">2</xref> presents a chronological timeline of ransomware families from 2019 to 2024 based on their prevalence and impact. The ordering is based on multi-source threat intelligence reports from 2019<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>, 2020<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>, 2021<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>, 2022<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, 2023<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>, and 2024<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>.</p><p id="Par39">
<fig id="Fig2" position="float" orientation="portrait"><label>Fig. 2</label><caption><p>Timeline showing the prevalence and family wise distribution of ransomware samples collected between 2019 and 2024. The ordering reflects attack frequency and global impact based on multi-source threat intelligence reports.</p></caption><graphic id="d33e971" position="float" orientation="portrait" xlink:href="41598_2025_17647_Fig2_HTML.jpg"/></fig>
</p><p id="Par40">This timeline highlights the evolution of ransomware, starting with prominent early families such as Maze and GandCrab, moving through increasingly sophisticated and widespread ransomware, such as NetWalker, LockBit, and BlackCat, and extending to recent threats, such as Lockbit3 and StopCrypt, in 2024. Each ransomware family was selected and positioned on the basis of its documented reach and influence within specific years, providing a clear view of the shifting ransomware landscape and progression of major threat actors over time. Focusing on prevalent ransomware families, such as LockBit, MedusaLocker, BlackCat, Phobos, and Conti, captures essential adaptive and sophisticated behaviors. This prioritization enhances the understanding of high-risk ransomware characteristics and improves the relevance of the dataset to detection models. Additionally, this study reveals trends in ransomware evolution and the techniques used by major threat actors, supporting a comprehensive analysis of current and emerging threats.</p><p id="Par41">For the collection of ransomware samples, we followed the same criteria outlined by<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, wherein three criteria were employed based on vendor engine detection from VirusTotal<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>.</p><p id="Par42">1) If at least 45 antivirus engines on VirusTotal marked a file as malicious.</p><p id="Par43">2) The sample was included if at least 15 antivirus engines on VirusTotal classified it specifically as ransomware.</p><p id="Par44">3) The majority of engines or at least ten engines should identify the file as belonging to the same ransomware family.</p><p id="Par45">Table&#160;<xref rid="Tab2" ref-type="table">2</xref> provides details regarding the ransomware families used in this study, including the number of samples and an overview of each.</p><p id="Par46">
<table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Ransomware families used in this study offers a brief description of each family and the number of samples collected per family.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Family name</th><th align="left" colspan="1" rowspan="1">No of samples</th><th align="left" colspan="1" rowspan="1">Overview of each family</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">Ryuk</td><td char="." align="char" colspan="1" rowspan="1">15</td><td align="left" colspan="1" rowspan="1">Since 2018, Ryuk has targeted large enterprises and government institutions, often delivered through TrickBot or Emotet malware.</td></tr><tr><td align="left" colspan="1" rowspan="1">GandCrab</td><td char="." align="char" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">GandCrab, a Ransomware-as-a-Service (RaaS), spread by phishing emails, exploit kits, and compromised Remote Desktop Protocol (RDP) services.</td></tr><tr><td align="left" colspan="1" rowspan="1">Cerber</td><td char="." align="char" colspan="1" rowspan="1">9</td><td align="left" colspan="1" rowspan="1">Active since 2016, Cerber has been among the first to offer RaaS and spread it by phishing and exploit kits.</td></tr><tr><td align="left" colspan="1" rowspan="1">Maze</td><td char="." align="char" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">Maze pioneered the &#8220;double extortion&#8221; tactic, encrypting data while threatening to leak it. It targeted large corporations, causing both financial and reputational harm.</td></tr><tr><td align="left" colspan="1" rowspan="1">Makop</td><td char="." align="char" colspan="1" rowspan="1">12</td><td align="left" colspan="1" rowspan="1">Active since 2020, Makop has targeted small and medium businesses by exploiting RDP vulnerabilities.</td></tr><tr><td align="left" colspan="1" rowspan="1">RagnarLocker (Ragnarok)</td><td char="." align="char" colspan="1" rowspan="1">23</td><td align="left" colspan="1" rowspan="1">RagnarLocker targets corporate networks and uses RDP and app vulnerabilities to spread malware and disables volume shadow copies<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>.</td></tr><tr><td align="left" colspan="1" rowspan="1">NetWalker</td><td char="." align="char" colspan="1" rowspan="1">24</td><td align="left" colspan="1" rowspan="1">NetWalker, a C++-coded ransomware, is promoted as RaaS by the CIRCUS SPIDER group, encrypts local files network shares, and exploits logged-in user tokens for further access<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>.</td></tr><tr><td align="left" colspan="1" rowspan="1">Mespinoza (Pysa)</td><td char="." align="char" colspan="1" rowspan="1">18</td><td align="left" colspan="1" rowspan="1">Mespinoza (Pysa) enters systems through spam or RDP credentials, using tools like Mimikatz and PowerShell Empire for credential theft and lateral movement<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>.</td></tr><tr><td align="left" colspan="1" rowspan="1">Clop</td><td char="." align="char" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">Over the past three years, Clop has been an active ransomware group, targeting major global organisations using advanced extortion tactics<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>.</td></tr><tr><td align="left" colspan="1" rowspan="1">REvil (Sodinokibi)</td><td char="." align="char" colspan="1" rowspan="1">26</td><td align="left" colspan="1" rowspan="1">REvil, also known as Sodinokibi, a RaaS model, has been highly active, initiating double extortion in 2020 and exploiting a zero-day vulnerability in the Kaseya VSA server in July 2021<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>.</td></tr><tr><td align="left" colspan="1" rowspan="1">LockBit</td><td char="." align="char" colspan="1" rowspan="1">30</td><td align="left" colspan="1" rowspan="1">LockBit is a highly automated and self-propagating ransomware, making it unique from many other ransomware attacks.</td></tr><tr><td align="left" colspan="1" rowspan="1">Phobos</td><td char="." align="char" colspan="1" rowspan="1">24</td><td align="left" colspan="1" rowspan="1">Phobos typically targets small to medium-sized businesses through insecure RDP connections</td></tr><tr><td align="left" colspan="1" rowspan="1">WastedLocker</td><td char="." align="char" colspan="1" rowspan="1">25</td><td align="left" colspan="1" rowspan="1">WastedLocker is linked with the Evil Corp group and is known for highly targeted attacks on large firms.</td></tr><tr><td align="left" colspan="1" rowspan="1">DarkSide</td><td char="." align="char" colspan="1" rowspan="1">24</td><td align="left" colspan="1" rowspan="1">DarkSide became notorious for attacking Colonial Pipeline, causing major fuel shortages in the U.S.</td></tr><tr><td align="left" colspan="1" rowspan="1">Avaddon</td><td char="." align="char" colspan="1" rowspan="1">16</td><td align="left" colspan="1" rowspan="1">Avaddon, a RaaS operator, employed DDoS attacks for triple extortion in January 2021. It targets victims&#8217; websites or networks to increase ransom demands<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>.</td></tr><tr><td align="left" colspan="1" rowspan="1">MountLocker</td><td char="." align="char" colspan="1" rowspan="1">15</td><td align="left" colspan="1" rowspan="1">MountLocker is known for targeting corporate networks and exfiltrating large amounts of sensitive data.</td></tr><tr><td align="left" colspan="1" rowspan="1">Thanos</td><td char="." align="char" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">Thanos ransomware is notable for its use of the RIPlace evasion technique, which makes detection by antivirus software difficult.</td></tr><tr><td align="left" colspan="1" rowspan="1">Conti</td><td char="." align="char" colspan="1" rowspan="1">18</td><td align="left" colspan="1" rowspan="1">Conti ransomware is known for its speed and efficiency, often deployed in highly coordinated attacks against large organisations.</td></tr><tr><td align="left" colspan="1" rowspan="1">Nefilim</td><td char="." align="char" colspan="1" rowspan="1">11</td><td align="left" colspan="1" rowspan="1">Nefilim ransomware is like Nemty and is known for its data exfiltration before encryption, used as leverage for ransom payments.</td></tr><tr><td align="left" colspan="1" rowspan="1">BlackCat</td><td char="." align="char" colspan="1" rowspan="1">30</td><td align="left" colspan="1" rowspan="1">BlackMatter is a successor to DarkSide, targeting large corporations with sophisticated attacks.</td></tr><tr><td align="left" colspan="1" rowspan="1">Babuk</td><td char="." align="char" colspan="1" rowspan="1">27</td><td align="left" colspan="1" rowspan="1">Babuk ransomware targeted various sectors, including healthcare, and was one of the first groups to adopt a RaaS model for affiliate use.</td></tr><tr><td align="left" colspan="1" rowspan="1">BlackMatter</td><td char="." align="char" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">BlackMatter is a successor to DarkSide, targeting large corporations with sophisticated attacks.</td></tr><tr><td align="left" colspan="1" rowspan="1">MedusaLocker</td><td char="." align="char" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">MedusaLocker primarily targets Windows systems, using batch scripts to propagate and encrypt data.</td></tr><tr><td align="left" colspan="1" rowspan="1">Mallox</td><td char="." align="char" colspan="1" rowspan="1">15</td><td align="left" colspan="1" rowspan="1">Mallox ransomware targets vulnerable servers, encrypting data and demanding ransom for decryption</td></tr><tr><td align="left" colspan="1" rowspan="1">BlueSky</td><td char="." align="char" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">BlueSky ransomware is less widespread but is known for its ability to encrypt both local and networked systems efficiently.</td></tr></tbody></table></table-wrap>
</p></sec><sec id="Sec6"><title>Execution and monitoring</title><p id="Par47">Each sample was executed within a cuckoo sandbox environment<sup><xref ref-type="bibr" rid="CR46">46</xref></sup> which offers interactive real-time monitoring, a user-friendly interface, and captures detailed behavioral data in real time. These data include various system activities such as process creation, file modifications, network communications, and other actions indicative of ransomware behavior.</p></sec><sec id="Sec43535"><title>Feature extraction and preprocessing</title><p id="Par49">Cuckoo Sandbox generated detailed behavioral reports in JSON format for each ransomware and benign sample, encompassing both static and dynamic analysis data. To enable structured downstream analysis, we implemented a domain-specific transformation pipeline that converted these hierarchical JSON files into structured data suitable for machine learning. This involved the following steps:</p><p id="Par50">
<list list-type="order"><list-item><p id="Par51">Feature extraction: Initially, we extracted 120 dynamic behavioral features spanning system behavior categories, including process activities (e.g., process creation and injection), network traffic (e.g., DNS and HTTP requests), registry and file system modifications, API usage, mutexes, and anti-VM techniques. We then selected the 100 most informative features based on domain-informed filtering, prioritizing features that are highly indicative of ransomware activities (e.g., file encryption, registry key modification, and backup deletion. Features were chosen for their low sparsity, appearing consistently across diverse ransomware samples. Features like file_created (indicating new file creation), regkey_written (modifications to the Windows registry), and dns_requests (outbound domain name lookups) were observed across multiple ransomware families and retained for their consistent presence. Additionally, the selected features were cross-referenced with MITRE ATT&amp;CK tactics and validated against findings from recent cybersecurity threat reports from organizations such as Sophos, CrowdStrike, and Trend Micro (2019&#8211;2024).This curated feature set ensures both technical depth and practical relevance, thereby improving the robustness and generalization of the detection model across diverse ransomware families. Preliminary experiments were conducted with 60, 80, and 120 features. However, 100 features provided an optimal trade-off between model performance and computational cost, achieving the highest accuracy and AUC without overfitting. The full list of the 100 extracted features, along with their behavioral descriptions and detection relevance, is provided in Supplementary Table <xref rid="MOESM1" ref-type="media">S1</xref>.</p></list-item><list-item><p>Preprocessing: Following feature extraction, each ransomware and benign sample was processed through a structured pipeline such as normalization, to prepare the behavioral data for CNN-based classification. All extracted values were either originally numeric or transformed into numeric representations during preprocessing to ensure consistent formatting and compatibility with image-based modelling. The following preprocessing rules were applied:<list list-type="simple"><list-item><label>I.</label><p id="Par54">Boolean-type features (e.g., true/false) were binary encoded:</p><p>Behavioral indicators such as privilege escalation attempt, shadow copy deletion, screen capture activity, and sandbox evasion behavior were processed as Boolean fields.</p><p>If the ransomware exhibited this behavior, the feature was encoded as 1 (true).</p><p id="Par57">If a behavior was absent, the feature was encoded as 0 (false).</p></list-item></list></p></list-item><list-item><p id="Par59">Categorical string fields (e.g., IP origin and country names) were quantified as follows:</p><p>String length or frequency of occurrence within the dataset.</p></list-item><list-item><p id="Par62">List-type features (e.g., dropped files, DNS request entries, and VirusTotal positives) were represented by count values indicate the number of elements in the list.</p></list-item><list-item><p id="Par63">Missing or null values were treated as follows:</p><p id="Par64">0 (zero), ensuring a uniform numerical structure across all samples.</p></list-item></list>
</p><p id="Par65">After preprocessing, each sample was represented as a row in a CSV file with 100 numerical features, with fixed column ordering to ensure uniform mapping across samples and saved in structured format. To automate feature extraction and preprocessing, we implemented a Python script &#8216;Preprocess_JSON_to_CSV,&#8217; available in our public GitHub repository<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>. This script extracts and transforms the raw behavioral data into a tabular (CSV) format. The core logic is outlined in Algorithm 1: Extraction and Structuring of dynamic behavioral features from JSON reports.</p><p id="Par399">
<fig id="Figa" position="float" orientation="portrait"><label>Algorithm 1</label><caption><p>Extraction and structuring of dynamic behavioral features from JSON reports.</p></caption><graphic id="d33e1296" position="float" orientation="portrait" xlink:href="41598_2025_17647_Figa_HTML.jpg"/></fig>
</p></sec></sec><sec id="Sec8"><title>Phase 2: visualization phase (Dynamic feature vector-to-image transformation)</title><p id="Par66">This phase transforms the structured numeric features into image representations to enable CNN-based classification. Each sample was initially represented as a 1D numeric vector with 100 features. The visualization process consists of the following three key steps:<list list-type="order"><list-item><p>2D reshaping (grid formation):<list list-type="bullet"><list-item><label/><p id="Par68">To ensure compatibility with CNN architectures, 1D feature vectors were reshaped into 2D square matrices. The final model used 100 features reshaped into a 10&#8201;&#215;&#8201;10 grid without padding, as 100 is a perfect square. For exploratory trials involving 120 features, zero padding was applied to make it 121 and turned it into an 11&#8201;&#215;&#8201;11 matrix. These were tested with the same CNN models as the main tests but were discarded owing to poor performance and misaligned features. No resizing or interpolation was used between formats. The 10&#8201;&#215;&#8201;10 configuration was retained for its high accuracy, spatial coherence, and suitability for CNNs, effectively simulating an image in which each cell represents one feature.</p></list-item></list></p></list-item><list-item><p>Pixel mapping and color encoding:<list list-type="bullet"><list-item><label/><p id="Par70">The reshaped matrix is normalized and converted into an image, where the numeric value of each feature is mapped to the pixel intensity.</p></list-item><list-item><label/><p id="Par71">Two visualization modes are supported:<list list-type="simple"><list-item><label>I.</label><p id="Par73">Grayscale: Feature values were mapped to brightness values of 0&#8211;255.</p></list-item><list-item><label>II.</label><p id="Par74">Color: A perceptual color map (e.g., &#8220;rainbow&#8221;) was applied to enhance the contrast between high and low intensity areas.</p></list-item></list></p></list-item></list></p></list-item><list-item><p>Image saving and directory naming:<list list-type="bullet"><list-item><label/><p id="Par76">The resulting image was saved as a.PNG file in either the <bold>&#8216;</bold>R&#8217; (ransomware) or <bold>&#8216;</bold>G<bold>&#8217;</bold> (benign) folder, depending on its label.</p></list-item><list-item><label/><p id="Par77">These folders are later used by TensorFlow&#8217;s image loading function, which automatically assigns class labels based on directory names.</p></list-item></list></p></list-item></list></p><p id="Par78">By transforming behavioral features into visual grids, pretrained CNNs can effectively learn discriminative patterns that represent ransomware activity. This approach exploits spatial regularities in structured behavioral data to improve detection accuracy. To automate this visualization process, we developed a Python script named &#8216;CSV-to-image conversion,&#8217; available in our public GitHub repository<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>. This script converts the structured dynamic features into 2D image representations. The core logic is outlined in Algorithm 2: Generation of 2D image representations from structured CSV data.</p><p id="Par3999">
<fig id="Figb" position="float" orientation="portrait"><label>Algorithm 2</label><caption><p>Generation of 2D image representations from structured CSV data.</p></caption><graphic id="d33e1370" position="float" orientation="portrait" xlink:href="41598_2025_17647_Figb_HTML.jpg"/></fig>
</p></sec><sec id="Sec12"><title>Phase 3: detection phase</title><p id="Par79">The detection phase is the final stage, in which the processed dataset is fed into various machine learning models to evaluate its accuracy in identifying ransomware from benign samples. We employed both pretrained and non-pretrained machine learning models to classify image-based representations of ransomware and benign samples via a small custom dataset. Owing to the challenges associated with limited data, transfer learning with pretrained models was chosen as the primary method for this task. To further validate the effectiveness of transfer learning, non-pretrained models were employed as baseline comparisons to assess how the models trained from scratch performed relative to the proposed pretrained models. This phase encompasses several critical steps: loading the input dataset, model selection, fine-tuning the hyperparameters, and classification.</p><sec id="Sec3"><title>Loading input dataset</title><p id="Par81">In this step, the model was loaded with the preprocessed dataset and split into 80% training and 20% validation sets, comprising ransomware and benign samples depicted as grayscale or color-mapped images based on dynamic behavioral features. This study used an 80&#8211;20 training&#8211;validation split and leveraged TensorFlow image preprocessing tools for efficient data handling. A balanced 50:50 ratio of ransomware to benign samples is achieved through random sampling and shuffling. The sampling selects a balanced subset from the entire dataset. By contrast, shuffling rearranges the data points to ensure randomness before feeding them into the model. This process is essential for preventing inherent data patterns from affecting the model during training.</p></sec><sec id="Sec13"><title>Model selection</title><p id="Par82">The detection phase incorporates both non-pretrained and pretrained models to evaluate their respective classification efficacies on the given dataset.</p></sec></sec><sec id="Sec14"><title>Pretrained models with transfer learning</title><p id="Par83">Training deep neural networks typically requires substantial time and computational power. Consequently, the primary objective of utilizing transfer learning is to leverage the knowledge acquired from one problem domain and apply it to another, which can lead to a reduction in training time and hardware requirements<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>. It can be implemented by either employing pretrained models as feature extractors for target domain classification or fine-tuning models to develop new learning parameters for the target domain<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. This study leveraged transfer learning by fine-tuning six pretrained CNNc1 models to achieve high ransomware detection accuracy with limited data. A brief description of these models is provided below:</p><p id="Par84">ResNet50: ResNet stands for the residual network and is a deep CNN model. The ResNet architecture incorporates a series of residual blocks with skip connections to address the phenomenon of diminishing accuracy that occurs when the number of layers increases<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>. These skip connections allowed the preservation of information from earlier layers, which helped the network learn better representations of the input data. The ResNet50 CNN model includes a 50-layer residual network. This neural network architecture demonstrated exceptional performance in image classification tasks. Consequently, the ResNet50 model is frequently selected for developing transfer learning models in related applications<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>.</p><p id="Par85">EfficientNetB0: EfficientNetB0 serves as the foundational model within the EfficientNet family, which employs a compound scaling method to proportionally increase the dimensions of convolutional neural networks (CNNs) across depth, width, and resolution. This method yields efficient and effective models, achieving high accuracy with fewer parameters<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>.</p><p id="Par86">Xception: Xception stands for &#8220;Extreme Inception&#8221; and is a deep convolutional neural network architecture that relies entirely on depth wise separable convolution layers, enabling easy definition and modification<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>.</p><p id="Par87">VGG16 and VGG19: The VGG model architecture includes 16 (or 19) layers organized into five convolutional neural network (CNN) blocks and three fully connected layers. Each convolutional layer employed a kernel size of 3&#8201;&#215;&#8201;3, with padding and a stride of 1. Additionally, each block of the VGG model incorporates a max pooling layer to further reduce the spatial dimensions. The max pooling layer uses a kernel size of 2&#8201;&#215;&#8201;2 with additional padding, and a stride of two is implemented to halve the dimensions compared with the preceding block of the model. The VGG model culminates in a fully connected dense layer preceding the softmax layer, which serves as the classification and prediction component<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>.</p><p id="Par88">InceptionV3: InceptionV3, a 48-layer deep convolutional neural network (CNN) architecture, excels in image-processing tasks within computer vision. It reportedly outperforms other deep CNN models such as VGG-Net, GoogleNet, PreLU, and BN-Inception. The literature shows that InceptionV3 attains high performance with relatively shallow convolutional layers using symmetric and asymmetric components such as convolution, pooling, dropout, and dense layers<sup><xref ref-type="bibr" rid="CR53">53</xref>,<xref ref-type="bibr" rid="CR54">54</xref></sup>.</p><p id="Par89">We selected each pretrained model based on the following key criteria: (i) architectural diversity (e.g., residual, depth-wise separable, multi-scale feature extraction capability), (ii) effectiveness on small datasets, (iii) computational feasibility in terms of training time and resource efficiency, and (iv) proven success in malware detection literature, as summarized in Table&#160;<xref rid="Tab3" ref-type="table">3</xref>. This model selection ensures consistency, reproducibility, and fair performance comparisons while maintaining practical feasibility for image-based ransomware detection.</p></sec><sec id="Sec15"><title>Non-pretrained models (performance benchmark)</title><p id="Par90">We employed some non-pretrained models (CNN, ANN, CNN-LSTM, and CNN-GRU) as baseline comparisons to show how the models trained from scratch performed on a small dataset compared to the pretrained models with transfer learning.</p><p id="Par91">Convolutional neural networks (CNNs): CNNs are deep learning models for structured grid-like data like images. They use convolutional layers to learn spatial hierarchies via filters that detect edges, textures, shapes, and patterns.</p><p id="Par92">
<table-wrap id="Tab3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Reasons for choosing the pretrained models used in our experiment.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model name</th><th align="left" colspan="1" rowspan="1">Rationale behind the model selection</th><th align="left" colspan="1" rowspan="1">Reference</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">ResNet50</td><td align="left" colspan="1" rowspan="1">ResNet50&#8217;s efficient feature extraction capability and relatively lighter computational requirements make it highly suitable for ransomware detection tasks. Its residual learning capabilities allow it to adapt effectively to the subtle differences between ransomware and benign samples, even when training on smaller datasets.</td><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR31">31</xref>,<xref ref-type="bibr" rid="CR32">32</xref>,<xref ref-type="bibr" rid="CR49">49</xref></sup>
</td></tr><tr><td align="left" colspan="1" rowspan="1">InceptionV3</td><td align="left" colspan="1" rowspan="1">InceptionV3 captures multiscale features through various filter sizes, enabling it to extract fine-grained feature from smaller images.</td><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR15">15</xref>&#8211;<xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR53">53</xref></sup>
</td></tr><tr><td align="left" colspan="1" rowspan="1">EfficientNetB0</td><td align="left" colspan="1" rowspan="1">EfficientNetB0 maintains high performance due to its architecture optimized for efficiency, making it well-suited for small datasets with fewer data points.</td><td align="left" colspan="1" rowspan="1"><sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR55">55</xref></sup>.</td></tr><tr><td align="left" colspan="1" rowspan="1">Xception</td><td align="left" colspan="1" rowspan="1">Xception uses depth wise separable convolutions to enhance learning efficiency by effectively extracting features from small images.</td><td align="left" colspan="1" rowspan="1"><sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR51">51</xref>,<xref ref-type="bibr" rid="CR56">56</xref></sup>.</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG16 andVGG19</td><td align="left" colspan="1" rowspan="1">VGG16 and VGG19, though older architectures, were included as strong baselines due to their simplicity, widespread use, and consistent performance across various small-data scenarios. Their sequential convolutional layers allow for straightforward feature extraction, and they tend to generalize well. While they may be more parameter-heavy than newer models, they offer stable performance and interpretability, which is particularly valuable in research settings where reproducibility and comparative benchmarking are important. Their inclusion helps establish a reference point for evaluating more recent architectures in our ransomware detection context.</td><td align="left" colspan="1" rowspan="1"><sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR31">31</xref>,<xref ref-type="bibr" rid="CR52">52</xref>,<xref ref-type="bibr" rid="CR57">57</xref>,<xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup>.</td></tr></tbody></table></table-wrap>
</p><p id="Par93">CNNs excel in image classification, object detection, and visual data tasks by capturing local and global patterns with shared weights, thereby increasing computational efficiency<sup><xref ref-type="bibr" rid="CR58">58</xref></sup>.</p><p id="Par94">Artificial Neural Network (ANN): ANNs are networks of interconnected nodes inspired by biological neural networks consisting of an input layer, one or more hidden layers, and an output layer. Each &#8220;neuron&#8221; connects to the neurons in the next layer, adjusting weights to minimize the prediction error. ANNs are applied in tasks such as regression, classification, and time series prediction; however, they generally excel with simple, structured data owing to their fully connected nature and lack of spatial awareness<sup><xref ref-type="bibr" rid="CR58">58</xref></sup>.</p><p id="Par95">CNN-LSTM: The CNN-LSTM model leverages CNNs for spatial pattern processing and LSTMs for learning temporal dependencies, making it ideal for sequential and spatiotemporal data. This model is particularly effective for tasks such as video classification, action recognition, and sequence-based anomaly detection, in which both spatial and temporal patterns are crucial<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>.</p><p id="Par96">CNN-GRU: This integrates a CNN with a GRU, a computationally efficient recurrent neural network that uses fewer parameters than LSTMs. The CNN layers extract spatial features, which are then processed by the GRU layers to capture sequential dependencies. This combination is ideal for tasks such as speech recognition and time series prediction, where speed and efficiency are crucial because of the large datasets or real-time demands<sup><xref ref-type="bibr" rid="CR58">58</xref></sup>.</p><sec id="Sec16"><title>Fine tuning to layers and hyperparameters</title><p id="Par97">Fine-tuning in transfer learning modifies the pretrained layers and optimizes the hyperparameter settings to enhance the system performance. We fine-tuned each CNN-based pretrained model (discussed in the model selection section) for ransomware detection in both the color and grayscale datasets. Table&#160;<xref rid="Tab4" ref-type="table">4</xref> summarizes the key hyperparameter settings used in our experiments, including the optimizer type, learning rate, batch size, loss function, and early stopping criteria, which were consistent across all models to ensure fair comparison and reproducibility.</p><p id="Par98">All the models were initialized with ImageNet weights and trained on images of our dataset with a size of 389&#8201;&#215;&#8201;389 pixels. We removed (including _top&#8201;=&#8201;False) the top classification layers with 1,000 outputs initially designed for the ImageNet dataset. We replaced them with fully connected (FC) layers designed explicitly for ransomware detection, allowing the models to effectively classify ransomware and benign samples. Max pooling has been used as the pooling method to capture dominant features. We added additional dense layers to ResNet50, EfficientNetB0, Xception, and InceptionV3. The addition of dense layers to these complex feature extraction models allows the network to capture task-specific patterns by combining and refining extracted features.</p><p id="Par99">In contrast, we retained the pretrained VGG16 and VGG19 models without extra dense layers to maintain computational efficiency and avoid overfitting, particularly on smaller datasets, because these architectures are already dense and computationally intensive<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>. The Softmax activation function in the classifier guarantees probabilistic outputs for the binary ransomware versus the benign task. The models were optimized using the Adam optimizer, which is a first-order gradient-based algorithm with an initial learning rate of 0.001 and sparse categorical cross-entropy loss function. Sparse categorical cross-entropy was used in this study because our model is designed with two output neurons (one for &#8220;benign&#8221; and one for &#8220;ransomware&#8221;) via a Softmax activation function, effectively treating binary classification as a two-class multiclass problem. This approach aligns with the use of sparse categorical cross-entropy, as it enables integer-encoded labels (0 for &#8220;benign&#8221; and 1 for &#8220;ransomware&#8221;) without requiring one-hot encoding. This aligns with Keras guidelines<sup><xref ref-type="bibr" rid="CR59">59</xref></sup> and recent research<sup><xref ref-type="bibr" rid="CR17">17</xref>,<xref ref-type="bibr" rid="CR60">60</xref>,<xref ref-type="bibr" rid="CR61">61</xref></sup>, ensuring both efficiency and methodological validity. A batch size of 32 was used to improve computational efficiency and prevent unstable gradient updates.</p><p id="Par100">To mitigate overfitting, we used early stopping and learning rate reduction. Overfitting occurs when the model memorizes training data too well and performs poorly on new data. Early stopping prevents this by monitoring model performance on validation data not used for training. It is a technique used in machine learning to stop training a model when it no longer improves its performance on validation data for a specified number of epochs, thereby preventing it from memorizing the training set. For example, if patience is set to five, the model stops training if there is no improvement in the monitored metric for five consecutive epochs. We also used callback (ReduceLROnPlateau) to decrease the learning rate by 0.2 if the validation loss did not improve over three epochs, with a minimum learning rate threshold of 1e-6.</p><p id="Par101">The selected hyperparameters (e.g., learning rate&#8201;=&#8201;0.001, batch size&#8201;=&#8201;32) were determined based on standard practices for training deep CNNs on small datasets, as well as prior studies on ransomware and malware detection<sup><xref ref-type="bibr" rid="CR13">13</xref>&#8211;<xref ref-type="bibr" rid="CR16">16</xref></sup>. Additionally, we performed preliminary tuning experiments on the validation set to confirm that these values offer stable convergence, good generalization, and efficient training performance.</p><p id="Par102">The classification performance was evaluated using metrics such as the accuracy, precision, recall, F1 score, and AUC. Algorithm 3 provides a pseudocode for training fine-tuned pretrained models, detailing the transfer learning process for CNN models in ransomware detection. The algorithm involves the following key steps:<list list-type="bullet"><list-item><p id="Par104">The image datasets were loaded and preprocessed into training and validation sets.</p></list-item><list-item><p id="Par105">Initialize a pretrained model with custom classification layers.</p></list-item><list-item><p id="Par106">The model was then combined with suitable loss functions and metrics.</p></list-item><list-item><p id="Par107">The model was trained via early stopping and learning rate scheduling.</p></list-item><list-item><p id="Par108">The performance of the model was evaluated using precision, recall, F1 score, accuracy, and AUC metrics.</p></list-item></list></p><p id="Par109">This method ensures efficient training on small datasets while leveraging the robust feature extraction capabilities of pretrained CNNs.</p><p id="Par110">
<table-wrap id="Tab4" position="float" orientation="portrait"><label>Table 4</label><caption><p>Hyperparameters for pretrained models.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Hyperparameter</th><th align="left" colspan="1" rowspan="1">Value</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">Include top</td><td align="left" colspan="1" rowspan="1">False</td></tr><tr><td align="left" colspan="1" rowspan="1">Input shape</td><td align="left" colspan="1" rowspan="1">(389, 389, 3)</td></tr><tr><td align="left" colspan="1" rowspan="1">Weights</td><td align="left" colspan="1" rowspan="1">imagenet</td></tr><tr><td align="left" colspan="1" rowspan="1">Pooling</td><td align="left" colspan="1" rowspan="1">Max</td></tr><tr><td align="left" colspan="1" rowspan="1">Optimizer</td><td align="left" colspan="1" rowspan="1">Adam</td></tr><tr><td align="left" colspan="1" rowspan="1">Learning rate</td><td align="left" colspan="1" rowspan="1">0.001</td></tr><tr><td align="left" colspan="1" rowspan="1">Loss function</td><td align="left" colspan="1" rowspan="1">sparse_categorical_crossentropy</td></tr><tr><td align="left" colspan="1" rowspan="1">Epochs</td><td align="left" colspan="1" rowspan="1">25</td></tr><tr><td align="left" colspan="1" rowspan="1">Batch size</td><td align="left" colspan="1" rowspan="1">32</td></tr><tr><td align="left" colspan="1" rowspan="1">Class mode</td><td align="left" colspan="1" rowspan="1">Binary</td></tr><tr><td align="left" colspan="1" rowspan="1">Monitor (Early stopping)</td><td align="left" colspan="1" rowspan="1">Accuracy</td></tr><tr><td align="left" colspan="1" rowspan="1">Min LR (Learning rate decay)</td><td align="left" colspan="1" rowspan="1">1e-6</td></tr><tr><td align="left" colspan="1" rowspan="1">Patience (Early stopping)</td><td align="left" colspan="1" rowspan="1">5</td></tr><tr><td align="left" colspan="1" rowspan="1">Patience (Reduce LR)</td><td align="left" colspan="1" rowspan="1">3</td></tr><tr><td align="left" colspan="1" rowspan="1">Additional dense layer units</td><td align="left" colspan="1" rowspan="1">1024 (ResNet50, EfficientNetB0, Xception, InceptionV3)</td></tr><tr><td align="left" colspan="1" rowspan="1">Classifier activation</td><td align="left" colspan="1" rowspan="1">Softmax</td></tr></tbody></table></table-wrap>
</p><p id="Par399999">
<fig id="Figc" position="float" orientation="portrait"><label>Algorithm 3</label><caption><p>Generation of 2D image representations from structured CSV data.</p></caption><graphic id="d33e1774" position="float" orientation="portrait" xlink:href="41598_2025_17647_Figc_HTML.jpg"/></fig>
</p></sec></sec></sec><sec id="Sec66565"><title>Experiment and results</title><p id="Par111">Our investigation aimed to assess the efficiency and robustness of the transfer learning approach using visual dynamic features to defend against ransomware attacks with limited datasets. This section consists of three components: experimental setup, evaluation metrics, and experimental results and discussion.</p><sec id="Sec18"><title>Experimental setup</title><p id="Par112">The experimental setup of this study incorporates sophisticated tools and techniques to analyze ransomware using dynamic analysis techniques. The analysis environment used a cuckoo sandbox<sup><xref ref-type="bibr" rid="CR46">46</xref></sup> to execute and monitor diverse ransomware behaviors securely. The evaluation environment leveraged Google Colab Pro<sup><xref ref-type="bibr" rid="CR62">62</xref></sup> with 51 GB of RAM, offering robust cloud computing to manage resource-intensive experiments and model training. Python version 3.10.12 was used to take advantage of the latest features, with essential libraries such as TensorFlow<sup><xref ref-type="bibr" rid="CR63">63</xref></sup> and Keras<sup><xref ref-type="bibr" rid="CR64">64</xref></sup> to implement and train deep learning models, as well as Pandas<sup><xref ref-type="bibr" rid="CR65">65</xref></sup> and NumPy<sup><xref ref-type="bibr" rid="CR66">66</xref></sup> for data management and numerical computations. Preprocessing involves scripting workflows in Python and using Bash commands to analyze the input/output operations of the JSON reports and store the resulting data in a CSV file. Additionally, color-mapping techniques were employed on structured CSV data via a Python script to visually represent the behavioral patterns of ransomware and benign applications.</p></sec><sec id="Sec19"><title>Dataset splitting and evaluation strategy</title><p id="Par113">The final dataset comprises 1,000 image samples derived from structured behavioral features, with an equal distribution of 500 ransomware and 500 benign samples. To ensure robust evaluation, we applied an 80/20 stratified split, resulting in 800 samples used for training and 200 for validation. The validation set was used to monitor the performance of the model during training, guide early stopping, support learning rate adjustment, and not for final testing. Although no separate test set was used owing to the small dataset size, we ensured performance generalization by-<list list-type="bullet"><list-item><p id="Par115">Stratified random sample splitting was used to preserve the class balance (50% ransomware and 50% benign) in both subsets.</p></list-item><list-item><p id="Par116">Applying early stopping and ReduceLROnPlateau callbacks based on validation metrics to avoid overfitting.</p></list-item><list-item><p id="Par117">Multiple runs were performed, and the results were compared across different models and data configurations (color vs. grayscale) for consistency.</p></list-item></list></p><p id="Par118">This setup allowed us to optimize training while mitigating overfitting risks, ensuring that the results reflected the true model performance under controlled conditions.</p><p id="Par119">To support the misclassification and interpretability analysis, we conducted additional evaluations of the trained model using the 200-sample validation set. These evaluations were used to generate confusion matrices and assess the generalization capabilities of the modelwhile maintaining controlled training-validation separation.</p></sec><sec id="Sec20"><title>Evaluation metrics</title><p id="Par120">To analyze and evaluate the results, we employed the precision, recall, F1 score, area under the curve (AUC), accuracy, and loss curve as performance metrics to assess the models for ransomware classification. However, accuracy was considered as the primary metric. The following equations (Eqs.&#160;(<xref rid="Equ1" ref-type="disp-formula">1</xref>)&#8211; (<xref rid="Equ4" ref-type="disp-formula">4</xref>)) describe the mathematical formulas for these metrics:</p><p id="Par121">Before proceeding with the equations, we define the acronyms of the confusion matrices used in the formulas:</p><p id="Par122">
<list list-type="bullet"><list-item><p id="Par123">TP: True positive (correctly identified ransomware samples).</p></list-item><list-item><p id="Par124">TN: true negative (correctly identified benign samples).</p></list-item><list-item><p id="Par125">FP: False positive (benign samples incorrectly labelled as ransomware).</p></list-item><list-item><p id="Par126">FN: False negative (ransomware samples incorrectly labelled benign).</p></list-item></list>
</p><p id="Par127">Accuracy: Accuracy is a metric that calculates the ratio of correct predictions (including both true positives and true negatives) to the total number of observations in a dataset.</p><p id="Par128">
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="d33e1859">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Accuracy = \frac{{TP + TN}}{{TP + TN + FP + FN}}$$\end{document}</tex-math><graphic position="anchor" orientation="portrait" xlink:href="41598_2025_17647_Article_Equ1.gif"/></alternatives></disp-formula>
</p><p id="Par129">Precision: This measures the proportion of correctly predicted positive observations to the total number of predicted positive observations.</p><p id="Par130">
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="d33e1870">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Pr ecision = \frac{{TP}}{{TP + FP}}$$\end{document}</tex-math><graphic position="anchor" orientation="portrait" xlink:href="41598_2025_17647_Article_Equ2.gif"/></alternatives></disp-formula>
</p><p id="Par131">Recall: This is also termed the sensitivity or true-positive rate, which measures the percentage of positive instances accurately classified and is calculated using the following formula:</p><p id="Par132">
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="d33e1881">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{Recall} = \frac{{TP}}{{TP + FN}}$$\end{document}</tex-math><graphic position="anchor" orientation="portrait" xlink:href="41598_2025_17647_Article_Equ3.gif"/></alternatives></disp-formula>
</p><p id="Par133">F1 score: F1 score combines precision and recall into a single metric, offering a balanced evaluation of false positives and false negatives.</p><p id="Par134">
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="d33e1893">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F1 - measure = 2 \times \frac{{\Pr ecision~ \times \text{Re} call}}{{\Pr ecision + \text{Re} call}}$$\end{document}</tex-math><graphic position="anchor" orientation="portrait" xlink:href="41598_2025_17647_Article_Equ4.gif"/></alternatives></disp-formula>
</p><p id="Par135">Area under the curve (AUC): The AUC metric evaluates the performance of a binary classifier by plotting a receiver operating characteristic (ROC) curve that shows a trade-off between true positives and false negatives at different thresholds. High AUC values indicate effective classification with minimal error.</p><p id="Par136">Loss: Loss measures the error between the predicted and actual labels during training, with lower values indicating better model performance.</p></sec><sec id="Sec21"><title>Results analysis</title><p id="Par137">We performed a series of experiments based on the following: (1) experiments with pretrained models and (2) experiments with nontrained models. (3) Performance comparison between grayscale and color image datasets. (4) Comparison of robustness and computational efficiency (5) Model interpretability and visual analysis (6) Misclassification analysis and (7) Comparison with relevant existing studies.</p><sec id="Sec22"><title>Experiment with pretrained models based on color and gray image datasets</title><p id="Par138">We trained six pretrained models with varying configurations, as listed in Table&#160;<xref rid="Tab4" ref-type="table">4</xref>. The performance metrics (accuracy, precision, recall, F1-score, AUC, and loss) for the ransomware classification results are summarized in Tables&#160;<xref rid="Tab5" ref-type="table">5</xref> and <xref rid="Tab6" ref-type="table">6</xref> for both color and grayscale samples. The primary evaluation metric was accuracy, which was tracked across all the experiments to measure the effectiveness of each model.</p><p id="Par139">ResNet50 emerged as the top-performing model, achieving 99.96% accuracy on the color dataset and 99.91% on the grayscale dataset. This 99.96% represents the highest training accuracy observed during repeated experiments (epoch 24). To further illustrate model behavior, a confusion matrix was generated from the validation set comprising 200 samples corresponding to the same training run. While training accuracy highlights the model&#8217;s optimal learning performance, the confusion matrix provides practical insight into its generalization and classification behavior on held-out data used during early stopping, not final testing. The consistently high precision, recall, F1-score, and AUC confirm ResNet50&#8217;s superiority.</p><p id="Par140">EfficientNetB0 followed closely with an accuracy of 99.91% on the color dataset and 99.70% on the grayscale dataset, thereby showing strong generalizability. Xception and InceptionV3 also demonstrate high effectiveness but with slightly lower scores, indicating their robustness in handling ransomware detection tasks. Conversely, VGG16 and VGG19 exhibited relatively low performance metrics, particularly when transitioning from the color to grayscale datasets.</p><p id="Par141">
<table-wrap id="Tab5" position="float" orientation="portrait"><label>Table 5</label><caption><p>Performance analysis results of the examined pretrained CNN models on the color image dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Accuracy</th><th align="left" colspan="1" rowspan="1">Precision</th><th align="left" colspan="1" rowspan="1">Recall</th><th align="left" colspan="1" rowspan="1">F1-score</th><th align="left" colspan="1" rowspan="1">AUC score</th><th align="left" colspan="1" rowspan="1">Loss</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">ResNet50</td><td align="left" colspan="1" rowspan="1">99.96</td><td align="left" colspan="1" rowspan="1">99.9591</td><td align="left" colspan="1" rowspan="1">99.96</td><td align="left" colspan="1" rowspan="1">99.959</td><td align="left" colspan="1" rowspan="1">99.8758</td><td align="left" colspan="1" rowspan="1">0.0026</td></tr><tr><td align="left" colspan="1" rowspan="1">EfficientNetB0</td><td align="left" colspan="1" rowspan="1">99.78</td><td align="left" colspan="1" rowspan="1">99.78</td><td align="left" colspan="1" rowspan="1">99.78</td><td align="left" colspan="1" rowspan="1">99.78</td><td align="left" colspan="1" rowspan="1">99.7725</td><td align="left" colspan="1" rowspan="1">0.0069</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG16</td><td align="left" colspan="1" rowspan="1">98.91</td><td align="left" colspan="1" rowspan="1">98.9093</td><td align="left" colspan="1" rowspan="1">98.91</td><td align="left" colspan="1" rowspan="1">98.9096</td><td align="left" colspan="1" rowspan="1">98.8759</td><td align="left" colspan="1" rowspan="1">0.0253</td></tr><tr><td align="left" colspan="1" rowspan="1">Xception</td><td align="left" colspan="1" rowspan="1">98.84</td><td align="left" colspan="1" rowspan="1">98.847</td><td align="left" colspan="1" rowspan="1">98.84</td><td align="left" colspan="1" rowspan="1">98.8418</td><td align="left" colspan="1" rowspan="1">98.8349</td><td align="left" colspan="1" rowspan="1">0.0579</td></tr><tr><td align="left" colspan="1" rowspan="1">InceptionV3</td><td align="left" colspan="1" rowspan="1">97.84</td><td align="left" colspan="1" rowspan="1">97.84</td><td align="left" colspan="1" rowspan="1">97.84</td><td align="left" colspan="1" rowspan="1">97.84</td><td align="left" colspan="1" rowspan="1">97.9207</td><td align="left" colspan="1" rowspan="1">0.0602</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG19</td><td align="left" colspan="1" rowspan="1">97.47</td><td align="left" colspan="1" rowspan="1">97.4701</td><td align="left" colspan="1" rowspan="1">97.47</td><td align="left" colspan="1" rowspan="1">97.4705</td><td align="left" colspan="1" rowspan="1">97.3692</td><td align="left" colspan="1" rowspan="1">0.0874</td></tr></tbody></table></table-wrap>
</p><p id="Par142">
<table-wrap id="Tab6" position="float" orientation="portrait"><label>Table 6</label><caption><p>Performance analysis results of the examined pretrained CNN models on a Gray image dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Accuracy</th><th align="left" colspan="1" rowspan="1">Precision</th><th align="left" colspan="1" rowspan="1">Recall</th><th align="left" colspan="1" rowspan="1">F1-score</th><th align="left" colspan="1" rowspan="1">AUC score</th><th align="left" colspan="1" rowspan="1">Loss</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">ResNet50</td><td align="left" colspan="1" rowspan="1">99.91</td><td align="left" colspan="1" rowspan="1">99.91</td><td align="left" colspan="1" rowspan="1">99.91</td><td align="left" colspan="1" rowspan="1">99.91</td><td align="left" colspan="1" rowspan="1">99.8492</td><td align="left" colspan="1" rowspan="1">0.0059</td></tr><tr><td align="left" colspan="1" rowspan="1">EfficientNetB0</td><td align="left" colspan="1" rowspan="1">99.70</td><td align="left" colspan="1" rowspan="1">99.6987</td><td align="left" colspan="1" rowspan="1">99.70</td><td align="left" colspan="1" rowspan="1">99.6993</td><td align="left" colspan="1" rowspan="1">99.61</td><td align="left" colspan="1" rowspan="1">0.0167</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG16</td><td align="left" colspan="1" rowspan="1">98.12</td><td align="left" colspan="1" rowspan="1">98.12</td><td align="left" colspan="1" rowspan="1">98.12</td><td align="left" colspan="1" rowspan="1">98.12</td><td align="left" colspan="1" rowspan="1">98.0213</td><td align="left" colspan="1" rowspan="1">0.0471</td></tr><tr><td align="left" colspan="1" rowspan="1">Xception</td><td align="left" colspan="1" rowspan="1">98.04</td><td align="left" colspan="1" rowspan="1">98.034</td><td align="left" colspan="1" rowspan="1">98.04</td><td align="left" colspan="1" rowspan="1">98.0375</td><td align="left" colspan="1" rowspan="1">98.9344</td><td align="left" colspan="1" rowspan="1">0.1261</td></tr><tr><td align="left" colspan="1" rowspan="1">InceptionV3</td><td align="left" colspan="1" rowspan="1">97.60</td><td align="left" colspan="1" rowspan="1">97.5986</td><td align="left" colspan="1" rowspan="1">97.60</td><td align="left" colspan="1" rowspan="1">97.5992</td><td align="left" colspan="1" rowspan="1">97.6078</td><td align="left" colspan="1" rowspan="1">0.1179</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG19</td><td align="left" colspan="1" rowspan="1">97.40</td><td align="left" colspan="1" rowspan="1">97.40</td><td align="left" colspan="1" rowspan="1">97.40</td><td align="left" colspan="1" rowspan="1">97.40</td><td align="left" colspan="1" rowspan="1">97.40</td><td align="left" colspan="1" rowspan="1">0.1194</td></tr></tbody></table></table-wrap>
</p><p id="Par143">Based on the results from both datasets the color dataset consistently outperformed grayscale, with all models achieving higher accuracy on color samples. Consequently, color images were prioritized for subsequent analysis. Figures&#160;<xref rid="Fig3" ref-type="fig">3</xref> and <xref rid="Fig4" ref-type="fig">4</xref> further underscore ResNet50&#8217;s superiority, showing its high accuracy trajectory and the lowest loss trend compared to other models. This advantage is attributed to its deeper architecture and advanced feature extraction capabilities, enabling it to capture complex behavioral patterns effectively. In contrast, the shallower VGG models exhibited limitations in handling feature-rich ransomware data.</p><p id="Par144">
<fig id="Fig3" position="float" orientation="portrait"><label>Fig. 3</label><caption><p>Accuracy trends for various pretrained learning models. The ResNet50 model demonstrates superior accuracy as the number of epochs increases.</p></caption><graphic id="d33e2187" position="float" orientation="portrait" xlink:href="41598_2025_17647_Fig3_HTML.jpg"/></fig>
</p><p id="Par145">
<fig id="Fig4" position="float" orientation="portrait"><label>Fig. 4</label><caption><p>The loss trends of pretrained models show that reveals that the ResNet50 model consistently demonstrates the lowest loss as the number of epochs increases.</p></caption><graphic id="d33e2197" position="float" orientation="portrait" xlink:href="41598_2025_17647_Fig4_HTML.jpg"/></fig>
</p></sec><sec id="Sec435354"><title>Experiment with non-pretrained models based on color and gray image datasets</title><p id="Par146">The performance of the non-pretrained models was evaluated on both color and gray image datasets, as shown in Tables&#160;<xref rid="Tab7" ref-type="table">7</xref> and <xref rid="Tab8" ref-type="table">8</xref>. The results revealed that the integrated CNN-GRU consistently outperformed other non-pretrained models across both datasets. For color images, CNN-GRU achieved the highest accuracy of 97.49% with a corresponding loss of 0.0579. Similarly, for gray images, an accuracy of 97.07% was achieved, with a loss of 0.0680. CNN-LSTM closely followed, demonstrating a slightly lower accuracy (96.94% for color and 96.80% for gray images) and greater loss than CNN-GRU. The standalone CNN model exhibited a performance similar to that of CNN-LSTM, achieving accuracies of 96.84% for color and 96.71% for gray images but with marginally higher loss values (0.0998 and 0.1045, respectively). The ANN consistently underperformed, showing the lowest accuracy (90.48% for color and 89.24% for gray images) and the highest loss values (0.2707 for color and 0.2853 for gray images).</p><p id="Par147">
<table-wrap id="Tab7" position="float" orientation="portrait"><label>Table 7</label><caption><p>Comparison of accuracy with that of the nontrained model for color images.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Accuracy</th><th align="left" colspan="1" rowspan="1">Precision</th><th align="left" colspan="1" rowspan="1">Recall</th><th align="left" colspan="1" rowspan="1">F1 Score</th><th align="left" colspan="1" rowspan="1">AUC</th><th align="left" colspan="1" rowspan="1">Loss</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">CNN-GRU</td><td align="left" colspan="1" rowspan="1">97.49</td><td align="left" colspan="1" rowspan="1">97.4964</td><td align="left" colspan="1" rowspan="1">97.49</td><td align="left" colspan="1" rowspan="1">97.4919</td><td align="left" colspan="1" rowspan="1">97.4676</td><td align="left" colspan="1" rowspan="1">0.0579</td></tr><tr><td align="left" colspan="1" rowspan="1">CNN-LSTM</td><td align="left" colspan="1" rowspan="1">96.94</td><td align="left" colspan="1" rowspan="1">96.9464</td><td align="left" colspan="1" rowspan="1">96.94</td><td align="left" colspan="1" rowspan="1">96.9419</td><td align="left" colspan="1" rowspan="1">96.8978</td><td align="left" colspan="1" rowspan="1">0.0963</td></tr><tr><td align="left" colspan="1" rowspan="1">CNN</td><td align="left" colspan="1" rowspan="1">96.84</td><td align="left" colspan="1" rowspan="1">96.799</td><td align="left" colspan="1" rowspan="1">96.84</td><td align="left" colspan="1" rowspan="1">96.7838</td><td align="left" colspan="1" rowspan="1">96.8165</td><td align="left" colspan="1" rowspan="1">0.0998</td></tr><tr><td align="left" colspan="1" rowspan="1">ANN</td><td align="left" colspan="1" rowspan="1">90.48</td><td align="left" colspan="1" rowspan="1">90.48</td><td align="left" colspan="1" rowspan="1">90.48</td><td align="left" colspan="1" rowspan="1">90.48</td><td align="left" colspan="1" rowspan="1">92.67</td><td align="left" colspan="1" rowspan="1">0.2707</td></tr></tbody></table></table-wrap>
</p><p id="Par148">
<table-wrap id="Tab8" position="float" orientation="portrait"><label>Table 8</label><caption><p>Comparison of accuracy with that of the nontrained model for Gray images.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Accuracy</th><th align="left" colspan="1" rowspan="1">Precision</th><th align="left" colspan="1" rowspan="1">Recall</th><th align="left" colspan="1" rowspan="1">F1 Score</th><th align="left" colspan="1" rowspan="1">AUC</th><th align="left" colspan="1" rowspan="1">Loss</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">CNN-GRU</td><td align="left" colspan="1" rowspan="1">97.07</td><td align="left" colspan="1" rowspan="1">97.0685</td><td align="left" colspan="1" rowspan="1">97.07</td><td align="left" colspan="1" rowspan="1">97.0692</td><td align="left" colspan="1" rowspan="1">97.1085</td><td align="left" colspan="1" rowspan="1">0.0680</td></tr><tr><td align="left" colspan="1" rowspan="1">CNN-LSTM</td><td align="left" colspan="1" rowspan="1">96.80</td><td align="left" colspan="1" rowspan="1">96.80</td><td align="left" colspan="1" rowspan="1">96.80</td><td align="left" colspan="1" rowspan="1">96.80</td><td align="left" colspan="1" rowspan="1">96.6958</td><td align="left" colspan="1" rowspan="1">0.0807</td></tr><tr><td align="left" colspan="1" rowspan="1">CNN</td><td align="left" colspan="1" rowspan="1">96.71</td><td align="left" colspan="1" rowspan="1">96.7107</td><td align="left" colspan="1" rowspan="1">96.71</td><td align="left" colspan="1" rowspan="1">96.7103</td><td align="left" colspan="1" rowspan="1">96.7168</td><td align="left" colspan="1" rowspan="1">0.1045</td></tr><tr><td align="left" colspan="1" rowspan="1">ANN</td><td align="left" colspan="1" rowspan="1">89.24</td><td align="left" colspan="1" rowspan="1">89.24</td><td align="left" colspan="1" rowspan="1">89.24</td><td align="left" colspan="1" rowspan="1">89.24</td><td align="left" colspan="1" rowspan="1">89.1613.</td><td align="left" colspan="1" rowspan="1">0.2853</td></tr></tbody></table></table-wrap>
</p><p id="Par149">The associated graphs in Fig.&#160;<xref rid="Fig5" ref-type="fig">5</xref> further clarify the analysis of the performance of these models across various image types. The graph comprises two plots that evaluate the performance of various non-pretrained models over 15 epochs in terms of accuracy and loss. ResNet50 was included as a reference pretrained model, and it displayed superior and stable performance across all epochs, quickly converging to near-perfect accuracy and minimal loss. This demonstrates the advantages of transfer learning. Among the non-pretrained models, the CNN-GRU achieved the highest accuracy and lowest final loss, highlighting its strength in capturing spatial and sequential features. These results highlight the superiority of the pretrained and hybrid models for image-based ransomware classification.</p><p id="Par150">The ANN demonstrated a limited learning capacity with lower accuracy and inconsistent loss trends. ANNs lack the ability to capture spatial and temporal dependencies, which likely accounts for their poor performances. CNN-LSTM demonstrated a similar structure to CNN-GRU but with less favorable results, possibly because of the relatively heavier computational burden of LSTM for this task.</p><p id="Par151">
<fig id="Fig5" position="float" orientation="portrait"><label>Fig. 5</label><caption><p>Comparative performance of non-pretrained models and ResNet50 over 15 epochs.</p></caption><graphic id="d33e2410" position="float" orientation="portrait" xlink:href="41598_2025_17647_Fig5_HTML.jpg"/></fig>
</p></sec><sec id="Sec24"><title>Performance comparison between color and grayscale datasets</title><p id="Par152">The comparative results in Table&#160;<xref rid="Tab9" ref-type="table">9</xref>; Fig.&#160;<xref rid="Fig6" ref-type="fig">6</xref> reveal that all the models (pretrained and nontrained) performed slightly better on the color datasets than on the grayscale datasets in terms of accuracy and loss drop.</p><p id="Par153">However, the performance differences were negligible for most models.<list list-type="bullet"><list-item><p id="Par155">ResNet50 achieved the highest accuracy for both datasets, with only a minor difference of 0.05%, and maintained the lowest loss gap (0.0033%), demonstrating its superior performance across both datasets and among all the models. EfficientNetB0 also demonstrated strong results, with a slight decrease in accuracy (0.12%) and a modest increase in loss (0.0114) for gray images.</p></list-item><list-item><p id="Par156">Among the non-pretrained models, the CNN-GRU outperforms the CNN-LSTM and CNN, with a relatively small accuracy gap (0.42%) and minimal loss difference (0.0101), whereas the ANN showed the largest performance decline, with a 1.24% decrease in accuracy and a 0.0146 increase in loss for gray images.</p></list-item><list-item><p id="Par157">Notably, CNN-LSTM is the only model with a marginally lower loss for gray images, indicating its unique adaptability to grayscale inputs.</p></list-item><list-item><p id="Par158">Overall, the pretrained models outperformed the nontrained models, with color datasets consistently yielding better results, as illustrated in Figs.&#160;<xref rid="Fig6" ref-type="fig">6</xref> and <xref rid="Fig7" ref-type="fig">7</xref>.</p></list-item></list></p><p id="Par159">Table&#160;<xref rid="Tab9" ref-type="table">9</xref> suggests that although color datasets provide a slight edge in performance, grayscale datasets remain highly effective for ransomware detection, making them a viable option when color data are unavailable or when computational efficiency is prioritized.</p><p id="Par160">
<table-wrap id="Tab9" position="float" orientation="portrait"><label>Table 9</label><caption><p>Accuracy and loss or error rate comparisons between color and Gray image datasets.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Accuracy (Color image)</th><th align="left" colspan="1" rowspan="1">Accuracy (Gray image)</th><th align="left" colspan="1" rowspan="1">Difference (%)</th><th align="left" colspan="1" rowspan="1">Loss (Color dataset)</th><th align="left" colspan="1" rowspan="1">Loss (Grayscale dataset)</th><th align="left" colspan="1" rowspan="1">Difference (%)</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">ResNet50</td><td align="left" colspan="1" rowspan="1">99.96</td><td align="left" colspan="1" rowspan="1">99.91</td><td align="left" colspan="1" rowspan="1">0.05</td><td align="left" colspan="1" rowspan="1">0.0026</td><td align="left" colspan="1" rowspan="1">0.0059</td><td align="left" colspan="1" rowspan="1">0.0033</td></tr><tr><td align="left" colspan="1" rowspan="1">EfficientNetB0</td><td align="left" colspan="1" rowspan="1">99.78</td><td align="left" colspan="1" rowspan="1">99.70</td><td align="left" colspan="1" rowspan="1">0.08</td><td align="left" colspan="1" rowspan="1">0.0069</td><td align="left" colspan="1" rowspan="1">0.0167</td><td align="left" colspan="1" rowspan="1">0.0098</td></tr><tr><td align="left" colspan="1" rowspan="1">Xception</td><td align="left" colspan="1" rowspan="1">98.91</td><td align="left" colspan="1" rowspan="1">98.12</td><td align="left" colspan="1" rowspan="1">0.79</td><td align="left" colspan="1" rowspan="1">0.0253</td><td align="left" colspan="1" rowspan="1">0.0471</td><td align="left" colspan="1" rowspan="1">0.0218</td></tr><tr><td align="left" colspan="1" rowspan="1">InceptionV3</td><td align="left" colspan="1" rowspan="1">98.84</td><td align="left" colspan="1" rowspan="1">98.04</td><td align="left" colspan="1" rowspan="1">0.80</td><td align="left" colspan="1" rowspan="1">0.0579</td><td align="left" colspan="1" rowspan="1">0.1261</td><td align="left" colspan="1" rowspan="1">0.0682</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG16</td><td align="left" colspan="1" rowspan="1">97.84</td><td align="left" colspan="1" rowspan="1">97.60</td><td align="left" colspan="1" rowspan="1">0.24</td><td align="left" colspan="1" rowspan="1">0.0602</td><td align="left" colspan="1" rowspan="1">0.1179</td><td align="left" colspan="1" rowspan="1">0.0577</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG19</td><td align="left" colspan="1" rowspan="1">97.47</td><td align="left" colspan="1" rowspan="1">97.40</td><td align="left" colspan="1" rowspan="1">0.07</td><td align="left" colspan="1" rowspan="1">0.0874</td><td align="left" colspan="1" rowspan="1">0.1194</td><td align="left" colspan="1" rowspan="1">0.0320</td></tr><tr><td align="left" colspan="1" rowspan="1">CNN-GRU</td><td align="left" colspan="1" rowspan="1">97.49</td><td align="left" colspan="1" rowspan="1">97.07</td><td align="left" colspan="1" rowspan="1">0.42</td><td align="left" colspan="1" rowspan="1">0.0579</td><td align="left" colspan="1" rowspan="1">0.0680</td><td align="left" colspan="1" rowspan="1">0.0101</td></tr><tr><td align="left" colspan="1" rowspan="1">CNN-LSTM</td><td align="left" colspan="1" rowspan="1">96.94</td><td align="left" colspan="1" rowspan="1">96.80</td><td align="left" colspan="1" rowspan="1">0.14</td><td align="left" colspan="1" rowspan="1">0.0963</td><td align="left" colspan="1" rowspan="1">0.0807</td><td align="left" colspan="1" rowspan="1">&#8722;0.0156</td></tr><tr><td align="left" colspan="1" rowspan="1">CNN</td><td align="left" colspan="1" rowspan="1">96.84</td><td align="left" colspan="1" rowspan="1">96.71</td><td align="left" colspan="1" rowspan="1">0.13</td><td align="left" colspan="1" rowspan="1">0.0998</td><td align="left" colspan="1" rowspan="1">0.1045</td><td align="left" colspan="1" rowspan="1">0.0047</td></tr><tr><td align="left" colspan="1" rowspan="1">ANN</td><td align="left" colspan="1" rowspan="1">90.48</td><td align="left" colspan="1" rowspan="1">89.24</td><td align="left" colspan="1" rowspan="1">1.24</td><td align="left" colspan="1" rowspan="1">0.2707</td><td align="left" colspan="1" rowspan="1">0.2853</td><td align="left" colspan="1" rowspan="1">0.0146</td></tr></tbody></table></table-wrap>
</p><p id="Par1510">
<fig id="Fig6" position="float" orientation="portrait"><label>Fig. 6</label><caption><p>Graph of the accuracy against the epoch across all models (pretrained and non-pretrained). The consistently lowest-performing model is ANN, whereas RsNet50 consistently ranks highest.</p></caption><graphic id="d33e2639" position="float" orientation="portrait" xlink:href="41598_2025_17647_Fig6_HTML.jpg"/></fig>
</p><p id="Par161">
<fig id="Fig7" position="float" orientation="portrait"><label>Fig. 7</label><caption><p>Graph of the loss against the epoch across all models (pretrained and non-pretrained). The consistently lowest loss performing model is ResNet50, whereas ANN shows the highest loss.</p></caption><graphic id="d33e2649" position="float" orientation="portrait" xlink:href="41598_2025_17647_Fig7_HTML.jpg"/></fig>
</p><p id="Par163">Color datasets inherently provide more information through pixel variations, which may help models distinguish between ransomware and benign behaviors. However, the negligible drop in performance across most models when grayscale datasets are used suggests that the essential features for ransomware detection can still be effectively captured with fewer color-specific details.</p></sec><sec id="Sec3424354"><title>Robustness and computational efficiency</title><p id="Par164">To assess both detection performance and computational demands, we compared six pretrained CNN models (ResNet50, EfficientNetB0, InceptionV3, Xception, VGG16, and VGG19) with and without fine-tuning. The results, summarized in Table&#160;<xref rid="Tab10" ref-type="table">10</xref>, show that fine-tuning generally improved classification accuracy across most models while also reducing training time per sample.</p><p id="Par165">Notably, ResNet50 achieved the highest accuracy improvement from 99.91 to 99.96%, with a reduced training time of 0.440&#160;s/sample (down from 0.571). EfficientNetB0 also demonstrated strong performance with lower training cost. By contrast, models such as VGG16 and VGG19 required more time and showed limited gains, indicating their inefficiency for small datasets.</p><p id="Par166">
<table-wrap id="Tab10" position="float" orientation="portrait"><label>Table 10</label><caption><p>Training time efficiency for pretrained models.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2" colspan="1">Model</th><th align="left" colspan="2" rowspan="1">Without fine-tuning</th><th align="left" colspan="2" rowspan="1">With fine-tuning (see Table <xref rid="Tab4" ref-type="table">4</xref>)</th></tr><tr><th align="left" colspan="1" rowspan="1">Accuracy (%)</th><th align="left" colspan="1" rowspan="1">Avg. training time per sample (s)</th><th align="left" colspan="1" rowspan="1">Accuracy (%)</th><th align="left" colspan="1" rowspan="1">Avg. training time per sample (s)</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">ResNet50</td><td align="left" colspan="1" rowspan="1">99.91</td><td align="left" colspan="1" rowspan="1">0.571</td><td align="left" colspan="1" rowspan="1">99.96</td><td align="left" colspan="1" rowspan="1">0.440</td></tr><tr><td align="left" colspan="1" rowspan="1">EfficientNetB0</td><td align="left" colspan="1" rowspan="1">99.26</td><td align="left" colspan="1" rowspan="1">0.208</td><td align="left" colspan="1" rowspan="1">99.78</td><td align="left" colspan="1" rowspan="1">0.193</td></tr><tr><td align="left" colspan="1" rowspan="1">InceptionV3</td><td align="left" colspan="1" rowspan="1">98.77</td><td align="left" colspan="1" rowspan="1">0.380</td><td align="left" colspan="1" rowspan="1">97.84</td><td align="left" colspan="1" rowspan="1">0.098</td></tr><tr><td align="left" colspan="1" rowspan="1">Xception</td><td align="left" colspan="1" rowspan="1">99.01</td><td align="left" colspan="1" rowspan="1">0.549</td><td align="left" colspan="1" rowspan="1">98.90</td><td align="left" colspan="1" rowspan="1">0.262</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG16</td><td align="left" colspan="1" rowspan="1">98.20</td><td align="left" colspan="1" rowspan="1">0.932</td><td align="left" colspan="1" rowspan="1">97.26</td><td align="left" colspan="1" rowspan="1">0.860</td></tr><tr><td align="left" colspan="1" rowspan="1">VGG19</td><td align="left" colspan="1" rowspan="1">97.47</td><td align="left" colspan="1" rowspan="1">1.460</td><td align="left" colspan="1" rowspan="1">98.00</td><td align="left" colspan="1" rowspan="1">1.444</td></tr></tbody></table></table-wrap>
</p><p id="Par167">These results highlight that transfer learning with fine-tuning offers a balanced trade-off, achieving a high detection accuracy while maintaining computational efficiency. Among all the tested models, ResNet50 provided the best combination of speed and robustness for small ransomware datasets.</p></sec><sec id="Sec23254"><title>Model interpretability and visual analysis</title><p id="Par168">To better understand the decision-making behavior of our deep learning models, we conducted a visual interpretability analysis using t-distributed stochastic neighbor embedding (t-SNE) and saliency maps. These methods help reveal how well the model separates ransomware and benign samples in the learned feature space and which regions of the input images most influence classification decisions. By employing these techniques, we aimed to provide deeper insights into the internal representations learned by pretrained CNNs and evaluate the consistency and reliability of the classification outcomes.</p></sec></sec><sec id="Sec32545"><title>t-SNE feature visualization</title><p id="Par169">To enhance the transparency of the model behavior, t-distributed stochastic neighbor embedding (t-SNE) was applied to the final dense layer outputs of the ResNet50 model. As shown in Fig.&#160;<xref rid="Fig8" ref-type="fig">8</xref>, the ransomware and benign samples are from two distinct clusters, with orange points indicating benign samples and green points representing ransomware.</p><p id="Par170">Although some overlap was observed near the cluster boundary, the overall separation was clear, supporting the model&#8217;s high classification accuracy of 99.96%. Rare misclassifications (one false negative) likely occurred in the overlapping region, where a ransomware sample displayed benign-like behavior.</p><p id="Par171">This clustering pattern highlights the ability of the model to map behaviorally distinct classes into well-defined regions in the latent space, thereby reducing the risk of misclassification. Therefore, the rare misclassification observed is explainable and expected in boundary scenarios, further affirming the robustness and reliability of the proposed detection pipeline.</p><p id="Par172">
<fig id="Fig8" position="float" orientation="portrait"><label>Fig. 8</label><caption><p>t-SNE feature visualization of used ransomware dataset. Orange points represent benign samples and green points represent ransomware. The two classes formed distinct clusters with limited overlap, illustrating strong feature separability and explaining the near-perfect classification accuracy of the model.</p></caption><graphic id="d33e2789" position="float" orientation="portrait" xlink:href="41598_2025_17647_Fig8_HTML.jpg"/></fig>
</p></sec><sec id="Sec28"><title>Saliency map interpretation</title><p id="Par173">To gain insight into the internal focus of the model during prediction, we applied saliency mapping using gradient-based backpropagation to the representative samples of both benign (B) and ransomware (R). This technique highlights the most influential pixel regions in the input images, allowing us to interpret which behavioral patterns the model attends to when classifying a sample as ransomware or benign.</p><p id="Par174">As shown in Fig.&#160;<xref rid="Fig9" ref-type="fig">9</xref>, the saliency maps reveal distinct patterns of attention for the benign and ransomware inputs. For benign samples (left), the focus of the model is limited to a small, dispersed set of pixels, suggesting sparse activation. In contrast, the ransomware (right) saliency map shows intense, localized attention in specific regions, indicating that the model has learned to associate certain behavioral patterns (e.g., registry access and file encryption events) in the presence of the ransomware.</p><p id="Par175">These visualizations demonstrate that the model does not respond to random noise but instead focuses on meaningful regions in the behavioral image. This further reinforces the reliability of the model and its high predictive accuracy of 99.96%.</p><p id="Par176">
<fig id="Fig9" position="float" orientation="portrait"><label>Fig. 9</label><caption><p>Saliency maps of representative benign (left) and ransomware (right) images. The highlighted regions indicate the pixels with the highest impact on the prediction of the model. The model focuses on structured behavior-encoded areas and confirms the class-specific pattern learning.</p></caption><graphic id="d33e2810" position="float" orientation="portrait" xlink:href="41598_2025_17647_Fig9_HTML.jpg"/></fig>
</p><sec id="Sec29"><title>Misclassification analysis</title><p id="Par177">To further evaluate the classification performance of the best-performing model, ResNet50, we analyzed its misclassification behavior using a confusion matrix derived from the model weights saved at epoch 24, which corresponded to the highest training accuracy of 99.96%, and evaluated it on the 200-sample validation set (98.50%).</p><p id="Par178">As shown in Fig.&#160;<xref rid="Fig10" ref-type="fig">10</xref>, the confusion matrix reveals three misclassifications: two false positives (FP) and one false negative (FN), resulting in a validation accuracy of 98.50%. This indicates that two benign samples were incorrectly predicted as ransomware and one ransomware sample was misclassified as benign. These raw counts show the performance of the model, correctly classifying 197 of the 200 validation samples. This matrix reflects the prediction performance of the model at convergence and is generated using the saved model weights after training.</p><p id="Par179">
<fig id="Fig10" position="float" orientation="portrait"><label>Fig. 10</label><caption><p>Confusion matrix for the best performing model ResNet50, evaluated on the 200-sample validation set (98.50% accuracy).</p></caption><graphic id="d33e2829" position="float" orientation="portrait" xlink:href="41598_2025_17647_Fig10_HTML.jpg"/></fig>
</p><p id="Par180">Despite these minor errors, the results confirm the high classification accuracy of the model, with near-perfect identification of both benign and ransomware samples. These findings reinforce the effectiveness of the transfer-learning-based model, which maintained a consistently low misclassification rate. These rare errors are likely attributable to borderline case either benign software exhibiting anomaly like behavior or ransomware instances that mimic benign traits to evade detection. This interpretation is supported by the supplementary visualizations such as t-SNE and saliency map. The t-SNE plot revealed distinct clustering between benign and ransomware samples, with minimal overlap, indicating strong feature separability. Furthermore, saliency map analysis demonstrates that the model consistently focuses on behaviorally relevant regions, thereby reinforcing the reliability of its decision-making process.</p><p id="Par181">Overall, the rarity and interpretability of the misclassification patterns confirm the ResNet50-based model&#8217;s robustness and generalization capability under transfer learning, even with unseen validation data.</p></sec><sec id="Sec30"><title>Comparison of our proposed technique with the existing relevant methods</title><p id="Par182">This section compares the performance of the proposed ransomware detection framework with those of several recent approaches, as summarized in Table&#160;<xref rid="Tab11" ref-type="table">11</xref>. It is important to note that the studies listed in Table&#160;<xref rid="Tab11" ref-type="table">11</xref> utilized different datasets, feature engineering strategies (e.g., static vs. dynamic), and varying malware types or versions that limited the fairness of direct comparison. While our method is based on a custom dynamic behavioral dataset, most existing approaches rely on static binaries, memory dumps, or hybrid combinations. Thus, the performance results presented in Table&#160;<xref rid="Tab11" ref-type="table">11</xref> are not intended for direct one-to-one comparison but rather to provide contextual benchmarking across a range of related methodologies. Against this benchmark, our proposed method achieved an accuracy of 99.96% on our balanced and threat-informed dataset, thereby demonstrating its effectiveness. To the best of our knowledge, no previous study has utilized this dynamic-to-image transformation technique for ransomware detection, making our approach a novel contribution to the literature.</p><p id="Par183">
<table-wrap id="Tab11" position="float" orientation="portrait"><label>Table 11</label><caption><p>Comparison of our method with existing recent relevant works in the literature.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Paper</th><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">Analysis technique</th><th align="left" colspan="1" rowspan="1">Feature type</th><th align="left" colspan="1" rowspan="1">Threat type</th><th align="left" colspan="1" rowspan="1">Accuracy (%)</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>
</td><td align="left" colspan="1" rowspan="1">VGG416</td><td align="left" colspan="1" rowspan="1">Static</td><td align="left" colspan="1" rowspan="1">Image</td><td align="left" colspan="1" rowspan="1">Malware</td><td align="left" colspan="1" rowspan="1">91.41</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>
</td><td align="left" colspan="1" rowspan="1">VGG416</td><td align="left" colspan="1" rowspan="1">Hybrid</td><td align="left" colspan="1" rowspan="1">Image</td><td align="left" colspan="1" rowspan="1">Malware</td><td align="left" colspan="1" rowspan="1">94.70</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>
</td><td align="left" colspan="1" rowspan="1">Xception ColSeq</td><td align="left" colspan="1" rowspan="1">Static</td><td align="left" colspan="1" rowspan="1">Image</td><td align="left" colspan="1" rowspan="1">Malware</td><td align="left" colspan="1" rowspan="1">98.20</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>
</td><td align="left" colspan="1" rowspan="1">ResNet50</td><td align="left" colspan="1" rowspan="1">Static</td><td align="left" colspan="1" rowspan="1">Image</td><td align="left" colspan="1" rowspan="1">Malware</td><td align="left" colspan="1" rowspan="1">99.50</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>
</td><td align="left" colspan="1" rowspan="1">ResNet50</td><td align="left" colspan="1" rowspan="1">Static</td><td align="left" colspan="1" rowspan="1">Image</td><td align="left" colspan="1" rowspan="1">Malware</td><td align="left" colspan="1" rowspan="1">98.61</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>
</td><td align="left" colspan="1" rowspan="1">ResNet50</td><td align="left" colspan="1" rowspan="1">Static</td><td align="left" colspan="1" rowspan="1">Image</td><td align="left" colspan="1" rowspan="1">Malware</td><td align="left" colspan="1" rowspan="1">98.62</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR67">67</xref></sup>
</td><td align="left" colspan="1" rowspan="1">Xception CNN</td><td align="left" colspan="1" rowspan="1">Static</td><td align="left" colspan="1" rowspan="1">Image</td><td align="left" colspan="1" rowspan="1">Malware</td><td align="left" colspan="1" rowspan="1">99.20</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>
</td><td align="left" colspan="1" rowspan="1">Logistic Regression (RLR)</td><td align="left" colspan="1" rowspan="1">Dynamic</td><td align="left" colspan="1" rowspan="1">CSV</td><td align="left" colspan="1" rowspan="1">Ransomware</td><td align="left" colspan="1" rowspan="1">96.34</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>
</td><td align="left" colspan="1" rowspan="1">CNN</td><td align="left" colspan="1" rowspan="1">Dynamic</td><td align="left" colspan="1" rowspan="1">CSV</td><td align="left" colspan="1" rowspan="1">Ransomware</td><td align="left" colspan="1" rowspan="1">95.90</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>
</td><td align="left" colspan="1" rowspan="1">Random forest</td><td align="left" colspan="1" rowspan="1">Dynamic</td><td align="left" colspan="1" rowspan="1">CSV</td><td align="left" colspan="1" rowspan="1">Ransomware</td><td align="left" colspan="1" rowspan="1">97.28</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>
</td><td align="left" colspan="1" rowspan="1">CNN, LSTM, MLP</td><td align="left" colspan="1" rowspan="1">Static&#8201;+&#8201;Dynamic</td><td align="left" colspan="1" rowspan="1">Image&#8201;+&#8201;CSV</td><td align="left" colspan="1" rowspan="1">Ransomware</td><td align="left" colspan="1" rowspan="1">98.75</td></tr><tr><td align="left" colspan="1" rowspan="1">
<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>
</td><td align="left" colspan="1" rowspan="1">2-layered CNN</td><td align="left" colspan="1" rowspan="1">Dynamic</td><td align="left" colspan="1" rowspan="1">CSV</td><td align="left" colspan="1" rowspan="1">Ransomware</td><td align="left" colspan="1" rowspan="1">98.20</td></tr><tr><td align="left" colspan="1" rowspan="1"> Our proposed method</td><td align="left" colspan="1" rowspan="1"> ResNet50</td><td align="left" colspan="1" rowspan="1"> Dynamic</td><td align="left" colspan="1" rowspan="1"> Image (from CSV)</td><td align="left" colspan="1" rowspan="1"> Ransomware</td><td align="left" colspan="1" rowspan="1"> 99.96</td></tr></tbody></table></table-wrap>
</p><p id="Par184">Several studies have reported competitive results using static analysis. For example<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR67">67</xref></sup>, achieved accuracies of 99.50% and 99.20%, respectively, using image-based static features. However, static analysis methods are often more vulnerable to the obfuscation and packing techniques employed by modern ransomware. In contrast, our method incorporates dynamic behavioral data, enabling a more robust detection of evasive threats.</p><p id="Par185">Further comparisons with dynamic and hybrid models using structured input formats (e.g., CSV) also support the strength of our approach. A technique proposed by<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR23">23</xref>,<xref ref-type="bibr" rid="CR24">24</xref></sup>, and<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> achieved accuracy scores ranging from 95.90 to 98.20%. Although promising, these results remained below the performance achieved by our framework.</p><p id="Par186">Overall, these findings underscore the advantage of converting structured behavioral data into images, allowing pretrained CNNs such as ResNet50 to exploit spatial patterns and significantly enhance detection performance, particularly in small dataset scenarios.</p></sec></sec></sec><sec id="Sec31"><title>Discussion</title><p id="Par187">The proposed approach presented in this study showed exceptional performance with 99.96% accuracy, despite the use of a limited dataset. This remarkable outcome was owing to the combination of domain-guided feature engineering, behavior-to-image transformation, and transfer learning (TL) with pretrained CNN models.</p><p id="Par188">Our data collection used an isolated dynamic analysis environment to capture the real-time ransomware behavior. This ensures that the dataset reflects genuine malicious activity rather than artificial samples. We conducted domain-based filtering to identify the most impactful features with highest discriminatory power between benign and ransomware behaviors. Supplementary Table <xref rid="MOESM1" ref-type="media">S1</xref> in the Appendix provides concise descriptions of these features and their impacts on detection. Although our dataset was small, this domain filtering reduced the background noise, and each sample was filtered to maximize the representational value and enhance the dataset quality. This ensures that the model learns from relevant patterns for accurate classification, rather than from an extensive but noisy dataset.</p><p id="Par189">We evaluated several CNN models using transfer learning, including ResNet50, InceptionV3, EfficientNetB0, Xception, and VGG variants. These models are well suited for small datasets because of their ability to generalize from prior training on large-scale datasets. By fine-tuning them on our domain-specific dataset, we achieved better classification performance, despite the limited sample size. Among these, ResNet50 consistently demonstrated superior accuracy and generalization capabilities. This makes it the optimal choice for our task of detecting ransomware.</p><p id="Par190">Additional architectures such as MobileNet and DenseNet121 were also tested. MobileNet demonstrated faster training but suffered from reduced feature extraction capacity owing to its shallow depth, which limited the classification accuracy. Capturing nuanced behavioral patterns from ransomware-related image data requires richer feature hierarchies, and deeper models such as ResNet50 or InceptionV3 are more effective. Because our goal was to detect subtle distinctions between benign and malicious behaviors, we prioritized deeper models that offer more robust and reliable feature representations. Therefore, MobileNet is not included in the final model selection. We also experimented with DenseNet121, which is known for its feature reuse and compact design. Despite its theoretical advantages, DenseNet121 exhibited a significantly higher training time in our experiments compared to the models listed in Table&#160;<xref rid="Tab3" ref-type="table">3</xref>. Given our focus on balancing the classification performance with computational efficiency, we excluded it from the final evaluation.</p><p id="Par191">We also complemented the accuracy with other metrics, such as precision, recall, and F1 score, to ensure that our approach was evaluated holistically. The results confirmed consistent model behavior across classes with near-perfect classification metrics. A comprehensive analysis of the various figures and tables in this study clearly justifies the superiority of the proposed model in ransomware classification.</p><p id="Par192">Model interpretability was assessed using visual tools such as t-SNE and saliency maps. The interpretability analysis confirms that our model not only achieves high classification accuracy (99.96%) but also provides valuable insight into its internal decision-making. The t-SNE visualization illustrates distinct clustering of ransomware and benign samples in the learned feature space, whereas saliency maps highlight class-relevant regions in the input images, confirming that the model focuses on meaningful behavioral patterns. A single false negative observed in the confusion matrix was explainable as a borderline behavioral case, further supporting the model&#8217;s reliability and generalization. Although SHAP is a widely adopted tool for model explainability, it is primarily suited to structured data or natural images where pixel locations correspond to semantically meaningful features. For instance, Deep SHAP applied by<sup><xref ref-type="bibr" rid="CR68">68</xref></sup> to the MNIST dataset works effectively because each pixel directly represents interpretable visual elements, such as strokes of handwritten digits. In contrast, our approach encodes abstract behavioral attributes into an image form, where pixel positions are determined by algorithmic mapping rather than a natural visual structure. Consequently, applying SHAP to our image-based data would produce attribution maps with limited human interpretability. Therefore, to support meaningful analysis, we adopted t-SNE and saliency maps, which are better suited for visualizing class separability and model attention in CNNs trained on behavior-to-image transformations.</p><p id="Par193">The proposed approach also offers a significant methodological contribution. Although this study employs standard CNN-based transfer learning models, the core novelty lies in how these models are adapted within a behavior-centric ransomware detection pipeline. By transforming dynamic behavioral features extracted from sandbox logs into structured image representations, we enable these models, originally designed for natural images, to effectively learn the complex runtime patterns associated with modern ransomware. This adaptation, combined with domain-guided feature engineering, our novel behavior-to-image transformation, and visual interpretability techniques such as t-SNE and saliency maps, represents a significant advancement in applying transfer learning to small-data, behavior-aware cybersecurity tasks. This advancement is particularly important for enhancing ransomware detection in real-world settings, where limited behavioral data and rapidly evolving threat variants present ongoing challenges for conventional detection approaches.</p><p id="Par194">The model also demonstrated robustness across image types, with only a minor decrease in accuracy when grayscale inputs were used. This result also suggests that the models can generalize well across both types of input data.</p><p id="Par195">While the current study demonstrates several strengths, it is not without limitations. The limited size of the dataset, although balanced and meticulously curated, may not fully capture the diverse range of ransomware behaviors observed in real-world scenarios. Additionally, the dependence of the detection pipeline on a specific sandbox (e.g., Cuckoo sandbox) environment may limit its adaptability to broader deployment contexts. To enhance the resilience and practical applicability of the model, it is essential to address these limitations through ongoing dataset expansion, incorporation of evolving threats, and integration with diverse dynamic analysis platforms.</p><p id="Par196">In summary, our study presents an interpretable, high-performance, and computationally efficient solution for modern ransomware detection, offering clear advantages over traditional static analysis methods.</p></sec><sec id="Sec3534535"><title>Conclusion and future work</title><p id="Par197">This study introduced a novel approach for ransomware detection that leverages a three-phase workflow: dataset creation, visualization, and detection. By carefully curating the domain-based dataset, we ensured that only the most relevant and impactful ransomware behaviors were included even within a small dataset. This dataset was then transformed into visual representations, allowing the application of TL with pretrained deep learning models. The experimental results demonstrated remarkable accuracy, with ResNet50 achieving 99.96% accuracy for color datasets and 99.91% accuracy for grayscale datasets, thereby demonstrating the power of this approach in leveraging small but highly relevant datasets for ransomware detection. The use of dynamic image-based features significantly enhances ransomware detection by capturing the complex behavioral patterns that static analysis methods often miss. TL further enhances the detection accuracy with small datasets by using pretrained models to reduce the training time and computational costs. In addition to accuracy, we emphasized model transparency through interpretability tools such as t-SNE and saliency maps. These visualizations confirmed that the model effectively distinguished ransomware from benign behavior by attending to meaningful regions of the input images rather than learning spurious patterns. The combined analysis of the performance and misclassification reinforces the robustness and reliability of the proposed pipeline. By capturing real-time behavior and employing sophisticated image-based classifiers, our method not only outperforms previous methods but also sets a new benchmark for scalable and accurate ransomware detection. This broadens the scope for future research in this area.</p><p id="Par198">Future research should focus on addressing the limitations identified in this study. We intend to enhance this dataset by incorporating a diverse array of ransomware families and benign variants. To further improve robustness, we plan to explore the utilization of more advanced sandboxes, such as CAPE, ANYRUN, and JOE, for dynamic analysis. Additionally, although SHAP is not applicable to our current image-based workflow, future research may consider SHAP-based interpretability for structured feature branches to enhance explainability and decision accountability in conjunction with other advanced machine learning models or hybrid detection systems.</p></sec><sec id="Sec33" sec-type="supplementary-material"><title>Supplementary Information</title><p>Below is the link to the electronic supplementary material.</p><p>
<supplementary-material content-type="local-data" id="MOESM1" position="float" orientation="portrait"><media xlink:href="41598_2025_17647_MOESM1_ESM.docx" position="float" orientation="portrait"><caption><p>Supplementary Material 1</p></caption></media></supplementary-material>
</p></sec></body><back><fn-group><fn><p><bold>Publisher&#8217;s note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><notes notes-type="author-contribution"><title>Author contributions</title><p>Jannatul Ferdous: Conceptualization, Methodology, Python Scripting, Investigation of experimental results, Writing &#8211; original draft, Visualization. Rafiqul Islam: Validation, Writing &#8211; review &amp; editing, Supervision. Arash Mahboubi: Validation, Writing &#8211; review &amp; editing, Supervision. Md Zahidul Islam: Validation, Writing &#8211; review &amp; editing, Supervision.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>This work was supported by the Charles Sturt University Tri-Faculty Open Access Publishing Fund (2025).</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>The code used for data preprocessing, including feature extraction, JSON-to-CSV parsing, and data visualization (CSV-to-image conversion), is available on GitHub: [Image-based Ransomware Detection with Transfer Learning] ([https://github.com/myresearchhub/Image-based-Ransomware-Detection-with-Transfer-Learning](https:/github.com/myresearchhub/Image-based-Ransomware-Detection-with-Transfer-Learning)).The data used in this study were obtained from various sources, with links provided in the &#8220;Phase 1: Dataset Creation Phase&#8221; section of the manuscript and the README.md file in the same repository.The dataset will be made available upon approval by the Charles Sturt University (CSU). Interested researchers may contact Jannatul Ferdous at [jferdous@csu.edu.au](mailto: jferdous@csu.edu.au) for data access.</p></notes><notes><title>Declarations</title><notes id="FPar3" notes-type="COI-statement"><title>Competing interests</title><p id="Par199">The authors declare no competing interests.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>Z</given-names></name><name name-style="western"><surname>Kaplan</surname><given-names>Z</given-names></name><name name-style="western"><surname>Yan</surname><given-names>Q</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>N</given-names></name></person-group><article-title>Security and privacy in the emerging cyber-physical world: A survey</article-title><source>IEEE Commun. Surv. Tutorials</source><year>2021</year><volume>23</volume><issue>3</issue><fpage>1879</fpage><lpage>1919</lpage><pub-id pub-id-type="doi">10.1109/COMST.2021.3081450</pub-id></element-citation><mixed-citation id="mc-CR1" publication-type="journal">Yu, Z., Kaplan, Z., Yan, Q. &amp; Zhang, N. Security and privacy in the emerging cyber-physical world: A survey. <italic toggle="yes">IEEE Commun. Surv. Tutorials</italic>. <bold>23</bold> (3), 1879&#8211;1919. 10.1109/COMST.2021.3081450 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other">Jean, B. L. &amp; <italic toggle="yes">Tour Howden&#8217;s 2024 Cyber Insurance Report- Risk, Resilience and Relevance</italic>. (Accessed 05 November 2024). <ext-link ext-link-type="uri" xlink:href="https://www.howdengroupholdings.com/reports/2024-cyber-report">https://www.howdengroupholdings.com/reports/2024-cyber-report</ext-link>&#160;(2024).</mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">SOPHOS.<italic toggle="yes"> Ransomware Payments Increase 500% In the Last Year, Finds Sophos State of Ransomware Report</italic>. (Accessed 12 November 2024). <ext-link ext-link-type="uri" xlink:href="https://www.sophos.com/en-us/press/press-releases/2024/04/ransomware-payments-increase-500-last-year-finds-sophos-state">https://www.sophos.com/en-us/press/press-releases/2024/04/ransomware-payments-increase-500-last-year-finds-sophos-state</ext-link>&#160;(2024).</mixed-citation></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ferdous</surname><given-names>J</given-names></name><name name-style="western"><surname>Islam</surname><given-names>R</given-names></name><name name-style="western"><surname>Mahboubi</surname><given-names>A</given-names></name><name name-style="western"><surname>Islam</surname><given-names>MZ</given-names></name></person-group><article-title>A Review of State-of-the-Art Malware Attack Trends and Defense Mechanisms</article-title><source>IEEE Access</source><year>2023</year><volume>11</volume><fpage>121118</fpage><lpage>121141</lpage><pub-id pub-id-type="doi">10.1109/access.2023.3328351</pub-id></element-citation><mixed-citation id="mc-CR4" publication-type="journal">Ferdous, J., Islam, R., Mahboubi, A. &amp; Islam, M. Z. A Review of State-of-the-Art Malware Attack Trends and Defense Mechanisms. <italic toggle="yes">IEEE Access</italic><bold>11</bold>, 121118&#8211;121141. 10.1109/access.2023.3328351 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="other">Sophos Maturing criminal marketplaces present new challenges to defenders, <italic toggle="yes">Sophos 2023 Threat Report.</italic>&#160;(Accessed 21 September 2024).&#160;<ext-link ext-link-type="uri" xlink:href="https://www.scribd.com/document/628559505/Sophos-Threat-Report-2023">https://www.scribd.com/document/628559505/Sophos-Threat-Report-2023</ext-link>&#160;(2023).</mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">TREND Phobos Emerges as a Formidable Threat in Q1 2024, LockBit Stays in the Top Spot. (Accessed 12 October 2024). <ext-link ext-link-type="uri" xlink:href="https://www.trendmicro.com/vinfo/au/security/news/ransomware-by-the-numbers/phobos-emerges-as-a-formidable-threat-in-q1-2024-lockbit-stays-in-the-top-spot">https://www.trendmicro.com/vinfo/au/security/news/ransomware-by-the-numbers/phobos-emerges-as-a-formidable-threat-in-q1-2024-lockbit-stays-in-the-top-spot</ext-link>&#160;(2024).</mixed-citation></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ferdous</surname><given-names>J</given-names></name><name name-style="western"><surname>Islam</surname><given-names>R</given-names></name><name name-style="western"><surname>Mahboubi</surname><given-names>A</given-names></name><name name-style="western"><surname>Islam</surname><given-names>MZ</given-names></name></person-group><article-title>AI-based Ransomware Detection: A Comprehensive Review</article-title><source>IEEE Access</source><year>2024</year><volume>12</volume><fpage>136666</fpage><lpage>136695</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2024.3461965</pub-id></element-citation><mixed-citation id="mc-CR7" publication-type="journal">Ferdous, J., Islam, R., Mahboubi, A. &amp; Islam, M. Z. AI-based Ransomware Detection: A Comprehensive Review. <italic toggle="yes">IEEE Access</italic><bold>12</bold>, 136666&#8211;136695. 10.1109/ACCESS.2024.3461965 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Daniele Sgandurra, E. C. L., Mu&#241;oz-Gonz&#225;lez, L. &amp; Mohsen, R. Automated dynamic analysis of ransomware: benefits, limitations and use for detection, https://arXiv.org/abs/1609.032020. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/pdf/1609.03020">https://arxiv.org/pdf/1609.03020</ext-link> &#160;(2016). </mixed-citation></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Singh</surname><given-names>J</given-names></name><name name-style="western"><surname>Sharma</surname><given-names>K</given-names></name><name name-style="western"><surname>Wazid</surname><given-names>M</given-names></name><name name-style="western"><surname>Das</surname><given-names>AK</given-names></name></person-group><article-title>Spline interpolation-envisioned neural network-based ransomware detection scheme</article-title><source>Comput. Electr. Eng.</source><year>2023</year><volume>106</volume><fpage>108601</fpage><pub-id pub-id-type="doi">10.1016/j.compeleceng.2023.108601</pub-id></element-citation><mixed-citation id="mc-CR9" publication-type="journal">Singh, J., Sharma, K., Wazid, M. &amp; Das, A. K. Spline interpolation-envisioned neural network-based ransomware detection scheme. <italic toggle="yes">Comput. Electr. Eng.</italic><bold>106</bold>, 108601. 10.1016/j.compeleceng.2023.108601 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zahoora</surname><given-names>U</given-names></name><etal/></person-group><article-title>Ransomware detection using deep learning based unsupervised feature extraction and a cost sensitive Pareto ensemble classifier</article-title><source>Sci. Rep.</source><year>2022</year><volume>12</volume><issue>1</issue><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1038/s41598-022-19443-7</pub-id><pub-id pub-id-type="pmid">36123364</pub-id><pub-id pub-id-type="pmcid">PMC9485118</pub-id></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Zahoora, U. et al. Ransomware detection using deep learning based unsupervised feature extraction and a cost sensitive Pareto ensemble classifier. <italic toggle="yes">Sci. Rep.</italic><bold>12</bold> (1), 1&#8211;15. 10.1038/s41598-022-19443-7 (2022).<pub-id pub-id-type="pmid">36123364</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-022-19443-7</pub-id><pub-id pub-id-type="pmcid">PMC9485118</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fernando</surname><given-names>DW</given-names></name><name name-style="western"><surname>Komninos</surname><given-names>N</given-names></name><name name-style="western"><surname>Chen</surname><given-names>T</given-names></name></person-group><article-title>A study on the evolution of ransomware detection using machine learning and deep learning techniques</article-title><source>IoT</source><year>2020</year><volume>1</volume><issue>2</issue><fpage>551</fpage><lpage>604</lpage><pub-id pub-id-type="doi">10.3390/iot1020030</pub-id></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Fernando, D. W., Komninos, N. &amp; Chen, T. A study on the evolution of ransomware detection using machine learning and deep learning techniques. <italic toggle="yes">IoT</italic><bold>1</bold> (2), 551&#8211;604. 10.3390/iot1020030 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Moreira</surname><given-names>CC</given-names></name><name name-style="western"><surname>Moreira</surname><given-names>DC</given-names></name><name name-style="western"><surname>de Sales</surname><given-names>C</given-names></name></person-group><article-title>Improving ransomware detection based on portable executable header using Xception convolutional neural network</article-title><source>Comput. Secur.</source><year>2023</year><volume>130</volume><fpage>103265</fpage><pub-id pub-id-type="doi">10.1016/j.cose.2023.103265</pub-id></element-citation><mixed-citation id="mc-CR12" publication-type="journal">Moreira, C. C., Moreira, D. C. &amp; de Sales, C. Improving ransomware detection based on portable executable header using Xception convolutional neural network. <italic toggle="yes">Comput. Secur.</italic><bold>130</bold>, 103265. 10.1016/j.cose.2023.103265 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vasan</surname><given-names>D</given-names></name><etal/></person-group><article-title>IMCFN: Image-based malware classification using fine-tuned convolutional neural network architecture</article-title><source>Comput. Networks</source><year>2020</year><volume>171</volume><fpage>107138</fpage><pub-id pub-id-type="doi">10.1016/j.comnet.2020.107138</pub-id></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Vasan, D. et al. IMCFN: Image-based malware classification using fine-tuned convolutional neural network architecture. <italic toggle="yes">Comput. Networks</italic>. <bold>171</bold>, 107138. 10.1016/j.comnet.2020.107138 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bensaoud</surname><given-names>A</given-names></name><name name-style="western"><surname>Kalita</surname><given-names>J</given-names></name></person-group><article-title>CNN-LSTM and transfer learning models for malware classification based on opcodes and API calls</article-title><source>Knowledge-Based Syst.</source><year>2024</year><volume>290</volume><fpage>111543</fpage><pub-id pub-id-type="doi">10.1016/j.knosys.2024.111543</pub-id></element-citation><mixed-citation id="mc-CR14" publication-type="journal">Bensaoud, A. &amp; Kalita, J. CNN-LSTM and transfer learning models for malware classification based on opcodes and API calls. <italic toggle="yes">Knowledge-Based Syst.</italic><bold>290</bold>, 111543. 10.1016/j.knosys.2024.111543 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kumar</surname><given-names>S</given-names></name><name name-style="western"><surname>Panda</surname><given-names>K</given-names></name></person-group><article-title>Stacking deep image features using fine-tuned Convolution neural network models for real-world malware detection and classification</article-title><source>Appl. Soft Comput.</source><year>2023</year><volume>146</volume><fpage>110676</fpage><pub-id pub-id-type="doi">10.1016/j.asoc.2023.110676</pub-id></element-citation><mixed-citation id="mc-CR15" publication-type="journal">Kumar, S. &amp; Panda, K. Stacking deep image features using fine-tuned Convolution neural network models for real-world malware detection and classification. <italic toggle="yes">Appl. Soft Comput.</italic><bold>146</bold>, 110676. 10.1016/j.asoc.2023.110676 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Almomani</surname><given-names>I</given-names></name><name name-style="western"><surname>Alkhayer</surname><given-names>A</given-names></name><name name-style="western"><surname>El-Shafai</surname><given-names>W</given-names></name></person-group><article-title>E2E-RDS: efficient End-to-End ransomware detection system based on Static-Based ML and Vision-Based DL approaches</article-title><source>Sensors</source><year>2023</year><volume>23</volume><issue>9</issue><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.3390/s23094467</pub-id><pub-id pub-id-type="pmcid">PMC10181608</pub-id><pub-id pub-id-type="pmid">37177671</pub-id></element-citation><mixed-citation id="mc-CR16" publication-type="journal">Almomani, I., Alkhayer, A. &amp; El-Shafai, W. E2E-RDS: efficient End-to-End ransomware detection system based on Static-Based ML and Vision-Based DL approaches. <italic toggle="yes">Sensors</italic><bold>23</bold> (9), 1&#8211;27. 10.3390/s23094467 (2023).<pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/s23094467</pub-id><pub-id pub-id-type="pmcid">PMC10181608</pub-id><pub-id pub-id-type="pmid">37177671</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">Ahmed, M., Afreen, N., Ahmed, M., Sameer, M., Ahamed, J. (2022). An inception approach for malware classification using machine learning and transfer learning. <italic toggle="yes">Int. J. Intell. Netw.</italic><bold>4</bold> 11&#8211;18, 10.1016/j.ijin.2022.11.005</mixed-citation></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chaganti</surname><given-names>R</given-names></name><name name-style="western"><surname>Ravi</surname><given-names>V</given-names></name><name name-style="western"><surname>Pham</surname><given-names>TD</given-names></name></person-group><article-title>Image-based malware representation approach with EfficientNet convolutional neural networks for effective malware classification</article-title><source>J. Inf. Secur. Appl.</source><year>2022</year><pub-id pub-id-type="doi">10.1016/j.jisa.2022.103306</pub-id></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Chaganti, R., Ravi, V. &amp; Pham, T. D. Image-based malware representation approach with EfficientNet convolutional neural networks for effective malware classification. <italic toggle="yes">J. Inf. Secur. Appl.</italic>10.1016/j.jisa.2022.103306 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">Escudero Garc&#237;a, D., DeCastro-Garc&#237;a, N. &amp; Mu&#241;oz Casta&#241;eda, A. L. An effectiveness analysis of transfer learning for the concept drift problem in malware detection. <italic toggle="yes">Expert Syst. Appl.</italic>,&#160;<bold>212</bold> 118724. 10.1016/j.eswa.2022.118724 (2022).</mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Aghakhani, H. et al. When malware is packin&#8217; heat; limits of machine learning classifiers based on static analysis features.&#160;<italic toggle="yes">27th Annu. Netw. Distrib. Syst. Secur. Symp. (NDSS</italic>10.14722/ndss.2020.24310 (2020).</mixed-citation></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>X</given-names></name><name name-style="western"><surname>Ma</surname><given-names>L</given-names></name><name name-style="western"><surname>Yang</surname><given-names>W</given-names></name><name name-style="western"><surname>Zhong</surname><given-names>Y</given-names></name></person-group><article-title>A method for windows malware detection based on deep learning</article-title><source>J. Signal. Process. Syst.</source><year>2021</year><volume>93</volume><fpage>2</fpage><lpage>3</lpage><pub-id pub-id-type="doi">10.1007/s11265-020-01588-1</pub-id></element-citation><mixed-citation id="mc-CR21" publication-type="journal">Huang, X., Ma, L., Yang, W. &amp; Zhong, Y. A method for windows malware detection based on deep learning. <italic toggle="yes">J. Signal. Process. Syst.</italic><bold>93</bold>, 2&#8211;3. 10.1007/s11265-020-01588-1 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sharma</surname><given-names>S</given-names></name><name name-style="western"><surname>Krishna</surname><given-names>CR</given-names></name><name name-style="western"><surname>Kumar</surname><given-names>R</given-names></name></person-group><article-title>RansomDroid: forensic analysis and detection of android ransomware using unsupervised machine learning technique</article-title><source>Forensic Sci. Int. Digit. Investig</source><year>2021</year><volume>37</volume><fpage>301168</fpage><pub-id pub-id-type="doi">10.1016/j.fsidi.2021.301168</pub-id></element-citation><mixed-citation id="mc-CR22" publication-type="journal">Sharma, S., Krishna, C. R. &amp; Kumar, R. RansomDroid: forensic analysis and detection of android ransomware using unsupervised machine learning technique. <italic toggle="yes">Forensic Sci. Int. Digit. Investig</italic>. <bold>37</bold>, 301168. 10.1016/j.fsidi.2021.301168 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Qin, B., Wang, Y. &amp; Ma, C. API Call based ransomware dynamic detection approach using TextCNN, <italic toggle="yes">Proc. 2020 Int. Conf. Big Data, Artif. Intell. Internet Things Eng.&#160;</italic> 162&#8211;166. 10.1109/ICBAIE49996.2020.00041 (ICBAIE, 2020).</mixed-citation></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hwang</surname><given-names>J</given-names></name><name name-style="western"><surname>Kim</surname><given-names>J</given-names></name><name name-style="western"><surname>Lee</surname><given-names>S</given-names></name><name name-style="western"><surname>Kim</surname><given-names>K</given-names></name></person-group><article-title>Two-Stage ransomware detection using dynamic analysis and machine learning techniques</article-title><source>Wirel. Pers. Commun.</source><year>2020</year><volume>112</volume><issue>4</issue><fpage>2597</fpage><lpage>2609</lpage><pub-id pub-id-type="doi">10.1007/s11277-020-07166-9</pub-id></element-citation><mixed-citation id="mc-CR24" publication-type="journal">Hwang, J., Kim, J., Lee, S. &amp; Kim, K. Two-Stage ransomware detection using dynamic analysis and machine learning techniques. <italic toggle="yes">Wirel. Pers. Commun.</italic><bold>112</bold> (4), 2597&#8211;2609. 10.1007/s11277-020-07166-9 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Manavi</surname><given-names>F</given-names></name><name name-style="western"><surname>Hamzeh</surname><given-names>A</given-names></name></person-group><article-title>A novel approach for ransomware detection based on PE header using graph embedding</article-title><source>J. Comput. Virol. Hacking Tech.</source><year>2022</year><volume>18</volume><issue>4</issue><fpage>285</fpage><lpage>296</lpage><pub-id pub-id-type="doi">10.1007/s11416-021-00414-x</pub-id></element-citation><mixed-citation id="mc-CR25" publication-type="journal">Manavi, F. &amp; Hamzeh, A. A novel approach for ransomware detection based on PE header using graph embedding. <italic toggle="yes">J. Comput. Virol. Hacking Tech.</italic><bold>18</bold> (4), 285&#8211;296. 10.1007/s11416-021-00414-x (2022).</mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Manavi</surname><given-names>F</given-names></name><name name-style="western"><surname>Hamzeh</surname><given-names>A</given-names></name></person-group><article-title>Ransomware detection based on PE header using convolutional neural networks&#8727;&#8727;</article-title><source>ISeCure</source><year>2022</year><volume>14</volume><issue>2</issue><fpage>181</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.22042/isecure.2021.262846.595</pub-id></element-citation><mixed-citation id="mc-CR26" publication-type="journal">Manavi, F. &amp; Hamzeh, A. Ransomware detection based on PE header using convolutional neural networks&#8727;&#8727;. <italic toggle="yes">ISeCure</italic><bold>14</bold> (2), 181&#8211;192. 10.22042/isecure.2021.262846.595 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Deng</surname><given-names>XZ</given-names></name><name name-style="western"><surname>Cen</surname><given-names>MC</given-names></name><name name-style="western"><surname>Jiang</surname><given-names>M</given-names></name><name name-style="western"><surname>Lu</surname><given-names>M</given-names></name></person-group><article-title>Ransomware early detection using deep reinforcement learning on portable executable header</article-title><source>Cluster Comput.</source><year>2023</year><volume>27</volume><issue>2</issue><fpage>1867</fpage><lpage>1881</lpage><pub-id pub-id-type="doi">10.1007/s10586-023-04043-5</pub-id></element-citation><mixed-citation id="mc-CR27" publication-type="journal">Deng, X. Z., Cen, M. C., Jiang, M. &amp; Lu, M. Ransomware early detection using deep reinforcement learning on portable executable header. <italic toggle="yes">Cluster Comput.</italic><bold>27</bold> (2), 1867&#8211;1881. 10.1007/s10586-023-04043-5 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gulmez</surname><given-names>S</given-names></name><name name-style="western"><surname>Gorgulu Kakisim</surname><given-names>A</given-names></name><name name-style="western"><surname>Sogukpinar</surname><given-names>I</given-names></name></person-group><article-title>XRan: explainable deep learning-based ransomware detection using dynamic analysis</article-title><source>Comput. Secur.</source><year>2024</year><volume>139</volume><fpage>103703</fpage><pub-id pub-id-type="doi">10.1016/j.cose.2024.103703</pub-id></element-citation><mixed-citation id="mc-CR28" publication-type="journal">Gulmez, S., Gorgulu Kakisim, A. &amp; Sogukpinar, I. XRan: explainable deep learning-based ransomware detection using dynamic analysis. <italic toggle="yes">Comput. Secur.</italic><bold>139</bold>, 103703. 10.1016/j.cose.2024.103703 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Karbab</surname><given-names>EMB</given-names></name><name name-style="western"><surname>Debbabi</surname><given-names>M</given-names></name><name name-style="western"><surname>Derhab</surname><given-names>A</given-names></name></person-group><article-title>SwiftR: Cross-platform ransomware fingerprinting using hierarchical neural networks on hybrid features</article-title><source>Expert Syst. Appl.</source><year>2023</year><volume>225</volume><fpage>120017</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2023.120017</pub-id></element-citation><mixed-citation id="mc-CR29" publication-type="journal">Karbab, E. M. B., Debbabi, M. &amp; Derhab, A. SwiftR: Cross-platform ransomware fingerprinting using hierarchical neural networks on hybrid features. <italic toggle="yes">Expert Syst. Appl.</italic><bold>225</bold>, 120017. 10.1016/j.eswa.2023.120017 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ni</surname><given-names>S</given-names></name><name name-style="western"><surname>Qian</surname><given-names>Q</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>R</given-names></name></person-group><article-title>Malware identification using visualization images and deep learning</article-title><source>Comput. Secur.</source><year>2018</year><volume>77</volume><fpage>871</fpage><lpage>885</lpage><pub-id pub-id-type="doi">10.1016/j.cose.2018.04.005</pub-id></element-citation><mixed-citation id="mc-CR30" publication-type="journal">Ni, S., Qian, Q. &amp; Zhang, R. Malware identification using visualization images and deep learning. <italic toggle="yes">Comput. Secur.</italic><bold>77</bold>, 871&#8211;885. 10.1016/j.cose.2018.04.005 (2018).</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vasan</surname><given-names>D</given-names></name><name name-style="western"><surname>Alazab</surname><given-names>M</given-names></name><name name-style="western"><surname>Wassan</surname><given-names>S</given-names></name><name name-style="western"><surname>Safaei</surname><given-names>B</given-names></name><name name-style="western"><surname>Zheng</surname><given-names>Q</given-names></name></person-group><article-title>Image-Based malware classification using ensemble of CNN architectures (IMCEC)</article-title><source>Comput. Secur.</source><year>2020</year><volume>92</volume><fpage>101748</fpage><pub-id pub-id-type="doi">10.1016/j.cose.2020.101748</pub-id></element-citation><mixed-citation id="mc-CR31" publication-type="journal">Vasan, D., Alazab, M., Wassan, S., Safaei, B. &amp; Zheng, Q. Image-Based malware classification using ensemble of CNN architectures (IMCEC). <italic toggle="yes">Comput. Secur.</italic><bold>92</bold>, 101748. 10.1016/j.cose.2020.101748 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="other">Rezende, E., Ruppert, G., Carvalho, T., Ramos, F. &amp; De Geus, P. Malicious software classification using transfer learning of ResNet-50 deep neural network.&#160;<italic toggle="yes">Proc. 16th IEEE Int. Conf. Mach. Learn. Appl. </italic><bold>2017</bold> 1011&#8211;1014. 10.1109/ICMLA.2017.00-19 (ICMLA,&#160;2017). </mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Abuse.ch, MalwareBazaar database.&#160;(Accessed 02 June 2024).&#160;<ext-link ext-link-type="uri" xlink:href="https://bazaar.abuse.ch/browse/">https://bazaar.abuse.ch/browse/</ext-link> (2024).</mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">VirusShare VirusShare.com - Because Sharing is Caring. (Accessed 07 June 2024). <ext-link ext-link-type="uri" xlink:href="https://virusshare.com/">https://virusshare.com/</ext-link>&#160;(2025).</mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="other"><italic toggle="yes">SnapFiles Popular freeware categories</italic>. (Accessed 06 July 2024). <ext-link ext-link-type="uri" xlink:href="https://www.snapfiles.com/freeware/">https://www.snapfiles.com/freeware/</ext-link>&#160;(1997).</mixed-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="other">Portableapps, <italic toggle="yes">Portable App Directory. </italic> (Accessed 10 July 2024) <ext-link ext-link-type="uri" xlink:href="https://portableapps.com/apps">https://portableapps.com/apps</ext-link>&#160;(2024).</mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Iosifache,&#160;<italic toggle="yes">DikeDataset.&#160;</italic> (Accessed 16 July 2024). <ext-link ext-link-type="uri" xlink:href="https://github.com/iosifache/DikeDataset/tree/main/files/benign">https://github.com/iosifache/DikeDataset/tree/main/files/benign</ext-link>&#160;(2023).</mixed-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="other">Ang, M. J. A. <italic toggle="yes">Narrowed Sights, Bigger Payoffs: Ransomware in</italic><italic toggle="yes">2019.</italic>&#160;(Accessed 01 October 2024).&#160;<ext-link ext-link-type="uri" xlink:href="https://www.trendmicro.com/vinfo/au/security/news/cybercrime-and-digital-threats/narrowed-sights-bigger-payoffs-ransomware-in-2019">https://www.trendmicro.com/vinfo/au/security/news/cybercrime-and-digital-threats/narrowed-sights-bigger-payoffs-ransomware-in-2019</ext-link>&#160;(<italic toggle="yes">TREND</italic>, 2019).</mixed-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Networks, P. A. <italic toggle="yes">Unit 42 Ransomware threat report</italic>. (Accessed 10 September 2024). <ext-link ext-link-type="uri" xlink:href="https://start.paloaltonetworks.com/unit-42-ransomware-threat-report.html">https://start.paloaltonetworks.com/unit-42-ransomware-threat-report.html</ext-link>&#160;(2020).</mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">Zscaler, <italic toggle="yes">Zscaler:&#160;2022 ThreatLabz State of Ransomware Report</italic>. (Accessed 12 October 2024).&#160;<ext-link ext-link-type="uri" xlink:href="https://www.zscaler.com/resources/industry-reports/2022-threatlabz-ransomware-report.pdf">https://www.zscaler.com/resources/industry-reports/2022-threatlabz-ransomware-report.pdf</ext-link>&#160;(2022).</mixed-citation></ref><ref id="CR41"><label>41.</label><citation-alternatives><element-citation id="ec-CR41" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Symantec</surname><given-names>B</given-names></name></person-group><article-title>The ransomware threat landscape</article-title><source>Ransomware Threat Landsc.</source><year>2023</year><pub-id pub-id-type="doi">10.2307/j.ctv1f8xc7v</pub-id></element-citation><mixed-citation id="mc-CR41" publication-type="journal">Symantec, B. The ransomware threat landscape. <italic toggle="yes">Ransomware Threat Landsc.</italic>10.2307/j.ctv1f8xc7v (2023).</mixed-citation></citation-alternatives></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="other"><italic toggle="yes">VirusTotal VirusTotal ransomware activity report</italic>. <ext-link ext-link-type="uri" xlink:href="https://www.virustotal.com/gui/home/upload">https://www.virustotal.com/gui/home/upload</ext-link> (Accessed 02 Jun 2024). </mixed-citation></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="other">SentinelOne, &#8220;Ragnar Locker Ransomware: In-Depth Analysis, Detection, Mitigation, and Removal,&#8221; 2024. https://www.sentinelone.com/anthology/ragnar-locker/#:~:text=Summary of Ragnar Locker Ransomware&amp;text=Ragnar Locker targets corporate networks,non-release of stolen data. (accessed Aug. 28, 2024).[44] K. Baker, &#8220;Ransomware Examples: 16 Recent Ransomware Attacks,&#8221; (2024).</mixed-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="other">Baker, K. <italic toggle="yes">Ransomware examples: 16 recent ransomware attacks</italic>. (Accessed 29 August 2024). <ext-link ext-link-type="uri" xlink:href="https://www.crowdstrike.com/cybersecurity-101/ransomware/ransomware-examples/">https://www.crowdstrike.com/cybersecurity-101/ransomware/ransomware-examples/</ext-link>&#160;(2024).</mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="other">Research, T. M. &amp; Ransomware-spotlight-Clop (Accessed 29 August 2024). <ext-link ext-link-type="uri" xlink:href="https://www.trendmicro.com/vinfo/au/security/news/ransomware-spotlight/ransomware-spotlight-clop">https://www.trendmicro.com/vinfo/au/security/news/ransomware-spotlight/ransomware-spotlight-clop</ext-link>&#160;(2022).</mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="other"><italic toggle="yes">Cuckoo Cuckoo Sandbox- automated malware analysis</italic>. <ext-link ext-link-type="uri" xlink:href="https://cuckoosandbox.org/download">https://cuckoosandbox.org/download</ext-link></mixed-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="other"><italic toggle="yes">Myresearchhub Image-based-Ransomware-Detection-with-Transfer-Learning</italic>. (Accessed 02 November 2024).&#160;<ext-link ext-link-type="uri" xlink:href="https://github.com/myresearchhub/Image-based-Ransomware-Detection-with-Transfer-Learning">https://github.com/myresearchhub/Image-based-Ransomware-Detection-with-Transfer-Learning</ext-link> (2024).</mixed-citation></ref><ref id="CR48"><label>48.</label><citation-alternatives><element-citation id="ec-CR48" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Algarni</surname><given-names>MD</given-names></name><etal/></person-group><article-title>An Efficient Convolutional Neural Network with Transfer Learning for Malware Classification</article-title><source>Wirel. Commun. Mob. Comput.</source><year>2022</year><pub-id pub-id-type="doi">10.1155/2022/4841741</pub-id></element-citation><mixed-citation id="mc-CR48" publication-type="journal">Algarni, M. D. et al. An Efficient Convolutional Neural Network with Transfer Learning for Malware Classification. <italic toggle="yes">Wirel. Commun. Mob. Comput.</italic>10.1155/2022/4841741 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="other">He, K. <italic toggle="yes">Deep Residual Learning for Image Recognition.</italic>&#160;(2015).</mixed-citation></ref><ref id="CR50"><label>50.</label><citation-alternatives><element-citation id="ec-CR50" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tan</surname><given-names>M</given-names></name><name name-style="western"><surname>Le</surname><given-names>QV</given-names></name></person-group><article-title>EfficientNetV2: Smaller Models and Faster Training</article-title><source>Proc. Mach. Learn. Res.</source><year>2021</year><volume>139</volume><fpage>10096</fpage><lpage>10106</lpage></element-citation><mixed-citation id="mc-CR50" publication-type="journal">Tan, M. &amp; Le, Q. V. EfficientNetV2: Smaller Models and Faster Training. <italic toggle="yes">Proc. Mach. Learn. Res.</italic><bold>139</bold>, 10096&#8211;10106 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="other">Lo, W. W., Yang, X. &amp; Wang, Y. An xception convolutional neural network for malware classification with transfer learning.&#160;<italic toggle="yes">10th IFIP Int. Conf. New Technol. Mobil. Secur. NTMS 2019 Proc. Work.</italic> 1&#8211;5. 10.1109/NTMS.2019.8763852 (2019).</mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="other">Simonyan, K. &amp; Zisserman, A. Very deep convolutional networks for large-scale image recognition.&#160;<italic toggle="yes">3rd Int. Conf. Learn. Represent. ICLR 2015 Conf. Track Proc.</italic> 1&#8211;14, (2015).</mixed-citation></ref><ref id="CR53"><label>53.</label><mixed-citation publication-type="other">Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z. Rethinking the inception architecture for computer vision. <italic toggle="yes">Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit.</italic><bold>2016</bold>&#160;2818&#8211;2826. (2016).</mixed-citation></ref><ref id="CR54"><label>54.</label><citation-alternatives><element-citation id="ec-CR54" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rani</surname><given-names>KS</given-names></name><etal/></person-group><article-title>Implementation of inception V3-Based CNN classification for malware detection</article-title><source>2024 Int. Conf. Recent. Adv. Electr. Electron. Ubiquitous Commun. Comput. Intell. RAEEUCCI 2024</source><year>2024</year><pub-id pub-id-type="doi">10.1109/RAEEUCCI61380.2024.10547935</pub-id></element-citation><mixed-citation id="mc-CR54" publication-type="journal">Rani, K. S. et al. Implementation of inception V3-Based CNN classification for malware detection. <italic toggle="yes">2024 Int. Conf. Recent. Adv. Electr. Electron. Ubiquitous Commun. Comput. Intell. RAEEUCCI 2024</italic>. 10.1109/RAEEUCCI61380.2024.10547935 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="other">Tan, M. &amp; Le, Q. V. EfficientNet: Rethinking model scaling for convolutional neural networks.&#160;<italic toggle="yes">36th Int. Conf. Mach. Learn. </italic><bold>2019 </bold> 10691&#8211;10700. (ICML, 2019).</mixed-citation></ref><ref id="CR56"><label>56.</label><mixed-citation publication-type="other">Chollet, F. Xception: Deep learning with depthwise separable convolutions, <italic toggle="yes">Proc. 30th IEEE Conf. Comput. Vis. Pattern Recognition CVPR 2017</italic><bold>2017</bold> 1800&#8211;1807. 10.1109/CVPR.2017.195 (2017).</mixed-citation></ref><ref id="CR57"><label>57.</label><citation-alternatives><element-citation id="ec-CR57" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kumar</surname><given-names>S</given-names></name><name name-style="western"><surname>Janet</surname><given-names>B</given-names></name><collab>DTMIC</collab></person-group><article-title>DTMIC: Deep transfer learning for malware image classification</article-title><source>J. Inf. Secur. Appl.</source><year>2021</year><pub-id pub-id-type="doi">10.1016/j.jisa.2021.103063</pub-id></element-citation><mixed-citation id="mc-CR57" publication-type="journal">Kumar, S., Janet, B., DTMIC. DTMIC: Deep transfer learning for malware image classification. <italic toggle="yes">J. Inf. Secur. Appl.</italic>10.1016/j.jisa.2021.103063 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR58"><label>58.</label><citation-alternatives><element-citation id="ec-CR58" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Maniriho</surname><given-names>P</given-names></name><name name-style="western"><surname>Mahmood</surname><given-names>AN</given-names></name><name name-style="western"><surname>Chowdhury</surname><given-names>MJM</given-names></name></person-group><article-title>A Survey of Recent Advances in Deep Learning Models for Detecting Malware in Desktop and Mobile Platforms</article-title><source>ACM Comput. Surv.</source><year>2024</year><pub-id pub-id-type="doi">10.1145/3638240</pub-id></element-citation><mixed-citation id="mc-CR58" publication-type="journal">Maniriho, P., Mahmood, A. N. &amp; Chowdhury, M. J. M. A Survey of Recent Advances in Deep Learning Models for Detecting Malware in Desktop and Mobile Platforms. <italic toggle="yes">ACM Comput. Surv.</italic>10.1145/3638240 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR59"><label>59.</label><mixed-citation publication-type="other"><italic toggle="yes">Keras &amp; Probabilistic losses.</italic><ext-link ext-link-type="uri" xlink:href="https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class">https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class</ext-link> (Accessed 08 February 2025).</mixed-citation></ref><ref id="CR60"><label>60.</label><citation-alternatives><element-citation id="ec-CR60" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Darabian</surname><given-names>H</given-names></name><etal/></person-group><article-title>Detecting cryptomining malware: a deep learning approach for static and dynamic analysis</article-title><source>J. Grid Comput.</source><year>2020</year><volume>18</volume><issue>2</issue><fpage>293</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1007/s10723-020-09510-6</pub-id></element-citation><mixed-citation id="mc-CR60" publication-type="journal">Darabian, H. et al. Detecting cryptomining malware: a deep learning approach for static and dynamic analysis. <italic toggle="yes">J. Grid Comput.</italic><bold>18</bold> (2), 293&#8211;303. 10.1007/s10723-020-09510-6 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR61"><label>61.</label><citation-alternatives><element-citation id="ec-CR61" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kumar</surname><given-names>S</given-names></name><name name-style="western"><surname>Meena</surname><given-names>S</given-names></name><name name-style="western"><surname>Khosla</surname><given-names>S</given-names></name><name name-style="western"><surname>Parihar</surname><given-names>AS</given-names></name></person-group><article-title>Autoencoder Enhanced Deep Convolutional Neural Network For Malware Classification</article-title><source>Int. Conf. Intell. Technol.</source><year>2021</year><pub-id pub-id-type="doi">10.1109/CONIT51480.2021.9498570</pub-id></element-citation><mixed-citation id="mc-CR61" publication-type="journal">Kumar, S., Meena, S., Khosla, S. &amp; Parihar, A. S. Autoencoder Enhanced Deep Convolutional Neural Network For Malware Classification. <italic toggle="yes">Int. Conf. Intell. Technol.</italic>10.1109/CONIT51480.2021.9498570 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR62"><label>62.</label><mixed-citation publication-type="other"><italic toggle="yes">Colab, Welcome to Colab</italic>. &#160;https://colab.research.google.com/#scrollTo=Wf5KrEb6vrkR (Accessed 10 August 2024).</mixed-citation></ref><ref id="CR63"><label>63.</label><mixed-citation publication-type="other"><italic toggle="yes">TensorFlow An end-to-end platform for machine learning</italic>.&#160;<ext-link ext-link-type="uri" xlink:href="https://www.tensorflow.org/">https://www.tensorflow.org/</ext-link></mixed-citation></ref><ref id="CR64"><label>64.</label><mixed-citation publication-type="other"><italic toggle="yes">Keras About Keras 3</italic><ext-link ext-link-type="uri" xlink:href="https://keras.io/about/">https://keras.io/about/</ext-link></mixed-citation></ref><ref id="CR65"><label>65.</label><mixed-citation publication-type="other"><italic toggle="yes">Pandas Latest version: 2.2.3</italic>. &#160;https://pandas.pydata.org/. (2024).</mixed-citation></ref><ref id="CR66"><label>66.</label><mixed-citation publication-type="other"><italic toggle="yes">NumPy The fundamental package for scientific computing with python.</italic> https://numpy.org/. (2024).</mixed-citation></ref><ref id="CR67"><label>67.</label><citation-alternatives><element-citation id="ec-CR67" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sharma</surname><given-names>O</given-names></name><name name-style="western"><surname>Sharma</surname><given-names>A</given-names></name><name name-style="western"><surname>Kalia</surname><given-names>A</given-names></name></person-group><article-title>Windows and IoT malware visualization and classification with deep CNN and Xception CNN using Markov images</article-title><source>J. Intell. Inf. Syst.</source><year>2023</year><volume>60</volume><issue>2</issue><fpage>349</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1007/s10844-022-00734-4</pub-id></element-citation><mixed-citation id="mc-CR67" publication-type="journal">Sharma, O., Sharma, A. &amp; Kalia, A. Windows and IoT malware visualization and classification with deep CNN and Xception CNN using Markov images. <italic toggle="yes">J. Intell. Inf. Syst.</italic><bold>60</bold> (2), 349&#8211;375. 10.1007/s10844-022-00734-4 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR68"><label>68.</label><mixed-citation publication-type="other">Scott, M., Lundberg &amp; Lee, S. I. A unified approach to interpreting model predictions. <italic toggle="yes">31st Conf. Neural Inf. Process. Syst. (NIPS 2017)</italic><bold>30</bold> 1&#8211;10. (Long Beach, 2017).&#160;</mixed-citation></ref></ref-list></back></article>
        
    </metadata>
</record>
    </GetRecord>

</OAI-PMH>